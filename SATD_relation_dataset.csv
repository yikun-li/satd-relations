Project,Relation Type,SATD A,SATD B
Drill,SATD Duplication,"[2017-09-12 19:57:04][ilooner][pull:summary][940]
DRILL-5752 Speed Up Unit Tests add Test Categories
","[2017-08-30 17:25:20][Timothy Farkas][issue:summary][DRILL-5752:13098611]
Speed Up Unit Tests"
Brooklyn Server,SATD Repayment,"[2013-01-28 17:27:45][Aled Sage][code-comment][8b66a8930784885a12980d6ed3eb651e79be4319]
 In jenkins for things like testRepeatedResizeUpStabilizationDelayTakesMaxSustainedDesired, which runs
 a time-sensitive test 100 times, it fails periodically due to things taking too long. This is most
 likely caused by a full (slow) GC kicking in during the test.

 By GC'ing here, we attempt to avoid a GC in the middle of the time-sensitive test
","[2013-01-28 17:27:45][Aled Sage][commit][8b66a8930784885a12980d6ed3eb651e79be4319]
AutoScalerPolicyTest repeated test: gc in setup

- Try to fix jenkins failure where the ""repeated"" test, which runs a
  time-sensitive test 100 consecutive times, fails occasionally due to
  scale out/back taking a couple of seconds longer than expected. I
  suspect it fails due to a slow GC in the middle of the test. 
  Therefore GC as part of setup for integration tests."
Incubator Pinot,SATD Repayment,"[2017-07-24 16:27:14][Xiaotian Jiang][code-comment][d6e37665863bdbe10138d730f00200cbcd2e0c1b]
 Disabled because with multiple servers, there is no way to check and guarantee that all servers get all segments
 reloaded, which cause the flakiness of the tests.
","[2017-07-24 16:27:14][Xiaotian Jiang][commit][d6e37665863bdbe10138d730f00200cbcd2e0c1b]
Fix the flakiness of OfflineClusterIntegrationTest (#1700)

With multiple servers, there is no way to check and guarantee that all servers get all segments reloaded, which cause the flakiness of the tests.
To fix that, in OfflineClusterIntegrationTest, only start one server.
Added a MultiNodesOfflineClusterIntegrationTest to keep the same coverage for multiple brokers and multiple servers."
Carbondata,SATD Duplication,"[2016-11-03 08:10:54][lion-x][pull:summary][288]
[CARBONDATA-369]Remove Useless Files in carbondata.scan.expression
","[2016-11-03 08:13:33][Lionx][issue:summary][CARBONDATA-369:13017547]
Remove Useless Files in carbondata.scan.expression"
Arrow,No Relation,"[2018-08-09 13:31:10][Wes McKinney][code-comment][78a4d651221c399c8e9779efa96e324a9caaa09c]
 This is overridden in several subclasses, but if an Unbox implementation
 is defined, it will be used here
","[2018-08-08 21:22:42][wesm][pull:comment][2366:208740429]
Yes, I think so. When mixing scalars and collections we can bail out early; I think exiting after 1000 elements if possible is better than visiting all 10,000,000. Maybe such cases are esoteric but preventing this worst case scenario is worth a bit of extra effort IMHO"
Groovy,SATD Repayment,"[2019-08-26 13:50:12][Daniel Sun][code-comment(deleted)][5a7fa7357bf587c317825df0de907e0d512e8b5d]
 TODO: Convert to functional interface?
","[2019-08-26 13:50:12][Daniel Sun][commit][5a7fa7357bf587c317825df0de907e0d512e8b5d]
Minor refactoring: Convert `ClassgenCallback` to functional interface"
Hbase,SATD Repayment,"[2017-12-14 15:59:41][zhangduo][commit][7466e64abb2c68c8a0f40f6051e4b5bf550e69bd]
HBASE-19510 TestDistributedLogSplitting is flakey for AsyncFSWAL
","[2017-12-14 02:33:36][Duo Zhang][issue:summary][HBASE-19510:13124863]
TestDistributedLogSplitting is flakey for AsyncFSWAL"
Hawq,SATD Duplication,"[2016-06-08 13:53:30][Paul Guo][code-comment][fe22ef4288fd9f08db67512740004922f7d71f51]

	 * This is a hack: We added the snappy support for row oriented storage, however
	 * to make the feature friendly to upgradation in short term, we decide to not
	 * modify the system table to implement this. Following ugly hack is to
	 * complete this. Let's remove this piece of code after snappy support is
	 * added to the related system tables.
","[2016-06-08 05:21:23][Paul Guo][issue:summary][HAWQ-793:12976707]
In HAWQ-774 we added the snappy support for the row oriented storage, however to make the change more friendly to upgradation, we will need to temporarily hack to keep the related metadata unmodified."
Beam,No Relation,"[2018-07-25 15:31:35][Ankur][commit][75e3986171ce68a6fc4c42689698576c407f05b1]
[BEAM-4176] Initial implementation for running portable runner tests (#5935)

* TestPortableRunner for validate runner tests

* Dynamically assign jobServer host and port.

* Documentation formatting

* Disable Metrics for Flink Portable Runner

* Change to gradle files and check for pipeline completion for flink validates runner test

* Review Comments

* Adding javadoc for default option factory

* Update lambda to handle 0 method args.

* Fix simple typo

* Use varargs in array based method declaration.

* Fixing Log message
","[2018-07-23 18:15:07][lukecwik][pull:comment][5935:204504520]
nit: use a lambda and the implicit `it` parameter as it allows you to call the method without any paramemters or with parameters"
Pulsar,SATD Repayment,"[2020-11-10 22:18:45][Renkai][commit][853bcf924ed7aa1ced63e7b985de2167c1820df1]
Gradually make `pulsar-broker` conform the project style check (#8501)

Make `checkstyle-pulsar-broker.xml` gradually the same with `checkstyle.xml` and keep style-check passed

* removed trailing white spaces
* replaced tabs with white spaces
* added `package-info.java`
","[2020-11-10 08:30:37][Renkai][pull:summary][8501]
Make `checkstyle-pulsar-broker.xml` gradually the same with `checkstyle.xml` and keep style-check passed

* removed trailing white spaces
* replaced tabs with white spaces
* added `package-info.java`"
Carbondata,SATD Repayment,"[2017-04-06 10:21:41][ravipesala][commit][4a7adfa97ae62ea946a1111101f5ae9b2148e76f]
[CARBONDATA-870] Folders and files not getting cleaned up created locally during data load operation. This closes #735
","[2017-04-05 13:44:54][Manish Gupta][issue:summary][CARBONDATA-870:13061745]
Folders and files which are created in local temp store location during data load and insert into operations are not getting cleaned up. After some time this will lead to filling up of local disk space and eventually will lead to data load failure if threshold limit is reached.
For this all the folders and files created locally need to be deleted once the operation is completed."
Ozone,SATD Duplication,"[2020-08-06 17:49:25][adoroszlai][pull:summary][1297]
HDDS-4073. Remove leftover robot.robot
","[2020-08-06 16:13:18][Attila Doroszlai][issue:summary][HDDS-4073:13321332]
An unused Robot test ({{robot.robot}}) was accidentally added in HDDS-3612.  It was refactored to separate {{string_tests.robot}} and {{fs_tests.robot}}, but the original file was not removed."
Lucene Solr,No Relation,"[2018-04-03 09:37:12][Alan Woodward][code-comment][00eab54f9d6232c68a93f10ff20e3a724ffeca14]
*
   * Return an iterator over intervals where the subiterators appear in a given order
","[2018-03-09 17:12:43][Jim Ferenczi][issue:comment][LUCENE-8196:16393188]
{quote}
I'd rather keep the API as it is, with the field being passed to IntervalQuery and then recursing down the IntervalSource tree.  Otherwise you end up having to declare the field on all the created sources, which seems redundant.  I've removed the cross-field hack entirely for the moment.
{quote}

+1 to remove the cross-field hack, thanks. Regarding the API it's ok since IntervalQuery limits all sources to one field so I am fine with that (I misunderstood how the IntervalQuery can be used)."
Nifi,SATD Repayment,"[2018-10-23 14:46:14][rednikotin][code-comment][c8928ce3509facbf4b6501295273849de2288fab]
 replace unnecessary row count with -1 stub value when paging is used
","[2018-10-23 14:46:14][rednikotin][commit][c8928ce3509facbf4b6501295273849de2288fab]
NIFI-5727: Added replace unnecessary row count with -1 stub value when paging is used

Signed-off-by: Matthew Burgess <mattyb149@apache.org>

This closes #3094"
Incubator Pinot,SATD Repayment,"[2016-07-27 13:16:16][Puneet Jaiswal][commit][dfa4a8f25fa23a4458f5d92376a06a72b8463836]
TE: removing unused DAO classes. (#320)

* thirdeye : removing unused classes

* adding results util function

* restoring code for backward compatibility

* optimizing function update with anomaly-result
","[2016-07-27 17:54:37][puneetjaiswal][pull:summary][320]
TE: removing unused DAO classes"
Incubator Doris,SATD Repayment,"[2020-12-18 21:17:18][Mingyu Chen][code-comment][3d4b2cb1aee6c3c0d4ebc74ca75046ceeeb8c350]
/ Regardless of whether the tablet is submitted for compaction or not,
/ we need to call 'reset_compaction' to clean up the base_compaction or cumulative_compaction objects
/ in the tablet, because these two objects store the tablet's own shared_ptr.
/ If it is not cleaned up, the reference count of the tablet will always be greater than 1,
/ thus cannot be collected by the garbage collector. (TabletManager::start_trash_sweep)
","[2020-12-17 03:36:23][morningman][pull:summary][5100]
## Proposed changes

Regardless of whether the tablet is submitted for compaction or not,
we need to call 'reset_compaction' to clean up the base_compaction or cumulative_compaction objects
in the tablet, because these two objects store the tablet's own shared_ptr.
If it is not cleaned up, the reference count of the tablet will always be greater than 1,
thus cannot be collected by the garbage collector. (TabletManager::start_trash_sweep)

This bug is introduced from #4891

## Types of changes

- [x] Bugfix (non-breaking change which fixes an issue)"
Phoenix,No Relation,"[2014-12-18 12:18:16][Nick Dimiduk][code-comment][8307f6c43fecd397c96414caf606c25b273dbd3a]

                 * There was a bug in serialization of timestamps which was causing the sub-second millis part
                 * of time stamp to be present both in the LONG and INT bytes. Having the <100000 check
                 * makes this serialization fix backward compatible.
","[2014-12-17 20:16:59][Eli Levine][issue:comment][PHOENIX-1514:14250457]
Thanks for the work, Nick! IMHO we might be better off keeping this in main and 5.0 branch. Looking at the pull req a bit... this change is quite pervasive and putting into 4.0 means version 4.3, the next minor Phoenix 4 release will get it. This is feeling like a major version feature.  Keeping it in 5.0 and main might make more sense and maybe only backport it if/when people express a need for this in 4.x?"
Camel,SATD Repayment,"[2020-08-28 09:11:55][Claus Ibsen][commit][0b25b36f0a6baf73ac0a9497af4502a0967b1964]
CAMEL-15474: camel-api-component - Source code generator should include parameter documentation
","[2020-08-27 10:15:52][Claus Ibsen][issue:summary][CAMEL-15474:13324809]
camel-api-component - Source code generator should include parameter documentation"
Pulsar,SATD Duplication,"[2020-09-16 04:56:10][gaoran10][pull:summary][8071]
[Test] transaction flaky test
","[2020-09-16 04:47:33][gaoran10][issue:summary][8070]
Transaction flaky test caused by TB client topic lookup failed"
Attic Apex Malhar,SATD Repayment,"[2015-03-06 12:26:22][Chaitanya][code-comment][5baa375c47efc7fdd5f326f8ad4f43d4ab7a0dba]
 Ignore the duplicate messages
","[2015-03-06 12:26:22][Chaitanya][commit][5baa375c47efc7fdd5f326f8ad4f43d4ab7a0dba]
Ignore the duplicate messages. Remove the map first, if the thread is done"
Incubator Mxnet,SATD Repayment,"[2018-08-07 05:18:48][Anirudh Subramanian][commit][9dd5edd8e6ec28a97c6ba9bda51b2b9c7a88971b]
Disable flaky cpp test (#12056)
","[2018-08-06 23:10:52][anirudh2290][pull:summary][12056]
## Description ##
Disabling flaky test. Tracking here: https://github.com/apache/incubator-mxnet/issues/11998

## Checklist ##
### Essentials ###
Please feel free to remove inapplicable items for your PR.

- [x] Changes are complete (i.e. I finished coding on this PR)
- [x] All changes have test coverage:
- Unit tests are added for small changes to verify correctness (e.g. adding a new operator)
- Nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore)
- Build tests will be added for build configuration changes (e.g. adding a new build option with NCCL)
- [x] To the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change

### Changes ###
- [x] Disable test MKLDNNSum"
Beam,SATD Repayment,"[2016-02-01 19:09:45][dhalperi][code-comment][ab733b4557f82589d661d5093a6e0c6d7905bae4]
 Cache the old encoder/decoder and let the factories reuse them when possible. To be threadsafe,
 these are ThreadLocal. This code does not need to be re-entrant as AvroCoder does not use
 an inner coder.
","[2016-02-01 19:09:45][dhalperi][commit][ab733b4557f82589d661d5093a6e0c6d7905bae4]
AvroCoder: more efficient use of Avro APIs

- Make the Encoder/Decoder factories static -- they are thread-safe
  and immutable.
- Reuse the DirectBinaryEncoder/DirectBinaryDecoder objects across
  invocations to encode/decode. Though reuse is only ""when possible"",
  it's always applicable in our invocations. This change reduces the
  allocations of these objects from 1/element to 1/coder instance.
- Remove the call to flush from encoder(), because the
  DirectBinaryEncoder does not need to be flushed.
- Cache the objects in ThreadLocal variables for thread safety.

----Release Notes----
[]
-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=113018546"
Fineract,SATD Repayment,"[2019-11-25 08:58:07][xurror][code-comment(deleted)][b0bfeddc62c09edf01ef193e5da373faab78a0cd]
 TODO Auto-generated method stub
","[2019-11-25 08:58:07][xurror][commit][b0bfeddc62c09edf01ef193e5da373faab78a0cd]
remove TODO Auto-generated method stub"
Lucene Solr,No Relation,"[2018-02-20 17:46:47][koji][code-comment][4bfcbc5c605e2823c924dbe287a67b37d2dd0ca8]
 Field to use to determine and enforce document uniqueness.
      Unless this field is marked with required=""false"", it will be a required field
","[2018-02-24 19:14:09][Uwe Schindler][issue:comment][SOLR-11795:16375749]
Hi Koji,
the snakeyaml people are fixing the bug with Java 9. So it looks like we may get a relaese - it should be enough to update the dependency then. I have no plans about their schedule.

Nevertheless, I am not really happy with another config file format. We should somehow decide for one of them, not add many more."
Hadoop,No Relation,"[2012-03-03 00:42:49][Aaron Myers][code-comment][a1fc055489766876e8d3ee2bd75a5fef25f05b33]
 Look up the address of the active NN.
","[2012-03-14 19:28:25][Todd Lipcon][issue:comment][HDFS-1623:13229534]
Hi Avik. The multi-SBN approach is actually very nearly implemented by what's in trunk. The main missing pieces are actually in the more trivial bits -- for example, we have a few bits of the code that look up ""the other node"" for operations like triggering checkpoints. Those would have to be modified a bit to ""look up the active node"" instead. But nothing fundamental or really difficult."
Hbase,SATD Repayment,"[2018-06-14 20:26:49][Sean Busbey][code-comment][cb2dfd117b1764c3719d184a5ffbf77a7c5949ec]
 If we change checkstyle configs, run checkstyle
","[2018-06-14 17:38:55][Sean Busbey][issue:summary][HBASE-20733:13166158]
right now we only do checkstyle tests when java files are altered. we should also run if our checkstyle configs in {{hbase-checkstyle}} are altered."
Lucene Solr,No Relation,"[2012-08-09 10:20:53][Uwe Schindler][code-comment][148d99cbbc1201c1812ea0b7d63604355f55ff8b]
Assume all of the docs have a unique term (e.g. a primary key) and we hope to maintain a set with 10% of bits set
","[2012-08-09 14:31:22][Chris Male][issue:comment][LUCENE-3312:13431839]
Yup found it.  

The problem is in the branch {{Document#getFields()}} is creating a new List and inside {{DocMaker}} in the benchmark module, it is pulling the Fields and clearing them (using {{clear()}}).  Since a new List is being created each time, it is the new List that is getting cleared rather than the actual fields.  Hence each iteration just adds more fields without having the previous ones cleared."
Druid,SATD Repayment,"[2018-10-23 07:17:38][Roman Leventov][commit][84ac18dc1bce14afe88ebcccd46da21baefae73d]
Catch some incorrect method parameter or call argument formatting patterns with checkstyle (#6461)

* Catch some incorrect method parameter or call argument formatting patterns with checkstyle

* Fix DiscoveryModule

* Inline parameters_and_arguments.txt

* Fix a bug in PolyBind

* Fix formatting
","[2018-10-12 21:46:46][leventov][pull:summary][6461]
Catch some incorrect method parameter or call argument formatting patterns with checkstyle"
Beam,SATD Repayment,"[2020-04-09 10:44:35][Kamil Wasilewski][commit][79b2d87b59819ee55fb8600e8a845c6ba5b98d64]
[BEAM-9085] Fix performance regression in SyntheticSource on Python 3 (#11092)
","[2020-01-10 12:15:55][Kamil Wasilewski][issue:summary][BEAM-9085:13278704]
Performance regression in np.random.RandomState() skews performance test results across Python 2/3 on Dataflow"
Attic Apex Core,SATD Duplication,"[2013-12-04 15:06:29][David Yan][code-comment][69862c37388b64f992fb31be4d88b5f405edeb1b]
 commented out because free memory is misleading because of GC. may want to revisit this.
public int memoryMBFree;
","[2013-12-04 15:06:29][David Yan][commit][69862c37388b64f992fb31be4d88b5f405edeb1b]
SPOI-1456 #resolve took out memoryFree because GC makes it misleading, may want to revisit this"
Hive,No Relation,"[2017-03-21 13:55:27][Sergey Shelukhin][code-comment(deleted)][9f5a3e3d89db7d6f4754eb345ad9abb6997857e1]
 TODO: is it valid to give zcr the modified 2nd part?
","[2017-03-21 13:55:27][Sergey Shelukhin][commit][9f5a3e3d89db7d6f4754eb345ad9abb6997857e1]
HIVE-16180 : LLAP: Native memory leak in EncodedReader (Sergey Shelukhin/Prasanth Jayachandran, reviewed by Prasanth Jayachandran/Sergey Shelukhin)"
Echarts,SATD Duplication,"[2017-12-29 17:37:20][sushuang][code-comment][ee5d23b29cc17ae07a63add3644f0826d0e57374]
 If a stageHandler should cover all series, `allSeries` should be declared mandatorily,
 to avoid some typo or abuse. Otherwise if an extension do not specify a `seriesType`,
 it works but it may cause other irrelevant charts blocked.
","[2017-12-29 17:37:20][sushuang][commit][ee5d23b29cc17ae07a63add3644f0826d0e57374]
If a stageHandler should cover all series, `allSeries` should be declared mandatorily, to avoid some typo or abuse. Otherwise if an extension do not specify a `seriesType`, it works but it may cause other irrelevant charts blocked."
Tvm,SATD Repayment,"[2020-03-22 18:15:19][Tianqi Chen][commit][50b5adaac2956712d65e14c163148c1e6279f5e2]
[DOCS] Cleanup docs before rebuild (#5127)

* [DOCS] Cleanup docs before rebuild

* Ask doxygen to generate svg to minimize the file size
","[2020-03-22 20:22:27][tqchen][pull:summary][5127]
[DOCS] Cleanup docs before rebuild"
Hbase,No Relation,"[2014-12-16 11:14:30][Jesse Yates][commit][a411227b0ebf78b4ee8ae7179e162b54734e77de]
HBASE-5162 Basic client pushback mechanism

Instead of just blocking the client for 90 seconds when the region gets too
busy, it now sends along region load stats to the client so the client can
know how busy the server is. Currently, its just the load on the memstore, but
it can be extended for other stats (e.g. cpu, general memory, etc.).

It is then up to the client to decide if it wants to listen to these stats.
By default, the client ignores the stats, but it can easily be toggled to the
built-in exponential back-off or users can plug in their own back-off
implementations
","[2014-11-07 20:01:02][Jesse Yates][issue:comment][HBASE-5162:14202565]
Updated patch on latest master (we were getting behind a little bit) and hopefully fixing the checkstyle and findbugs issues."
Arrow,SATD Repayment,"[2018-03-26 19:38:25][Antoine Pitrou][commit][f9f8320339692d4134d1ef42c32cb7c8d547593e]
ARROW-2354: [C++] Make PyDecimal_Check() faster

This basically keeps an eternal reference to the decimal type.

Before:
```
[100.00%] ··· Running convert_pandas.PandasConversionsToArrow.time_from_series                                                                               ok
[100.00%] ····
               ========= ========== ============= ============== ===========
               --                               dtype
               --------- ---------------------------------------------------
                  size     int64       float64     float64_nans      str
               ========= ========== ============= ============== ===========
                   10     420±1μs      426±1μs      421±0.3μs     450±0.6μs
                1000000   6.92±1ms   14.1±0.02ms   15.5±0.04ms      1.66s
               ========= ========== ============= ============== ===========
```

After:
```
[100.00%] ··· Running convert_pandas.PandasConversionsToArrow.time_from_series                                                                               ok
[100.00%] ····
               ========= =========== ============= ============== ===========
               --                               dtype
               --------- ----------------------------------------------------
                  size      int64       float64     float64_nans      str
               ========= =========== ============= ============== ===========
                   10     425±0.9μs     428±1μs      430±0.8μs     438±0.6μs
                1000000    7.49±1ms   14.2±0.04ms   15.4±0.05ms     99.2±1ms
               ========= =========== ============= ============== ===========
```

Author: Antoine Pitrou <antoine@python.org>

Closes #1794 from pitrou/ARROW-2354-faster-decimal-check and squashes the following commits:

3e22cfe3 <Antoine Pitrou> ARROW-2354:  Make PyDecimal_Check() faster
","[2018-03-26 16:41:42][Antoine Pitrou][issue:summary][ARROW-2354:13147974]
[C++] PyDecimal_Check() is much too slow"
Incubator Brooklyn,SATD Duplication,"[2015-11-02 16:42:45][Alex Heneveld][code-comment][48e4fe3ca0b5a00fbdec10bceec9f21edee25ded]
 TODO-type-registry
","[2015-10-30 03:00:38][ahgittin][pull:summary][993]
Introduce a type registry as a simplified catalog"
Flink,No Relation,"[2015-07-21 17:58:14][Stephan Ewen][code-comment][d59cebd8c3f643dc6da88924300e78f65f26c640]
 If no document and documentElement is available, return
","[2015-07-21 19:17:05][Stephan Ewen][issue:comment][FLINK-2358:14635654]
Implemented in 44ee1c1b64b18db199a7e77492dc890a1234fcb0 and e86f451705315ea7d1ed4d3821e08dd2225d84c0"
Incubator Mxnet,SATD Repayment,"[2019-08-29 10:37:11][Anirudh Subramanian][commit][649429d055e8ac89b2a45929ff2344959768a6e3]
Disable flaky test in test_amp_conversion (#16031)
","[2019-08-28 18:51:26][anirudh2290][pull:summary][16031]
Disable flaky test in test_amp_conversion"
Ignite,No Relation,"[2019-02-06 13:03:51][ascherbakoff][pull:comment][3501:254261587]
Missing javadoc
","[2018-02-08 09:13:14][Alexey Scherbakov][issue:summary][IGNITE-7648:13137103]
IGNITE_ENABLE_FORCIBLE_NODE_KILL system property was introduced in IGNITE-5718 as a way to prevent unnecessary node drops in case of short network problems.

I suppose it's wrong decision to fix it in such way.

We had faced some issues in our production due to lack of automatic kicking of ill-behaving nodes (on example, hanging due to long GC pauses) until we realised the necessity of changing default behavior via property.

Right solution is to kick nodes only if failure threshold is reached. Such behavior should be always enabled.

UPDATE: During a discussion it was decided what the property will remain disabled by default.

We decided to change timeout logic in case of failure detection enabled. We start performing connect and handshake from 500ms increasing using exponential backoff strategy."
Lucene Solr,No Relation,"[2011-06-30 13:59:59][Mark Robert Miller][code-comment][b5be90974b28e59d6ee59b6cbfd24f68c7fc79f6]
*
 * Helper class for tracking autoCommit state.
 * 
 * Note: This is purely an implementation detail of autoCommit and will
 * definitely change in the future, so the interface should not be relied-upon
 * 
 * Note: all access must be synchronized.
","[2011-06-01 00:13:57][Jason Rutherglen][issue:comment][SOLR-2193:13041904]
bq. I guess personally, just looking at the big picture, this issue seems like a great win for Solr.

Yes the concept of not stopping the world is great.  The concept of Solr continuing to be difficult to customize is not so great.  

-1 on the implementation which introduces even more awkward layers into Solr, which should be going in the direction of removing the old cruft."
Trafodion,SATD Repayment,"[2017-10-02 00:13:35][Anoop Sharma][code-comment(deleted)][2eaef5d7a9b3beb1b4f45ab97899c2a4b6b7059e]
 warning elimination
 warning elimination 
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
","[2017-10-02 00:13:35][Anoop Sharma][commit][2eaef5d7a9b3beb1b4f45ab97899c2a4b6b7059e]
PR-1251 [TRAFOFION-2731] CodeCleanup: Phase4: Removed lagacy/obsolete warning elimination pragmas"
Trafodion,SATD Repayment,"[2017-10-02 00:13:35][Anoop Sharma][code-comment(deleted)][2eaef5d7a9b3beb1b4f45ab97899c2a4b6b7059e]
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination
","[2017-10-02 00:13:35][Anoop Sharma][commit][2eaef5d7a9b3beb1b4f45ab97899c2a4b6b7059e]
PR-1251 [TRAFOFION-2731] CodeCleanup: Phase4: Removed lagacy/obsolete warning elimination pragmas"
Airflow,SATD Duplication,"[2017-09-11 15:08:00][Fokko][pull:summary][2592]
[AIRFLOW-1582] Improve logging within Airflow
","[2017-09-08 13:37:58][Fokko Driesprong][issue:summary][AIRFLOW-1582:13100812]
Improve logging structure of Airflow"
Incubator Doris,SATD Repayment,"[2019-09-03 10:42:16][EmmyMiao87][commit][9f5e5717d4aaf184518d8da93b11c2137489fe6d]
Unify the msg of 'Memory exceed limit' (#1737)

The new msg of limit exceed: ""Memory exceed limit. %msg, Backend:%ip, fragment:%id Used:% , Limit:%. xxx"".
This commit unifies the msg of 'Memory exceed limit' such as check_query_state, RETURN_IF_LIMIT_EXCEEDED and LIMIT_EXCEEDED.
","[2019-09-02 12:09:41][EmmyMiao87][pull:summary][1737]
The new msg of limit exceed: ""Memory exceed limit. %msg, Backend:%ip, fragment:%id Used:% , Limit:%. xxx"".
This commit unifies the msg of 'Memory exceed limit' such as check_query_state, RETURN_IF_LIMIT_EXCEEDED and LIMIT_EXCEEDED."
Reef,No Relation,"[2014-05-29 17:03:31][Markus Weimer][commit][9ae319a235bd2aaf22e340230edc3236446b9171]
Fixed the first half of #750

The fixes the first half of #750, namely the test for exception propagation from a Task's `call()` method:

 * Removed the `FailedTask` handler in the test's Driver. This means that we now forward the errors correctly to the client.
 * Fixed a log message in `FailTaskStart`
 * Updated `EvaluatorManager` logging
","[2016-01-05 18:25:40][tcNickolas][pull:comment][750:169088890]
Do we need to increase the size of the images? I'm not sure how github resizes them when displaying README.md, they might not scale."
Gobblin,SATD Repayment,"[2016-11-23 11:47:58][htran1][commit][5910b0734d297988b3e0bf4e7f9b29310c958514]
Interleave gc() calls with memory allocations to improve reliability of garbage collection test. (#1421)
","[2016-11-23 18:39:49][htran1][pull:summary][1421]
Interleave gc() calls with memory allocations to improve reliability …"
Camel,SATD Repayment,"[2015-01-20 09:53:59][Claus Ibsen][commit][f7cbecbb43738a94bf37f856868f3685ad65896f]
CAMEL-8195: Add javadoc to model classes so we have EIP documentation out of the box
","[2014-12-30 10:04:09][Claus Ibsen][issue:summary][CAMEL-8195:12764171]
Add javadoc to model classes so we have EIP documentation out of the box"
Hbase,SATD Duplication,"[2016-06-14 18:51:54][anoopsjohn][code-comment][17bcf14fea2637fe0e5ca23bb0008c1cca208c98]
 TODO better config names?
 hbase.ipc.server.reservoir.initial.max -> hbase.ipc.server.reservoir.max.buffer.count
 hbase.ipc.server.reservoir.initial.buffer.size -> hbase.ipc.server.reservoir.buffer.size
","[2016-06-14 13:37:53][Anoop Sam John][issue:comment][HBASE-15525:15329506]
{quote}
// TODO better config names?
+  // hbase.ipc.server.reservoir.initial.max -> hbase.ipc.server.reservoir.max.buffer.count
+  // hbase.ipc.server.reservoir.initial.buffer.size -> hbase.ipc.server.reservoir.buffer.size
{quote}
I added this TODO.  Kept the old config names from BoundedBBPool for BC.  May be we should add the new config and deprecate old for 2.0?  We can not just rename by deprecating in 1.3+ versions."
Incubator Mxnet,SATD Repayment,"[2017-07-11 10:56:24][Soonhwan-Kwon][commit][22f9a0dc96a0ad3741c1f8db7b66f27d9de9971a]
add bucketing/batchnorm and improved performance for speech_recognition example (#6971)
","[2017-07-10 04:20:29][Soonhwan-Kwon][pull:summary][6971]
add bucketing and batch norm scheme for speech_recognition example to improve training performance
add flexibility to support various optimizer
fix bug in generating bi-graphemes dictionray
add option not to save csv file to improve performane and reduce disk space requirement
and it solves performance issue(speed) related to #6418
and may related to issues #3076, #6115, #2663
when using both bucketing(variable length) and batch norm
although it is not a solution for time-step wise but layer wise approach for batch normalization"
Accumulo,No Relation,"[2018-08-28 15:44:40][Christopher McTague][code-comment][aaa1c0c82f58b5047b9146d1a0adf007cdb75c0c]
 TODO use constants
","[2018-08-28 15:44:40][Christopher McTague][commit][aaa1c0c82f58b5047b9146d1a0adf007cdb75c0c]
Spelling corrections in comments/javadocs (#620)"
Druid,SATD Duplication,"[2017-05-23 10:33:03][Gian Merlino][code-comment][22e5f52d00425d3e70a10c2c49db39055864d51e]
 Workaround for non-thread-safe use of HyperLogLogCollector.
 OnheapIncrementalIndex has a penchant for calling ""aggregate"" and ""get"" simultaneously.
","[2017-05-23 10:33:03][Gian Merlino][commit][22e5f52d00425d3e70a10c2c49db39055864d51e]
Workaround for non-thread-safe use of CardinalityAggregator. (#4304)"
Ignite,SATD Duplication,"[2017-09-27 12:20:24][Pavel Tupitsyn][code-comment][7f82340189bebac7bfd5f935eb3531035a6f9acb]
/ <summary>
/ A trick to clean up ignite.jni.dll when Ignite is started in non-default AppDomain.
/ We rely on finalizer order here, which is technically undefined:
/ everything that uses UnmanagedUtils must be cleaned up when this class is finalized.
/ </summary>
","[2017-07-12 15:44:25][Pavel Tupitsyn][issue:comment][IGNITE-5730:16084187]
* {{DomainUnload}} is not called in default domain. {{ProcessExit}} should be used instead.
* When Ignite is started in a non-default AppDomain, we should use {{DomainUnload}}. But we rely on {{UnmanagedTarget}} and {{UnmanagedContext}} finalizers to clean up unmanaged objects, so we can't unload ignite.jni.dll before everything is finalized. And finalizer order is undefined. Seems like there is no reliable way to handle this.

Maybe we should not waste time on this and implement IGNITE-5343 instead, which gets rid of {{ignite.jni.dll}} altogether."
Drill,SATD Duplication,"[2016-01-29 18:12:27][laurentgo][pull:summary][347]
Drill code base references lots of rawtypes, which generates lots of warning from the compiler.

As Drill is now compiled with Java 1.7, most of them can be replaced by generic types.
","[2016-01-29 17:52:56][Laurent Goujon][issue:summary][DRILL-4327:12935193]
The Drill codebase references lots of rawtypes, which generates lots of warning from the compiler.

Since Drill is now compiled with Java 1.7, it should use generic types as much as possible."
Lucene Solr,No Relation,"[2017-11-03 10:40:14][Alan Woodward][code-comment][a886a001a4c08e37cc975fd4965bbbaa4ddf938a]
 BooleanQuery wrapping an uncacheable query should also not be cached
","[2017-11-01 14:01:33][Alan Woodward][issue:comment][LUCENE-8017:16234100]
Here's a patch adding getCacheHelper() as a method on Weight.  I've made this abstract and implemented it on all Weights - it could theoretically default to returning null or the Reader-level cache helper, but I think it's better to be explicit about it.

Some things to explore in follow-up issues:
* re-instate getCoreAndDeletesCacheHelper (or CoreAndDocValues, or whatever we want to call it) so that doc-values based queries can be re-used between searchers if the DV gen is the same
* add getCacheHelper to Double/LongValuesSource so that, eg constant DVS queries can be cached properly"
Beam,No Relation,"[2017-01-23 16:03:47][Kenneth Knowles][code-comment][9248befbbba6b2d18cde3b7ee562b13af33681fc]
*
 * Tests for ApiSurface. These both test the functionality and also that our
 * public API is conformant to a hard-coded policy.
","[2017-01-23 16:03:47][Kenneth Knowles][commit][9248befbbba6b2d18cde3b7ee562b13af33681fc]
Revert ""Simplified API surface verifications""

This reverts commit 29ffaf3859ba9b4d8ba8529efc96fd5e105e21a3.

The change to require all whitelisted packages to actually expose something
failed in the Dataflow runner postcommit. To be rolled forward after
fixing."
Hbase,SATD Repayment,"[2017-12-14 15:59:41][zhangduo][commit][7466e64abb2c68c8a0f40f6051e4b5bf550e69bd]
HBASE-19510 TestDistributedLogSplitting is flakey for AsyncFSWAL
","[2017-12-14 02:33:36][Duo Zhang][issue:summary][HBASE-19510:13124863]
TestDistributedLogSplitting is flakey for AsyncFSWAL"
Geode,SATD Repayment,"[2018-08-07 13:51:17][Dan Smith][commit][fcd6940600bc0ad3593a492c9a3a30bef4a9bf76]
GEODE-5470: Deleting flaky DlockAndTxLockRegressionTest

This test was introduced as part of the fix for GEODE-4928. However,
we've determined that GEODE-4928 is not actually fixed, which is why
this test is sporadically failing.

Since GEODE-4928 actually appears to be trying to introduce new behavior
for dlocks that is a rather involved feature to implement. Leaving that
feature for another time and deleting this test.
","[2018-07-24 16:35:42][Jinmei Liao][issue:comment][GEODE-5470:16554497]
The test has a comment that says: ""sometimes fail if the background cleanup takes too long."""
Helix,SATD Repayment,"[2014-05-21 18:52:05][zzhang][code-comment][f3b2c4f66acc700467cf99c7b28be1e494d724d7]
 all other participants should have cleaned up empty current state
","[2014-05-21 18:52:05][zzhang][commit][f3b2c4f66acc700467cf99c7b28be1e494d724d7]
[HELIX-132] current-state and external-view are not cleaned up when a resource has been removed, rb=21666"
Beam,SATD Repayment,"[2018-04-24 15:59:53][Thomas Groh][commit][6bb6425dec9ba764d8ba70135e47dc71ecfa22dd]
Merge pull request #5148: Cleanups in GroupByKeyOnlyEvaluatorFactory
","[2018-04-16 23:23:01][tgroh][pull:summary][5148]
Cleanups in GroupByKeyOnlyEvaluatorFactory"
Tinkerpop,SATD Duplication,"[2014-05-28 10:48:49][Stephen Mallette][code-comment][ce936da5d046d426d69eae7c887a45d109a1295b]
 a dead connection signifies a likely dead host - given that assumption close the pool.  we could likely
 have a smarter and more configurable choice here, but for now this is ok.
","[2014-05-28 10:48:49][Stephen Mallette][commit][ce936da5d046d426d69eae7c887a45d109a1295b]
Handle dead connections in a pool by closing the pool.

We likely could have more configurable and flexible approaches to dealing with dead connections, but for now the assumption that a dead connection means a dead host is likely good enough."
Lucene Solr,SATD Repayment,"[2018-07-05 14:53:44][Steve Rowe][code-comment][039dae76cb27d6dbc4273f3033ed167a87e3e5f2]
 Remove old stuff
","[2018-07-05 14:53:44][Steve Rowe][commit][039dae76cb27d6dbc4273f3033ed167a87e3e5f2]
Run 'rvm cleanup all' to remove old stuff"
Shardingsphere Elasticjob,SATD Duplication,"[2020-10-19 19:29:09][Liang Zhang][code-comment][dc25797275052f4519e7c59331be295bb3ee9d44]
 TODO default value is 5000
","[2020-10-19 11:29:04][terrymanu][pull:summary][1600]
Add todo to default value"
Flink,SATD Repayment,"[2020-11-10 10:57:26][fangliang][commit][ea88795c96585e1ae5a195b9e633d8565c1a7f5d]
[FLINK-18938][table-api] Throw better exception message for querying sink only or source only connector

This closes #13214
","[2020-08-13 08:10:18][Jark Wu][issue:summary][FLINK-18938:13322489]
Throw better exception message for quering sink-only connector"
Drill,No Relation,"[2016-11-02 18:00:55][Parth Chandra][commit][7f5acf8f06f4ab2a2efc9801d322b81436794004]
DRILL-4800: Parallelize column reading. Read/Decode fixed width fields in parallel Decoding var length columns in parallel Use simplified decompress method for Gzip and Snappy decompression. Avoids concurrency issue with Parquet decompression. (It's also faster). Stress test Parquet read write Parallel column reader is disabled by default (may perform less well under higher concurrency)
","[2016-07-22 18:48:48][Parth Chandra][issue:summary][DRILL-4800:12991922]
Improve parquet reader performance"
Incubator Doris,SATD Repayment,"[2020-02-05 11:48:54][LingBin][commit][ee5323a6a04ac668a86bff255d8e1e4e88e38a2f]
[Code Refactor]Improve initialization flow of Schema (#2833)

When constructing `Schema` objects, two similar `init` functions
need to be called, and the call order is implicitly required, which
is easy to be misused. At the same time, some of the existing comments
are missing or out of date, which will cause some misleading.

This patch unifies the initialization logic of `Schema`.

No functional changes in this patch.
","[2020-02-04 08:51:00][lingbin][pull:summary][2833]
When constructing `Schema` objects, two similar `init()` functions
need to be called, and the call order is implicitly required, which
is easy to be misused. At the same time, some of the existing comments
are missing or out of date, which will cause some misleading.

This patch unifies the initialization logic of `Schema`.

No functional changes in this patch."
Carbondata,SATD Repayment,"[2018-04-23 16:28:35][ravipesala][commit][8b33ab240126e999e9196369025917370172eee4]
[CARBONDATA-2376] Improve Lucene datamap performance by eliminating blockid while writing and reading index

Problem:
Currently DataMap interface implementations use blockid and blockletid while writing index files, Actually blockid is not needed to store in index files as it only requires blockletid. So it adds more memory and disk size to write index files.

Solution:
Use taskname as index name to identify the indexname. And filter the blocklets directly by avoiding blockids.And pass the taskName as indexname to identify the blockid from blocletdatamap.

Corrected the implementations of LuceneDatamap, BloomFilterDataMap, CGDataMap, FGDataMap and MinMaxDataMap

This closes #2206
","[2018-04-22 05:03:56][ravipesala][pull:summary][2206]
[CARBONDATA-2376] Improve Lucene datamap performance by eliminating blockid while writing and reading index."
Incubator Pinot,SATD Repayment,"[2018-09-27 18:39:45][Xiaotian Jiang][commit][e5ec0f9cdf60b341fd2373da12420c89367e19a2]
Simplify the parameter for forward index creators (#3208)

Also move method getNumBitsPerValue() into PinotDataBitSet and re-implement it without using double
","[2018-09-21 00:50:00][Jackie-Jiang][pull:summary][3208]
Simplify the parameter for forward index creators"
Flink,SATD Duplication,"[2020-06-03 14:46:50][Aljoscha Krettek][code-comment][dc6181667ac012afc0c68cfef825ec7bb30a7589]
 We are using JavaSerializer from the flink-runtime module here. This is very naughty and
 we shouldn't be doing it because ideally nothing in the API modules/connector depends
 directly on flink-runtime. We are doing it here because we need to maintain backwards
 compatibility with old state and because we will have to rework/remove this code soon.
","[2020-06-03 14:46:50][Aljoscha Krettek][commit][dc6181667ac012afc0c68cfef825ec7bb30a7589]
[FLINK-17376] Use JavaSerializer instead of getSerializableListState()

We do this because we want to deprecate that method. We will have to get
rid of using JavaSerialization completely soon, though."
Incubator Brooklyn,No Relation,"[2015-11-17 22:50:49][Alex Heneveld][code-comment][3e40b2bfd609e6313c9f48d42be722f708043da1]
 TODO depending how useful this is, it might be better to replace by a static WeakHashMap in RegisteredTypes
","[2015-11-12 13:09:18][neykov][pull:comment][1017:44654399]
Doesn't look right, aren't application specs always top level?

On another note, I haven't removed this method just for backwards compatibility. It belongs to an utils class with the `createServiceSpecs` doing the heavy lifting."
Incubator Pinot,SATD Repayment,"[2020-08-05 21:23:37][Xiaotian (Jackie) Jiang][commit][ffa954194e61e330c625a795cae94c15a54a2694]
Pre-generate aggregation functions in QueryContext (#5805)

`AggregationFunction` itself is stateless, so we can share it among all the segments to prevent the overhead of creating it per segment. This can significantly improve the performance of high selectivity queries that hit lots of segments.

- Remove the `accept(visitor)` from the `AggregationFunction` interface which may make it stateful
- Make `DistinctCount` and `DistinctCountBitmap` stateless by caching the dictionary within the result holder
","[2020-08-04 19:59:16][Jackie-Jiang][pull:summary][5805]
## Description
`AggregationFunction` itself is stateless, so we can share it among all the segments to prevent the overhead of creating it per segment. This can significantly improve the performance of high selectivity queries that hit lots of segments.

- Remove the `accept(visitor)` from the `AggregationFunction` interface which may make it stateful
- Make `DistinctCount` and `DistinctCountBitmap` stateless by caching the dictionary within the result holder

## Release Notes
Interface change: `accept(visitor)` is removed from `AggregationFunction`
All the implementation of the `AggregationFunction` should be stateless so that it can be shared among all the segments."
Ozone,No Relation,"[2019-01-09 11:20:57][Hanisha Koneru][code-comment][a8426d990f79e4cf826136dd8960cbcfb091d14a]
 Since the state machine is not implemented yet, we should get the
 configured dummy message from Ratis.
","[2019-01-09 09:15:34][Shashikant Banerjee][issue:comment][HDDS-947:16737994]
Thanks [~hanishakoneru] for updating the patch. The patch looks good to me. I am +1 on this.

Please take care of the checkStyle issues and ASF licensing issue while committing."
Kafka,No Relation,"[2016-04-07 21:42:24][granders][pull:comment][1173:58950231]
@ewencp Isn't this true of any check of ""aliveness"" here since the process can be gone by the time you check?

In principle you'd need to detect
""is alive OR was alive and finished successfully""

One option is to simply keep as-is, but document that there a known (but probably unlikely) way to get a spurious failure here
","[2016-04-01 16:59:28][Ismael Juma][issue:summary][KAFKA-3490:12955353]
To verify the performance impact of changes, it is very handy to be able to run ducktape performance tests across multiple Kafka versions. Luckily [~geoffra] has done most of the work for this."
Hive,SATD Duplication,"[2017-03-21 13:55:27][Sergey Shelukhin][code-comment][9f5a3e3d89db7d6f4754eb345ad9abb6997857e1]
 TODO: the memory release could be optimized - we could release original buffers after we
       are fully done with each original buffer from disk. For now release all at the end;
       it doesn't increase the total amount of memory we hold, just the duration a bit.
       This is much simpler - we can just remember original ranges after reading them, and
       release them at the end. In a few cases where it's easy to determine that a buffer
       can be freed in advance, we remove it from the map.
","[2017-03-21 01:52:55][Sergey Shelukhin][issue:comment][HIVE-16180:15933968]
Simplifying the release logic - we can just remember the buffers in the beginning. Could be simplified even more by removing all the early release."
Flink,No Relation,"[2019-11-07 08:50:51][Dawid Wysakowicz][code-comment][0b28e830d7366126a91ca9faa38cb19a8f66a9b6]
*
	 * Must be public as it is used during code generation.
","[2019-10-31 13:12:22][Dawid Wysakowicz][issue:comment][FLINK-13702:16963982]
I don't know exactly how the {{JoinedRow}} is used and therefore if the {{equals/hashCode}} is needed. Correct me if I am wrong but if we remove the {{equals/hashCode}} from {{BinaryGeneric}}, doesn't it mean that we can no longer use generic objects in a {{GroupBy}} clause, no? Isn't that a regression?

Edit: Ok I think the answer is that the key selector always uses {{BinaryRow}}, where the {{BinaryGeneric}} is written as bytes. You never compare the objects.

I would be in favor of removing the {{serializer}} from the {{BinaryGeneric}} then."
Lucene Solr,SATD Repayment,"[2020-04-14 16:48:01][David Smiley][code-comment][9b303b934e05a8af6880c66f1cb5c91c7c6e9e45]
 check for *:* is simple and avoids needless BooleanQuery wrapper even though BQ.rewrite optimizes this away
","[2020-04-06 21:00:44][dsmiley][pull:comment][1407:404385251]
I'll add a comment:
`// check for *:* is simple and avoids needless BooleanQuery wrapper even though BQ.rewrite optimizes this away`"
Attic Apex Malhar,No Relation,"[2014-08-03 00:12:58][Milinda Sreenath][code-comment][bec35e3c24b2b7486b9ca4d4f0ecddd3835f227d]
 TODO Auto-generated method stub
","[2014-08-03 00:12:58][Milinda Sreenath][commit][bec35e3c24b2b7486b9ca4d4f0ecddd3835f227d]
performance improved and benchmark added"
Servicecomb Java Chassis,SATD Repayment,"[2018-07-19 17:33:08][heyile][code-comment(deleted)][767d4a0c8ec1a0b41b2283df76abaf39dad1c089]
do not duplicate copy cse config to serviceComb config
","[2018-07-19 17:33:08][heyile][commit][767d4a0c8ec1a0b41b2283df76abaf39dad1c089]
do not duplicate copy cse config to serviceComb config when create local config"
Phoenix,SATD Duplication,"[2015-06-30 18:11:28][James Taylor][code-comment][84a17ce9f5513c04c8c75a50575896a8a0a74a56]
 Only tables may have views, so prevent the running of this potentially
 expensive full table scan over the SYSTEM.CATALOG table unless it's needed.
 In the case of a view, we allow a column to be dropped without checking for
 child views, but in the future we'll allow it and propagate it as necessary.
","[2015-06-18 03:19:46][Arun Kumaran Sabtharishi][issue:summary][PHOENIX-2050:12838664]
Whenever a view is dropped, MetaDataEndPointImpl.findChildViews() checks whether it has child views or not. This is doing a full scan in all the rows in SYSTEM.CATALOG which reduces performance. When the number of rows is very high, it causes timeout. The check has to be done only for the tables."
Qpid Dispatch,No Relation,"[2016-09-15 16:49:45][Ted Ross][commit][566a1a19e2c662b40aa4477421bddb51e4e7310c]
DISPATCH-511 - Cache-line align mutexes and conditions.  Remove extra assertions in mutexes.
","[2016-09-15 21:03:08][Ted Ross][issue:comment][DISPATCH-511:15494517]
Memory pool statistics are enabled by default.  If you wish to disable them for improved performance, use the following cmake definition:

cmake -DQD_MEMORY_STATS=OFF .."
Flink,No Relation,"[2018-08-03 19:40:24][Andrey Zagrebin][code-comment][ce96c409148d1a9bc40f581e13900818b5f11f6a]
* Return expired user value if it is not cleaned up yet.
","[2018-08-01 12:15:31][StefanRRichter][pull:comment][6460:206855467]
What I don't like about this line in particular is that it is a bit invasive and adds branching to an otherwise very tight loop, and I am not sure that this will simply be removed by the JIT. Can we do this in a way that does not involve filtering-calls if it is clear that no filtering is done, similar to the `NestedMapsStateTable`?

Overall, maybe we can keep in mind that there will be a unified format for the different state backends, and that probably will not start by writing a count. After that is introduced, we can also push the filtering right before the writing to the stream for a nice separation."
Lucene Solr,No Relation,"[2015-02-23 06:30:07][Erick Erickson][code-comment][230d24b43f6f57503ac3c26677290f0b607aad77]
 We expose the powerful $event object on the scope that provides access to the Window,
 etc. that isn't protected by the fast paths in $parse.  We explicitly request better
 checks at the cost of speed since event handler expressions are not executed as
 frequently as regular change detection.
","[2013-12-31 11:18:54][Upayavira][issue:comment][SOLR-5507:13859445]
I have a prototype of a complete rewrite, that shows the technology can create clean code even on something as complex as the analysis pane.

However, I'm stalled on the topic of how to manage a transition between the two technologies, without requiring a hard-switch between them, as that would likely be way too tough to manage.

So, we need to work out a way for the two technologies to play nicely together as an intermediate step - that's what I'm grappling with right now."
Flink,No Relation,"[2014-08-14 22:43:26][Stephan Ewen][commit][d0cead7e19ab4c580705799adb5ca460dd228809]
[FLINK-1053] Cleanup implementation of mapPartition function

This closes #42
","[2014-06-25 14:13:29][uce][pull:comment][42:47105893]
I think this will be a nice addition to the API.

Would it make sense to rename the operator to flatMapPartition? It might be confusing in relation to the existing map and flatMap functions. Map is a 1:1 mapping wheras a flatMap is the 1:n mapping. The new operator is called `mapParititons`, but is able to collect multiple elements."
Bookkeeper,No Relation,"[2016-12-13 08:16:38][sijie][pull:comment][89:92116194]
This flush here will do unnecessary flushes here.

A better algorithm here is:

- you should track the last piggyback lac update time.
- when the scheduled task is running, it should compare the last piggyback lac update time to see if piggyback lac update already elapsed more than the interval. if it is more than the interval, add the lac explicitly again.
","[2015-10-24 16:55:26][JV Jujjuri][issue:comment][BOOKKEEPER-874:14972708]
Sijie, I would like to request you to give another consideration

I just modeled it around ReadLastAddConfirmedOp() operation. This doesn't read anything other than getting LAC.
I looked around and following this model to add a new flag appears to be natural fit with minimum amount of code 
instead of adding completely new request."
Spark,SATD Repayment,"[2015-02-06 14:48:30][lianhuiwang][commit][61073f832128845a76469fc37376483b784c927b]
[SPARK-4994][network]Cleanup removed executors' ShuffleInfo  in yarn shuffle service

when the application is completed, yarn's nodemanager can remove application's local-dirs.but all executors' metadata of completed application havenot be removed. now it lets yarn ShuffleService to have much more memory to store Executors' ShuffleInfo. so these metadata need to be removed.

Author: lianhuiwang <lianhuiwang09@gmail.com>

Closes #3828 from lianhuiwang/SPARK-4994 and squashes the following commits:

f3ba1d2 [lianhuiwang] Cleanup removed executors' ShuffleInfo
","[2014-12-29 12:43:22][lianhuiwang][pull:summary][3828]
[SPARK-4994][network]Cleanup removed executors' ShuffleInfo  in yarn shuffle service"
Netbeans,No Relation,"[2020-07-20 21:33:58][Jan Lahoda][code-comment][7c9326139ffcd06e4e65130153e4a8a233eb6398]
        // if x11forwarding is set, but we consider it is unavailable,
        // we should at least allow switching it off => || serverRecord.getX11Forwarding()
        cbX11.setEnabled(serverRecord.isX11forwardingPossible() || serverRecord.getX11Forwarding());
","[2017-09-03 17:38:17][Daniel Gruno][issue:comment][INFRA-15006:16151875]
I believe this to be unnecessary, and I can't recall any project that has ever done or had to do this."
Incubator Pinot,No Relation,"[2020-09-29 21:16:34][Xiaotian (Jackie) Jiang][code-comment][009ab53d1943829803fe308205dd951be2caffcb]
 TODO: Remove the legacy delimiter after releasing 0.6.0
","[2020-09-29 00:41:07][siddharthteotia][pull:comment][6056:496310465]
Same as before. We should try to enhance the same code."
Ignite,SATD Repayment,"[2018-08-07 13:53:37][Ilya Kasnacheev][commit][de9227d7c5d69d9dcc5987e060937412bb8c22c9]
IGNITE-7615: Find orphaned tests without test suites, create separate test suite for them; IGNITE-8344: Remove duplicate tests and suites; IGNITE-8345: Streamline tests' class names: mark Abstract and Load tests obviously so; - Fixes #3464.

Signed-off-by: Dmitriy Pavlov <dpavlov@apache.org>
","[2018-02-02 12:47:47][Ilya Kasnacheev][issue:summary][IGNITE-7615:13135764]
Find orphaned tests without test suites, create separate test suite for them"
Cassandra,No Relation,"[2013-11-21 15:20:28][Jason Brown][commit][fdbddc13272bed6dfa3019e77acfb5f9107d6dce]
Batch read from OTC's queue and cleanup
patch by jasorown and belliotsmith for CASSANDRA-1632
","[2013-11-21 19:33:07][Jason Brown][issue:comment][CASSANDRA-1632:13829258]
v3 is based on [~jbellis]'s v2 patch, but removes the changes to PCLES and switches OTC's use of active.peek() to active.isEmpty()"
Arrow,SATD Repayment,"[2020-01-02 07:24:58][Kazuaki Ishizaki][commit][cec93999fdef8fe9c83e78ec9f9cc53f9341d71c]
ARROW-7482: [C++] Fix typos

This PR fixes typos in files under `cpp/src/arrow` directory

Closes #6110 from kiszk/ARROW-7482 and squashes the following commits:

b5dc3f012 <Kazuaki Ishizaki> fix lint errors
bb39903f4 <Kazuaki Ishizaki> address review comment
b291f2e01 <Kazuaki Ishizaki> fix lint errors
224796723 <Kazuaki Ishizaki> fix typo

Authored-by: Kazuaki Ishizaki <ishizaki@jp.ibm.com>
Signed-off-by: Sutou Kouhei <kou@clear-code.com>
","[2019-12-31 17:49:14][Kazuaki Ishizaki][issue:summary][ARROW-7482:13277039]
[C++] Fix typos"
Tinkerpop,SATD Duplication,"[2014-03-07 18:47:08][Stephen Mallette][code-comment][1afb4eb87c41e1f4e294de55656a60b058e39e11]
 todo: centralize kryo instance creation
 todo: need way to register custom types.
","[2014-03-07 18:47:08][Stephen Mallette][commit][1afb4eb87c41e1f4e294de55656a60b058e39e11]
Add todo reminders."
Flink,SATD Repayment,"[2012-04-11 13:18:52][Tommy Neubert][code-comment(deleted)][580254fee9c21ed450d494ec853b7312df5e2263]
 TODO find a way to reuse Primitives
","[2012-04-11 13:18:52][Tommy Neubert][commit][580254fee9c21ed450d494ec853b7312df5e2263]
naive way to reuse primitives in GeneralSchema; further commenting"
Incubator Mxnet,No Relation,"[2017-06-17 10:53:37][Yuwen Xiong][commit][ce2bca6e6847f54fc37a9c295e96f14f681ae2b9]
Add operators for Deformable ConvNets/DFF (#6298)

* Add operators for Deformable ConvNets/FCIS/DFF

* fix programming rule to meet pr rule

* fix programming rule to meet pr rule

* fix programming rule to meet pr rule

* minor fix channel operator

* minor fix deformable conv

* fix a stupid error

* add test code

* add test code

* remove channel operator and add gradient check

* remove redundant print

* fix unittest code

* dummy commit to trigger building check

* dummy commit to trigger building check

* Update deformable_convolution-inl.h

* Update deformable_im2col.h

* Update deformable_convolution.cc

* Update deformable_psroi_pooling.cc
","[2017-06-16 17:51:34][piiswrong][pull:comment][6298:122497881]
These docs seems to be copied from standard conv. Could you updated it to describe DeformableConvolution or remove inaccurate doc and insert a link to the original paper?"
Ignite,SATD Duplication,"[2017-10-24 11:41:07][dspavlov][pull:summary][2914]
IGNITE-6713: Ignite Cache 5 flaky test CacheRebalancingSelfTest.testD…
","[2017-10-23 14:02:28][Dmitry Pavlov][issue:summary][IGNITE-6713:13111423]
Ignite Cache 5 flaky test CacheRebalancingSelfTest.testDisableRebalancing()"
Airflow,SATD Repayment,"[2017-06-07 09:16:51][Bolke de Bruin][commit][4764646b18f56c34a35c19bd20a1931eb3a844fe]
[AIRFLOW-1166] Speed up _change_state_for_tis_without_dagrun

_change_state_for_tis_without_dagrun was locking a
significant
amount of tasks uncessarily. This could end up in
a deadlock
in the database due to the time the lock stood.

Closes #2267 from bolkedebruin/fix_deadlock
","[2017-05-02 20:26:20][bolkedebruin][pull:summary][2267]
[AIRFLOW-1166] Speed up _change_state_for_tis_without_dagrun"
Trafodion,No Relation,"[2016-11-10 13:07:14][Zalo Correa][code-comment][5175653088a34225f48843ac147dd60ee65efb19]
 third round, populate the ranges that this ESP needs to read
","[2017-05-30 19:02:47][Dave Birdsall][issue:comment][TRAFODION-2001:16029947]
I'm wondering how this change will affect development practices on workstations where we have used ""install_local_hadoop"".

For example, sometimes an instance will get messed up, and we want to throw it away and start clean. Today, I often use the script ilh_cleanhb 2 to throw away all the instance HBase files, and then ilh_traf_restart. The latter script does an sqgen. But it looks like sqgen can only be run once now? Has ilh_traf_restart been changed to take this into account?"
Flink,No Relation,"[2015-01-12 09:15:12][Ufuk Celebi][code-comment][d908ca19741bf2561cb6a7663541f642e60c0e6d]
 TODO We can just keep the serialized data in the Netty buffer and release it later at the reader
","[2014-12-09 18:55:22][StephanEwen][pull:comment][254:21552080]
I think that the `stringifyException` call is unnecessary and even hindering proper logging. I would remove it, construct a proper error message for the log and pass the exception as the second parameter."
Helix,No Relation,"[2020-06-09 12:30:36][Hunter Lee][commit][39bf0ad429660797d70a0a1b53a2105e4ec1cd50]
Deprecate Raw ZkClient in helix-core (#1070)

We have moved the raw ZkClient to zookeeper-api. As such, we need to deprecate the old one in helix-core. We are leaving the class for backward-compatibility purposes.
","[2020-06-07 05:21:36][narendly][pull:comment][1070:436326127]
On this point, I thought about it, but I decided to keep them separate because 1) It is less confusing - TestHelper solely provides methods around testing and TestNG, and ZkTestHelper provides methods related to ZK operations. 2) From the dev perspective, we get less confused (why are there 2 helpers in helix-core vs 1 helper in zookeeper-api?) and 3) it helps us keep the classes small."
Usergrid,No Relation,"[2014-01-27 15:21:53][Todd Nine][code-comment][80c4dddba900d647d7133d324b889ead759f76da]
 TODO(vojta): change params to: method, url, data, headers, callback
","[2014-07-25 19:22:26][rodsimpson][pull:summary][35]
Usergrid-100 added missing license headers to ios SDK"
Hudi,SATD Duplication,"[2020-06-30 04:51:24][hddong][pull:summary][1774]
[HUDI-703]Add unit test for HoodieSyncCommand
","[2020-03-12 14:28:39][hong dongdong][issue:summary][HUDI-703:13291338]
Add unit test for HoodieSyncCommand"
Tvm,No Relation,"[2020-09-18 11:37:13][Leandro Nunes][code-comment][292b640f1338317af6d90cc3f4e96f0bacde4ca4]
 TODO (@leandron) a new PR will introduce the 'tune' subcommand
      the is used to generate the tuning records file
","[2020-08-20 14:54:10][leandron][pull:comment][6302:474045263]
This is the output file (the log) from the tuning process, so that transfer learning can be used. I'll make that simpler to understand in the `help` description."
Flink,SATD Repayment,"[2019-02-19 14:05:11][azagrebin][code-comment][735b5141f14bc56a0c88d792b8413bcad42f0ce3]
* This determines if compaction filter to cleanup state with TTL is enabled.
","[2019-02-19 14:05:11][azagrebin][commit][735b5141f14bc56a0c88d792b8413bcad42f0ce3]
[FLINK-10471][State TTL] State TTL cleanup using RocksDb compaction filter

This closes #7163."
Hive,SATD Repayment,"[2017-06-09 14:46:11][Daniel Dai][commit][302360f51c2f6d93db244b6e67fc05517a654b2b]
HIVE-16323: HS2 JDOPersistenceManagerFactory.pmCache leaks after HIVE-14204 (Daniel Dai, reviewed by Thejas Nair)
","[2017-05-30 05:25:02][Thejas Nair][issue:comment][HIVE-16323:16028750]
This leak and also usage of syncMetaStoreClient seems to be from HIVE-14204 . Thats why I suggested it here.
We could track the syncMetaStoreClient.close() change in a separate jira as well, if you prefer that."
Helix,SATD Repayment,"[2020-07-15 12:11:23][Hunter Lee][commit][90840f48eb1ede6ace06a6b30cb0fe2dfd02a210]
Remove legacy duplicate metric classes in helix-core (#1147)

As part of ZooKeeper API separation initiative, most metric-related classes were moved to metrics-common module. However, there were some that were left in helix-core for backward-compatibility purposes, but these were causing class conflicts at runtime. This change removes such classes.
","[2020-07-14 04:18:13][narendly][pull:summary][1147]
Remove legacy duplicate metric classes in helix-core"
Cloudstack,No Relation,"[2015-11-29 01:44:22][pdube][pull:comment][1134:46086641]
It is actually unused in the api call. I will remove it.
","[2015-08-03 15:18:40][Ingo Jochim][issue:comment][CLOUDSTACK-6276:14651975]
﻿ ﻿Sehr geehrte Damen und Herren,
vielen Dank für Ihre E-Mail.
Ich bin zur Zeit außer Haus und habe limitierten Zugang zu meinen E-Mails. Am 10.08.2015
werde ich wieder im Haus sein und Ihre Nachricht bearbeiten.
In dringenden Fällen kontaktieren Sie bitte VGBITBITCloud@bautzen-it.de.
Mit freundlichen Grüßen,
Ingo Jochim"
Lucene Solr,SATD Repayment,"[2020-12-23 12:41:23][Dawid Weiss][commit][2d6ad2fee6dfd96388594f4de9b37c037efe8017]
LUCENE-9570: code reformatting [partial].
","[2021-01-05 11:50:29][Bruno Roustant][issue:comment][LUCENE-9570:17258851]
[~dweiss] Yes finally it's done. I pushed the commit directly to your branch.

I have been working on spatial3d since yesterday. 123 classes, with some giant ones. Ouch, it took me more time than anticipated.

Lots of (inconsistently) missing braces in a single-line if. I added them. I hope I didn't miss too many of them.

Many multi-line comments where the lines were truncated with a newline inserted. I had to reformat manually the comment.

Badly formatted commented code. Either line-truncated, or with original commented code had no space between concatenated strings (and I tried to add them as often as I could)

Lots of duplicated code to reformat again and again."
Hive,SATD Repayment,"[2018-12-06 10:51:05][Zoltan Haindrich][commit][8b968c7e46929c3af86da46e316faeb8d17f03df]
HIVE-20985: If select operator inputs are temporary columns vectorization may reuse some of them as output (Zoltan Haindrich reviewed by Teddy Choi)

Signed-off-by: Zoltan Haindrich <kirk@rxd.hu>
","[2018-11-29 16:35:02][Zoltan Haindrich][issue:summary][HIVE-20985:13201391]
If select operator inputs are temporary columns vectorization may reuse some of them as output"
Incubator Mxnet,No Relation,"[2018-02-15 14:44:34][Da Zheng][code-comment][c3e3a832bfeceff070ba263aa8a4489ca27f452e]
 MKLDNN ops may not support the case that the input and the output uses
 the same memory. Let's use an extra copy to make sure it always works.
","[2018-02-15 19:25:36][cjolivier01][pull:comment][9677:366034644]
There's only two out of 10-or-15-or-so tests that are disabled.  
I am fine with the merge from the point of the cpp tests.  Although it's possible there is something wrong, it's not clear if it's the test or the main code, so I agree with @piiswrong that if it's really broken, we will find out soon enough after it is merged.
Both tests are disabled for the same behavior."
Beam,SATD Duplication,"[2016-11-23 10:42:17][Davor Bonaci][code-comment][9b9d016c80b9a7e73a7485d3e579ead3ada18ac6]
 TODO(vikasrk): Figure out what other errors should be retried.
","[2016-11-22 07:36:00][chamikaramj][pull:comment][1398:89056210]
TODO: Figure out what other errors should be retried."
Hbase,No Relation,"[2011-10-13 23:12:30][Michael Stack][code-comment][8d8dc87d0dd1e6039866543b4dd75fdb273ac2d7]
 This is hacky.  Need to get the configuration into admin instance
","[2011-02-06 06:10:21][Michael Stack][issue:comment][HBASE-3446:12991106]
Moving out of 0.90.1.  I won't have time to spend testing this patch more before tomorrow evening, the cut-off point.  The patch looks to be working properly but I keep tripping over other issues that I have to follow to make sure this patch is not the cause."
Beam,SATD Repayment,"[2018-03-09 17:47:04][Robert Bradshaw][commit][2dcff0e7f47fe8bfb37346c78ebb9e19020f532a]
Merge pull request #4845 from robertwb/runner-cleanup

Remove obsolete MapTaskRunner.
","[2018-03-10 00:01:34][robertwb][pull:summary][4845]
Remove obsolete MapTaskRunner."
Arrow,SATD Duplication,"[2019-07-29 18:06:00][wesm][pull:summary][4963]
ARROW-6065: [C++][Parquet] Clean up parquet/arrow/reader.cc, reduce code duplication, improve readability
","[2019-07-29 18:03:35][Wes McKinney][issue:summary][ARROW-6065:13247718]
The code in parquet/arrow/reader.cc has quite a bit of code duplication and is difficult to follow. In the course of making some other improvements to this code I am going to reorganize and clean things up. PR coming shortly"
Hive,SATD Duplication,"[2017-10-03 16:35:14][Jesus Camacho Rodriguez][code-comment][073e8473ea61da995c42847ea53909e77f7e76f2]
 TODO: We have a cache for Table objects in SemanticAnalyzer::getTableObjectByName()
 We need to move that cache elsewhere and use it from places like this.
","[2017-09-13 21:46:56][ashutoshc][pull:comment][245:138748546]
We have a cache for Table objects in SemanticAnalyzer::getTableObjectByName() We need to move that cache elsewhere and use it from places like this. 
Could be a follow-up: Leave a TODO"
Spark,SATD Duplication,"[2017-07-17 10:07:32][Ajay Saini][code-comment][7047f49f45406be3b4a9b0aa209b3021621392ca]
 TODO: need to set metadata
","[2017-07-02 07:24:42][jkbradley][pull:comment][18428:125176253]
Leave a TODO indicating that we need to set metadata."
Incubator Mxnet,SATD Repayment,"[2019-08-29 10:37:11][Anirudh Subramanian][commit][649429d055e8ac89b2a45929ff2344959768a6e3]
Disable flaky test in test_amp_conversion (#16031)
","[2019-08-28 18:51:26][anirudh2290][pull:summary][16031]
Disable flaky test in test_amp_conversion"
Beam,SATD Repayment,"[2017-09-19 13:52:54][Eugene Kirpichov][code-comment(deleted)][e7eefddea925e9b5359468a74a5dffe75b4b55e7]
[BEAM-407] Inconsistent synchronization
","[2017-09-19 13:52:54][Eugene Kirpichov][commit][e7eefddea925e9b5359468a74a5dffe75b4b55e7]
This closes #3827: [BEAM-407] fixes inconsistent synchronization in OffsetRangeTracker.copy"
Kafka,SATD Repayment,"[2016-03-02 18:50:59][Gwen Shapira][commit][00a58f8e1e0c82c2948a8fdfacf812ec4865b339]
KAFKA-2944: Replaced the NPE with a nicer error and clean exit and added debug message to assist with figuring this out.

…ssage to assist with figuring this out.

Author: Gwen Shapira <cshapi@gmail.com>

Reviewers: Ewen Cheslack-Postava <ewen@confluent.io>

Closes #993 from gwenshap/KAFKA-2944
","[2016-03-02 03:46:46][gwenshap][pull:summary][993]
KAFKA-2944: Replaced the NPE with a nicer error and clean exit and added debug me…"
Nifi,No Relation,"[2015-11-18 23:23:10][Joseph Percivall][commit][1e5cc070a3d29736beea9af0b2d684a9bdcfff8e]
NIFI-1081 Adding option to ExecuteStreamCommand to put output value to an attribute

Reviewed and amended (comments,whitespace,and some code readability (discussed in ticket)) by Tony Kurc (tkurc@apache.org)
","[2015-11-13 16:03:22][Bryan Bende][issue:comment][NIFI-1081:15004175]
Just adding my two cents here, I think it will be much easier if we define a standard, probably similar to what Yetus has in the link Tony provided. Right now some of our tickets have a series of patches 1, 2, and 3 that need to be applied in that order, and others will have the same naming convention, but are full patches where only the third one is needed."
Geode,SATD Repayment,"[2016-02-05 16:39:57][Sai Boorlagadda][commit][57b8229d1905142d53d65d9eec8bde671262080c]
GEODE-891: improve DataType unit test coverage

* Added tests for missing cases
* Removed SQLF case

This closes #89
","[2016-02-05 19:21:54][sboorlagadda][pull:summary][89]
Geode 891: DataType needs better unit test coverage"
Spark,SATD Repayment,"[2020-11-30 13:59:51][Josh Soref][commit][485145326a9c97ede260b0e267ee116f182cfd56]
[MINOR] Spelling bin core docs external mllib repl

### What changes were proposed in this pull request?

This PR intends to fix typos in the sub-modules:
* `bin`
* `core`
* `docs`
* `external`
* `mllib`
* `repl`
* `pom.xml`

Split per srowen https://github.com/apache/spark/pull/30323#issuecomment-728981618

NOTE: The misspellings have been reported at https://github.com/jsoref/spark/commit/706a726f87a0bbf5e31467fae9015218773db85b#commitcomment-44064356

### Why are the changes needed?

Misspelled words make it harder to read / understand content.

### Does this PR introduce _any_ user-facing change?

There are various fixes to documentation, etc...

### How was this patch tested?

No testing was performed

Closes #30530 from jsoref/spelling-bin-core-docs-external-mllib-repl.

Authored-by: Josh Soref <jsoref@users.noreply.github.com>
Signed-off-by: Takeshi Yamamuro <yamamuro@apache.org>
","[2020-11-28 23:23:44][jsoref][pull:summary][30530]
[MINOR] Spelling bin core docs external mllib repl"
Incubator Pinot,SATD Repayment,"[2018-09-27 18:39:45][Xiaotian Jiang][commit][e5ec0f9cdf60b341fd2373da12420c89367e19a2]
Simplify the parameter for forward index creators (#3208)

Also move method getNumBitsPerValue() into PinotDataBitSet and re-implement it without using double
","[2018-09-21 00:50:00][Jackie-Jiang][pull:summary][3208]
Simplify the parameter for forward index creators"
Drill,No Relation,"[2017-06-21 10:02:16][Paul Rogers][code-comment][90f43bff7a01eaaee6c8861137759b05367dfcf3]
*
 * Light-weight sanity test of the copier class. The implementation has
 * been used in production, so the tests here just check for the obvious
 * cases.
 * <p>
 * Note, however, that if significant changes are made to the copier,
 * then additional tests should be added to re-validate the code.
","[2017-05-19 01:01:28][Ben-Zvi][pull:comment][808:117385660]
A little confusing: ""there is no way to run just the secondary tests from Maven"", but above (line 51) it says: ""to run the secondary tests .... mvn ......"" . Does this mean that the above form (line 52) runs both the primary and the secondary tests ?"
Netbeans,No Relation,"[2017-10-02 06:06:59][jlahoda][pull:comment][7:333447910]
Description of the current -license.txt processing is here:
http://wiki.netbeans.org/DevFaqExternalLibraries

I think details under Apache are still somewhat unclear, but I think maintaining -license.txt and -notice.txt (if needed) in the library wrapper near the external library is much more maintainable than trying to have a central registry, and that whatever we do will be based on the current design/state. So, I think it would be good to have things prepared for automatic processing as much as possible.

Thanks.
","[2017-09-05 16:32:02][Craig L Russell][issue:comment][NETBEANS-54:16153933]
Option a is what all newly incubating projects do as part of due diligence IP Clearance. The only difference here is the size of the grant. 

I agree with Gj that the process for determining which of the files is suitable for Apache Netbeans is under way and needs to be documented here and followed."
Drill,SATD Repayment,"[2017-10-20 16:52:34][Parth Chandra][commit][d2e3dd95a55ffadc0ac2f1e90c4ba6fd43346d8b]
DRILL-5873: (C++ Client) Improve SASL error reporting.

This closes #992
","[2017-10-13 22:05:37][parthchandra][pull:summary][992]
DRILL-5873: (C++ Client) Improve SASL error reporting."
Hbase,SATD Repayment,"[2019-06-08 20:25:31][syedmurtazahassan][commit][b32e716bee03ce5a2eca1d5b908f71a7bd9399c7]
HBASE-22481 Javadoc Warnings reference not found
","[2019-05-27 09:32:13][Murtaza Hassan][issue:summary][HBASE-22481:13235770]
Javadoc Warnings: reference not found"
Airflow,SATD Repayment,"[2019-06-28 17:01:48][Xiaodong][commit][b30f0fa9f2ef0cf0b00b0cbc047e3e01318becc6]
[AIRFLOW-3935] answer a TODO in airflow/executors/local_executor.py (#4752)

To answer why 'raise e' was commented:
1. This try-except is inside method execute_work() & there are other operations
   after the try-except and after invoking this method.
   Raising exception here will prevent all following steps from taking place.
2. The exception itself is already marked properly by labelling state to be FAILED,
   and the exception is printed out using self.log.error().
","[2019-02-21 14:15:31][XD-DENG][pull:summary][4752]
[AIRFLOW-3935] answer a TODO in airflow/executors/local_executor.py"
Camel,No Relation,"[2020-07-28 08:50:29][Andrea Cosentino][code-comment][120a76fb11cd62f659e645541f25ec1ef89cecd5]
*
         * Setting the autoDiscoverClient mechanism, if true, the component will
         * look for a client instance in the registry automatically otherwise it
         * will skip that checking.
         * 
         * The option is a: <code>boolean</code> type.
         * 
         * Default: true
         * Group: common
","[2020-07-18 17:02:17][Christophe Willemsen][issue:summary][CAMEL-15310:13317565]
The `amazonS3Client` query parameter takes the key of the bean in the registry as argument, however that key is not used.

 

Actually, today the component supports *ONLY* having 1 bean of type AmazonS3 in the registry, the following method in the S3Component shows it : 

 

 
{code:java}
private void checkAndSetRegistryClient(S3Configuration configuration) {
    Set<AmazonS3> clients = this.getCamelContext().getRegistry().findByType(AmazonS3.class);
    if (clients.size() == 1) {
        configuration.setAmazonS3Client((AmazonS3)clients.stream().findFirst().get());
    }

}
{code}"
Lucene Solr,No Relation,"[2017-04-29 20:39:50][Jan Høydahl][commit][61f64829d84d5a6b8c8bdff0e1a1f32c5e0a86f6]
SOLR-7041: Remove a lot of defaultOperator and defaultSearchField from test configs (still more work to do)
","[2015-01-27 10:53:38][Jan Høydahl][issue:comment][SOLR-7041:14293346]
I see the two used in a bunch of test-schemas. Also, the methods {{getDefaultSearchFieldName()}} and {{getQueryParserDefaultOperator()}} in {{IndexSchema.java}} are *not* deprecated in current trunk.

If we don't take the time to rip it all out for 5.0, I propose we
* remove the commented-out parts from example schemas
* deprecate the two methods in IndexSchema
* remove mentions in RefGuide
* start logging a WARN if schema parser finds any of these in use

Another in-between option is to fail-fast if {{luceneMatchVersion >= 5.0}} and log warning if less (indicates people brought their old config)."
Jena,SATD Repayment,"[2016-08-04 10:57:01][Andy Seaborne][code-comment][52efaadb4689444470ebf6ab3f63cb526cac7212]
*
     * Switch off logging setting. 
     * Used by the embedded server so that the application's
     * logging setup is not overwritten.
","[2016-08-04 09:47:47][Andy Seaborne][issue:summary][JENA-1220:12994846]
Improve the logging setting so that:

Take logging setup out of initialization of the Fuseki code system

Logging is set by the standalone server in the command line setup. Then ensure logging is in {{FusekiServerEnvironmentInit}}, the ServletContextListener which is where it is triggered for the WAR file if the webapp container has not already set it up.

If using Fuseki without the webapp, i.e. in an embedded mode, do not set logging and rely on the application to have set slf4j along with the rest of Jena."
Lucene Solr,No Relation,"[2020-01-10 04:09:44][dsmiley][pull:comment][1151:365065931]
Compared to other TPIs, I think 3f is too low.  For example DVTQ (in the superclass) is 3f but we also must call advanceExact on the top level DV.  I suggest 10f.  It's a bike-shed number but I just want more than 3 and much less than 100 which is what some of the no-idea but probably expensive TPIs have.
","[2019-12-23 18:08:34][Joel Bernstein][issue:comment][SOLR-13890:17002416]
I dug into this pretty deeply and I believe there is a large advantage to the top level doc values approach when there is a large number of terms. The reason is that *MultiSortedSetDocValues.lookupOrd*  (in MultiDocValues) is really clever, so the overhead of doing the top level term lookup is much less than doing the segment by segment term lookups. Using the top level ordinals inside of the scorer would be possible also but seemed kind of awkward. But, in theory using top level ordinals in the scorer would get similar performance as this patch."
Hbase,No Relation,"[2013-04-04 17:21:14][larsh][code-comment][fff96309a6816f4769024c10014cff57ec91f7a2]
 sleep for 1s to give the ZK change a chance to reach the watcher in the observer.
 TODO: Better to wait for the data to be propagated
","[2013-04-03 22:28:11][Ted Yu][issue:comment][HBASE-8259:13621424]
Nice catch.
{code}
+    // and not the value specified in the enum definition. so we can't add stuff in the middle.
+    C_M_SNAPSHOT_TABLE        (48),   // Client asking Master to snapshot an offline table
+    C_M_RESTORE_SNAPSHOT      (49);   // Client asking Master to snapshot an offline table
{code}
Should the numeric values for the above two enum's be increased after the movement ?

I understand the numeric values (48, 49 currently) are not used. The question is just for readability."
Tinkerpop,SATD Duplication,"[2014-01-22 11:12:56][Stephen Mallette][code-comment][c82b1e3d7982076d47394873b6c2a7b896ab4203]
 TODO: need GraphComputer.Exceptions consistency checks
","[2014-01-22 11:12:56][Stephen Mallette][commit][c82b1e3d7982076d47394873b6c2a7b896ab4203]
Add todo for consistency checks for GraphComputer exceptions."
Systemds,SATD Repayment,"[2016-05-03 22:55:27][Deron Eriksson][commit][f9d10cfba029a7e2418bc4c0b57b06f2d7495efa]
[SYSTEMML-648] Deprecate castAsScalar

Add castAsScalar deprecation warnings.
Add Expression javadocs.
Remove unused enums from Expression.
Display parse warnings if they occur without parse errors.
Don't chain ParseException in JMLC Connection.

Closes #130.
","[2016-04-27 23:47:47][deroneriksson][pull:summary][130]
Add castAsScalar deprecation warnings.
Add Expression javadocs, rename cast enum values.
Remove unused enums from Expression.
Display parse warnings if they occur without parse errors.
Don't chain ParseException in JMLC Connection."
Accumulo,SATD Repayment,"[2018-08-28 15:44:40][Christopher McTague][commit][aaa1c0c82f58b5047b9146d1a0adf007cdb75c0c]
Spelling corrections in comments/javadocs (#620)
","[2018-08-28 18:48:00][cjmctague][pull:summary][620]
Spelling corrections in comments/javadocs"
Hadoop,SATD Duplication,"[2016-08-08 15:16:14][Wei-Chiu Chuang][code-comment][cc20316b55ee108ccd880e8fb0565eacae2b90bd]
 The UNAUTHORIZED will trigger cache invalidation, which then triggers
 the aggregated OK (accessCount=5). But the order of the UNAUTHORIZED and
 the aggregated OK is arbitrary - no correctness concerns, but flaky here.
","[2016-07-26 07:18:30][Xiao Chen][issue:comment][HADOOP-13395:15393346]
Patch 2 fixes checkstyle warnings (except the >80 chars ones, which in this test I think is better to read).

Fixed the flaky {{testAggregationUnauth}}:
{{KMSAudit}} utilizes a removal listener to aggregate the same logs ({{OK}} ones in the test), and an {{UNAUTHORIZED}} log will invalidate the aggregation cache. Whether the {{UNAUTHORIZED}} entry or the aggregated {{OK}} log appear first solely depend on the run time -  after {{cache.invalidate(cacheKey)}}, whether the {{AUDIT_LOG.info}} executes first, or the removal listener's log executes first.

Fixed the unit test by verifying either scenario happened. The goal of the test is to check aggregation stops after {{UNAUTHORIZED}}, which is checked via the last {{OK}} message."
Drill,SATD Repayment,"[2015-02-11 18:35:51][Aman Sinha][code-comment][ca28b9cba419702a58cbce43b31a9d731d824377]
 Use max cost of all operators in this fragment; this is consistent with the
 calculation that ExcessiveExchangeRemover uses
","[2015-02-11 18:35:51][Aman Sinha][commit][ca28b9cba419702a58cbce43b31a9d731d824377]
DRILL-2170: For fragment parallelization, use max cost of operators instead of total cost (this makes it consistent with what ExcessiveExchangeRemover  uses)."
Activemq Artemis,No Relation,"[2018-09-26 09:19:40][Timothy Bish][code-comment][a851a8f93f30972d252f2bff0bb3d5847cfd7b5f]
----- Test that message decode ignores unused sections ------------------//
","[2018-09-26 09:19:40][Timothy Bish][commit][a851a8f93f30972d252f2bff0bb3d5847cfd7b5f]
ARTEMIS-2096 Refactor AMQMessage abstraction

Major refactoring of the AMQPMessage abstraction to resolve
some issue of message corruption still present in the code and
improve the API handling of message changes and re-encoding.

Improves handling of decoding of message sections limiting the
work to only the portions needed and ensuring the state data
is always updated with what has been done.  Fixes issues of
corrupt state on copy of message or other changes in filters."
Hadoop,SATD Repayment,"[2017-08-01 17:28:21][Subru Krishnan][commit][083a05bc1420d6d6aa30d98ab48c2ed8ead5b810]
YARN-5634. Simplify initialization/use of RouterPolicy via a RouterPolicyFacade. (Carlo Curino via Subru).

(cherry picked from commit d7672ce2bddb40fbaa77d3f6fec8c99f5589177f)
","[2016-09-10 00:16:35][Carlo Curino][issue:summary][YARN-5634:13004015]
Simplify initialization/use of RouterPolicy via a RouterPolicyFacade"
Drill,SATD Repayment,"[2014-08-06 16:44:22][Hanifi Gunes][commit][28fbdad886583bc7193833abb06deea327ec8fbe]
DRILL-1202: fixes memory leak issues: i) ProducerConsumerBatch should clean up resources ii) FragmentExecutor should clean up gracefully at faulty & non-faulty runs regardless
","[2014-07-28 00:31:18][Steven Phillips][issue:summary][DRILL-1202:12730102]
ProduceConsumer operator causing memory leaks"
Lucene Solr,No Relation,"[2012-07-30 22:15:06][Michael McCandless][code-comment][94aecff6c33affad2795f0ffc18f58deb0825e39]
 vInt encode the remaining doc deltas and freqs:
","[2012-08-08 13:53:33][Han Jiang][issue:comment][LUCENE-3892:13431117]
And result on skipMulitiplier, use current 8 as the baseline: http://pastebin.com/TG4C6u6S
Somewhat noisy, but or-queries benifit a little when skipMultiplier=32.
And results when we set blockSize fixed to 64: http://pastebin.com/FQBiKGim"
Incubator Doris,No Relation,"[2020-01-16 14:39:08][LingBin][code-comment][d0e2fc33059020009eff92413b784bc9fe9c0151]
 TODO: why need to catch these signals, should leave a comment
 Return result to FE
","[2020-01-16 14:39:08][LingBin][commit][d0e2fc33059020009eff92413b784bc9fe9c0151]
Remove resource_info related members from TaskWorkerPool (#2704)

The `TResourceInfo` was used to help `cgruops` to isolate resources,
but it is no longer used.

In fact, the `TResourceInfo` information is no longer carried in
the requests from FE to BE."
Carbondata,SATD Repayment,"[2017-04-06 10:21:41][ravipesala][commit][4a7adfa97ae62ea946a1111101f5ae9b2148e76f]
[CARBONDATA-870] Folders and files not getting cleaned up created locally during data load operation. This closes #735
","[2017-04-05 13:44:54][Manish Gupta][issue:summary][CARBONDATA-870:13061745]
Folders and files which are created in local temp store location during data load and insert into operations are not getting cleaned up. After some time this will lead to filling up of local disk space and eventually will lead to data load failure if threshold limit is reached.
For this all the folders and files created locally need to be deleted once the operation is completed."
Samza,SATD Duplication,"[2017-04-05 16:42:15][Prateek Maheshwari][code-comment][4bf8ab6ebdf95cdf78f07b81a3b450a7f3fd9d45]
 TODO: SAMZA-1148 - Cast to appropriate input (key, msg) types based on the serde before applying the msgBuilder.
","[2017-03-31 18:04:16][prateekm][pull:comment][92:109217811]
No, this is intentional. I'd prefer to not access RuntimeEnvironment in the SamzaContainer/StreamProcessor at all. It'd be much cleaner IMHO if the Systems themselves only interacted with rest of the Container in terms of logical streamIds, at least for the high-level StreamApplications. That way the only logical to physical binding would happen in the RuntimeEnvironment layer. We can revisit this discussion when we start working on SAMZA-1118."
Ozone,SATD Duplication,"[2019-12-06 05:47:49][bharatviswa504][pull:summary][319]
## What changes were proposed in this pull request?

Remove Ratisclient from OM, now we use ratis server API's

## What is the link to the Apache JIRA

https://issues.apache.org/jira/browse/HDDS-1991

## How was this patch tested?

Cleanup code, Test will be from CI run
","[2019-08-19 21:16:00][Bharat Viswanadham][issue:summary][HDDS-1991:13251698]
In OM, we use ratis server api's to submit request. We can remove the RatisClient code from OM, which is no more used in submitting requests to ratis."
Nifi,No Relation,"[2018-03-15 15:10:41][Mark Payne][commit][844da063442c1819457108ff872881277c0e8e54]
NIFI-4849: Implemented REST Endpoint and associated backend code to generate a Diagnostics Report for a Processor
Implemented review feedback. Refactored data model to make the API cleaner and delineate more along the lines of what permissions are required in order to see which details
Implementing review feedback
Removed sensitive information from the diagnostics reports
Fixed bug in merging logic for GCDiagnosticsSnapshots
This closes #2468
","[2018-03-13 14:02:43][mcgilman][pull:comment][2468:174141284]
We use processorDiagnostics for the DTO name, can we update this one to be processorDiagnosticsEntity to be more consistent with other entities. I believe this name is important for folks consuming the swagger.json like nipy-api."
Trafficserver,No Relation,"[2020-09-01 10:32:58][Brian Neradt][code-comment][4e375331c9bc0e9e3955fd15f11b8c352ab2afb0]
* Perform more simplified parsing that is resilient to receiving regular
   * expressions.
   *
   * This simply looks for the first '/' in a URL and considers that the end of
   * the authority and the beginning of the rest of the URL. This allows for
   * the '?' character in an authority as a part of a regex without it being
   * considered a query parameter and, thus, avoids confusing the parser.
   *
   * This is only used in RemapConfig and may have no other uses.
","[2020-08-25 20:41:11][SolidWallOfCode][pull:comment][7119:680258809]
I spent quite a bit of time reviewing and pondering, and I think this is the best option at this point in time. Doing better would require far more substantial changes, as @bneradt notes in some of the comments."
Incubator Pagespeed Ngx,SATD Repayment,"[2014-08-14 11:34:50][Jeff Kaufman][commit][d00911b00f93f75ce1c67690e60b9e925be974a0]
Merge pull request #775 from pagespeed/jefftk-clearer-test-flake-error

testing: make it clearer why test flake in Issue #774 happens
","[2014-08-13 17:53:57][jeffkaufman][pull:summary][775]
testing: make it clearer why test flake in Issue #774 happens"
Fluo,SATD Repayment,"[2014-12-04 12:38:42][Mike Walch][commit][c9bb1761242e0788e5d1fd939d859c1d6793df65]
Merge pull request #358 from mikewalch/fluo-348

Closes #348 - Clean up ScannerConfiguration and create unit test
","[2014-12-02 13:14:14][mikewalch][pull:summary][358]
Closes #348 - Clean up ScannerConfiguration and create unit test"
Kafka,No Relation,"[2017-11-28 09:37:27][Guozhang Wang][code-comment][5df1eee7d689e18ac2f7b74410e7a30159d3afdc]
 TODO: this is going to be replaced by AdminClient
","[2017-11-21 16:21:32][bbejeck][pull:comment][4224:152326556]
nit: this looks a little awkward IMHO, maybe add a method to `InternalTopologyBuilder`  sth like `ensureCanBuildTopology` although I don't like that name and don't have a better suggestion atm.  EDIT: Only if this would not require a KIP or a change to the current KIP."
Druid,SATD Repayment,"[2013-09-13 13:21:03][cheddar][commit][ef1ac46a7ebe69d916fe840cdc73b3087009f5b9]
Merge pull request #237 from metamx/is-ut

Rework tests in indexing service to be more unit testy
","[2013-09-12 23:39:39][fjy][pull:summary][237]
Rework tests in indexing service to be more unit testy"
Lucene Solr,SATD Repayment,"[2016-03-02 09:22:20][Steve Rowe][commit][9427b7402da33cccff9692bb4d7146dad4bb16e1]
SOLR-8764: Remove deprecated methods and classes
","[2016-03-01 03:03:12][Steven Rowe][issue:summary][SOLR-8764:12945714]
Remove all deprecated methods and classes from master prior to the 6.0 release"
Tvm,SATD Duplication,"[2017-12-24 19:09:57][Lianmin Zheng][code-comment][5d37be6259658ce7b47ab2eea79cba999d241041]
 The assignment below introduces side-effect, and the resulting value cannot
 be reused across multiple expression, thus a new scope is needed
","[2017-12-19 14:16:35][tqchen][pull:comment][711:157765369]
add a comment:

The assignment introduces side-effect, and the resulting value cannot be reused across multiple expression, thus a new scope is needed"
Hbase,SATD Repayment,"[2017-11-02 21:29:20][Sean Busbey][commit][e79a007dd9810b33cd508986037e17d45b55a705]
HBASE-18784 if available, query underlying outputstream capabilities where we need hflush/hsync.

* pull things that don't rely on HDFS in hbase-server/FSUtils into hbase-common/CommonFSUtils
* refactor setStoragePolicy so that it can move into hbase-common/CommonFSUtils, as a side effect update it for Hadoop 2.8,3.0+
* refactor WALProcedureStore so that it handles its own FS interactions
* add a reflection-based lookup of stream capabilities
* call said lookup in places where we make WALs to make sure hflush/hsync is available.
* javadoc / checkstyle cleanup on changes as flagged by yetus

Signed-off-by: Chia-Ping Tsai <chia7712@gmail.com>
","[2017-11-02 20:16:56][Sean Busbey][issue:comment][HBASE-18784:16236513]
-2

  - clean up test-compile failure
  - couple more javadoc warnings."
Carbondata,No Relation,"[2018-06-20 15:12:22][xuchuanyin][commit][dc53dee2448f366319764021d77c4be75d43b9e3]
[CARBONDATA-2420][32K] Support string longer than 32000 characters

Add a property in creating table 'long_string_columns' to support string columns that will contains more than 32000 characters.
Inside carbondata, it use an integer instead of short to store the length of bytes content.

Internally in Carbondata,

add a new datatype called varchar to represent the long string column
add a new encoding called DIRECT_COMPRESS_VARCHAR to the varcher column page meta
use an integer (previously short) to store the length of bytes content.
add 2GB constraint for one column page

This closes #2379
","[2018-06-20 09:53:48][xuchuanyin][pull:comment][2379:398692719]
Currently the long_string_columns does not support complex datatypes. Carbondata will support it later in CARBONDATA-2620"
Gobblin,SATD Repayment,"[2018-01-09 13:56:25][Hung Tran][code-comment][fbf7c9bbd23ef310f3107bcc13dc16a1b37234be]
 check that workunit and taskstate directory for the job are cleaned up
","[2018-01-09 13:56:25][Hung Tran][commit][fbf7c9bbd23ef310f3107bcc13dc16a1b37234be]
[GOBBLIN-363] Clean up the job-level subdir in the _taskstate directory in Gobblin Cluster after a job is done

Closes #2234 from
htran1/cluster_task_state_cleanup"
Trafficcontrol,No Relation,"[2019-12-16 13:42:18][Jackie Heitzer][commit][811d65d25f1a0ee074085576e42bb25d5d4ebde1]
Fixes #3813 implement `/profiles/name/{{name}}/copy/{{fromName}}` in Go (#4204)

* Fixes #3813 implement `/profiles/name/{{name}}/copy/{{fromName}}` in Go

other minor changes on the files touched

* fixing a few typos

* fixing a typo an err returned
","[2019-08-06 15:05:38][ocket8888][issue:summary][3813]
## I'm submitting an ...
improvement request (usability, performance, tech debt, etc.)

## Traffic Control components affected ...
- Documentation (possibly)
- Traffic Ops

## Current behavior:
`/profiles/name/{{name}}/copy/{{fromName}}` is handled by Perl

## Expected / new behavior:
`/profiles/name/{{name}}/copy/{{fromName}}` should be handled by Go.

### Minimum API Version
1.1

### Request Methods
- [x] `POST`

## Minimal reproduction of the problem with instructions:
N/A"
Lucene Solr,No Relation,"[2018-08-29 10:02:09][David Smiley][commit][5a0e7a615a9b1e7ac97c6b0f9e5604dcc1aeb03f]
SOLR-12519: child doc transformer can now produce a nested structure.
Fixed SolrDocument's confusion of field-attached child documents in addField()
Fixed AtomicUpdateDocumentMerger's confusion of field-attached child documents in isAtomicUpdate()
","[2018-07-19 10:44:59][mosh][issue:comment][SOLR-12519:16549116]
 
{quote}See org.apache.solr.search.join.BlockJoinParentQParser#getCachedFilter for a clue.
{quote}
That sounds like the next thing on my todo list, right after implementing the filtering using Lucene iterations we have discussed prior.

BTW,
 I have just pushed to the WIP pull request, I have made some progress and it is starting to get there."
Iceberg,SATD Duplication,"[2020-08-05 13:46:32][Jingsong Lee][code-comment][fc5e3e5bbde66f0d5c66c4d980d47b9fd1f19f63]
 TODO add AVRO once the RowDataWrapper are ready.
","[2020-08-05 04:22:59][JingsongLi][pull:comment][1232:465463522]
Removed this and add comment:
`TODO add AVRO once the RowDataWrapper are ready.`"
Nifi,No Relation,"[2016-06-01 20:55:17][mosermw][pull:comment][444:65440697]
I examined the content of each output FlowFile.  The first and third look fine, but the second FlowFile had a trailing newline even though the dreaded REMOVE_TRAILING_NEWLINES defaults to ""true"".
","[2016-03-18 15:26:52][Mark Bean][issue:comment][NIFI-1118:15201629]
The proposed change effectively removes a feature, the Remove Trailing Newlines. The property Remove Trailing Newlines is still present, but the user will be forced to set it to false; there is no functionality behind it. The currently existing bug(s) with this features are not fixed. Rather, the poorly functioning feature is simply not available and therefore the bugs are no longer present."
Attic Apex Malhar,SATD Duplication,"[2013-09-18 10:28:42][Pramod Immaneni][code-comment][a960186f46cb15153159df902e6e940461ce67a5]
 This parsing code will be handled by API in future in a manner that is transparent to the
 user and should not be relied upon
 This composing code will be handled by API in future in a manner that is transparent to the
 user and should not be relied upon
","[2013-09-18 10:28:42][Pramod Immaneni][commit][a960186f46cb15153159df902e6e940461ce67a5]
Added comments that the web socket message parsing and composing will be available from API and the users should not rely on the code that is doing it currently in the library #54."
Tvm,No Relation,"[2020-05-21 09:39:14][Samuel][commit][019da5dae15d2bd13536673ab689203c799629f0]
[TUTORIAL]TFLite QNN Tutorial (#5595)

* [TUTORIAL]TFLite QNN Tutorial

* Review comments
","[2020-05-14 17:38:23][anijain2305][pull:comment][5595:425316098]
Can you please add a comment about ARM tuning here? It is more likely that TVM user interested in this tutorial is looking to run on ARM device."
Incubator Pinot,SATD Repayment,"[2017-02-27 12:05:51][Xiaotian Jiang][commit][c7ba84212aca0ff5c0d07d95c9529bef65707932]
Fix a typo inside RangeMergeOptimizer (#1094)

Added unit test for the typo.
","[2017-02-27 19:19:31][Jackie-Jiang][pull:summary][1094]
Added unit test for the typo."
Myfaces Tobago,SATD Repayment,"[2014-03-05 18:39:25][Udo Schnurpfeil][commit][754426b47430927dd8f5b8ae895054bb6086f4d9]
TOBAGO-1373 - Better JavaScript logging: using browser console and fill browser gaps.
","[2014-03-03 08:33:29][Udo Schnurpfeil][issue:summary][TOBAGO-1373:12698374]
Better JavaScript logging: using browser console and fill browser gaps."
Hawq,SATD Repayment,"[2018-03-14 18:23:19][interma][commit][a1acf9638b9834424718349aa8c75f21a614f1fe]
HAWQ-1594. Memory leak in standby master (gpsyncagent process)
","[2018-03-14 03:09:49][Hongxu Ma][issue:summary][HAWQ-1594:13144918]
In a high workload scenario, the gpsyncagent process of standby master consumes memory continuously until restart it.

There are some Memory leak happened."
Ignite,SATD Duplication,"[2018-06-08 14:37:28][alex-plekhanov][pull:summary][4159]
IGNITE-8529 Implement testing framework for checking WAL delta records consistency
","[2018-05-18 10:45:44][Ivan Rakov][issue:summary][IGNITE-8529:13160314]
Implement testing framework for checking WAL delta records consistency"
Incubator Brooklyn,SATD Duplication,"[2014-11-10 15:59:33][Aled Sage][code-comment][3cfda7e8ffd573dc1144c47f954f0350973b9e3d]
 Bad to leak a ref to this before constructor finished, but we'll live with it because
 it's just test code!
","[2014-11-10 11:42:01][aledsage][pull:comment][310:20077403]
It was for another test to sub-class it, so that the `getMutableEvents()` returns a `static` events field. Thus we could test the instance that was created reflectively (whose class was defined in `brooklyn.properties`).

I've changed this for the static instance to just record a reference to the listener instances, rather than relying on `getMutableEvents()`. The test-logic therefore doesn't leak into the other class as much."
Hive,No Relation,"[2016-11-18 08:17:39][Ferdinand Xu][code-comment][936df7a15a3ce323300cabe7b2ebb90e22f2069d]
 this should never happen.
 provide a good error message in case there's a bug
","[2016-11-02 23:44:51][sunchao][pull:comment][104:86266538]
We can check this at the beginning to avoid unnecessary batch reset"
Cloudstack,No Relation,"[2013-11-21 07:56:47][Alex Huang][code-comment(deleted)][433a6319160242af954275b6fe02820fb3c77996]
*
   * Set to true to print debugging messages.
","[2013-11-21 07:56:47][Alex Huang][commit][433a6319160242af954275b6fe02820fb3c77996]
Reformat of source code to set a stable base for the future.  I couldn't get checkstyle enabled.  There's still about a thousand errors from checkstyle.  Most of it from length errors from comments and strings.  Will attempt to remove those tonight.  This change is so large I just want to get it in before any merge nightmares.  The changes are fairly minor though and I did a full compile and start a server with the reformat code."
Flink,SATD Repayment,"[2018-02-01 13:54:57][Stephan Ewen][code-comment][31e97e57ceeaf37264ab6db078552b73ee5121bf]
*
	 * Tests that the file state handle does not attempt to check and clean up the parent directory.
	 * Doing directory contents checks and cleaning up the parent directory in the state handle disposal
	 * has previously led to excessive file system metadata requests, which especially on systems like
	 * Amazon S3 is prohibitively expensive.
","[2018-02-01 13:54:57][Stephan Ewen][commit][31e97e57ceeaf37264ab6db078552b73ee5121bf]
[FLINK-8540] [checkpointing] FileStateHandles no longer attempt to clean up their parent directory.

Performing directory contents checks and cleaning up the parent directory in the state handle disposal
has previously led to excessive file system metadata requests, which especially on systems like
Amazon S3 is prohibitively expensive."
Beam,No Relation,"[2018-01-19 21:03:17][aaltay][pull:comment][4376:162731473]
perhaps rename this to `lint3` `lint_py3` or something similar. 2 might be confusing.
","[2018-01-09 22:45:48][Holden Karau][issue:summary][BEAM-3444:13129692]
Fix flake8 detected errors E999 (AST compile error)"
Arrow,No Relation,"[2020-03-02 15:00:49][Antoine Pitrou][code-comment][24ce242516c74138a280c58c7fb074c8c2de7c5a]
/ Move the C schema from `src` to `dest`
/
/ Note `dest` must *not* point to a valid schema already, otherwise there
/ will be a memory leak.
","[2020-02-26 09:41:28][pitrou][pull:comment][6483:384376286]
Well, it doesn't hurt to keep the argument either, and it's more flexible."
Hbase,No Relation,"[2018-02-22 09:40:20][Josh Elser][commit][4cf846d08570256115ac8c2787d0f7fbf162be23]
HBASE-20035 Stabilize the flaky TestQuotaStatusRPCs

The test will fail if the quota moves to violation before
the second half of the test.

Signed-off-by: Michael Stack <stack@apache.org>
","[2018-02-21 16:05:16][Josh Elser][issue:comment][HBASE-20035:16371588]
Looks to me like the MasterQuotaManager isn't getting initialized (given the Master also never does so). The test is ultimately waiting 30s for the presence of the hbase:quota table and some data which should be written in there.

Will try to look at the logs today and see if anythign else jumps out at me. Else, I can try to make some logging changes for the future."
Trafodion,SATD Repayment,"[2019-10-02 19:29:26][Selvaganesan Govindarajan][commit][520c8ea3808867b8c22547f6240cc507e53078be]
Merge pull request #1859 from selvaganesang/t2_driver_cleanup_1

[TRAFODION-3329] Code cleanup in Type 2 driver
","[2019-10-02 22:22:01][Selvaganesan Govindarajan][issue:summary][TRAFODION-3329:13260200]
Remove unused code in T2 driver"
Druid,No Relation,"[2017-06-02 15:39:04][Jonathan Wei][commit][b90c28e861d8797a4ada930367fb42fbe387568b]
Support limit push down for GroupBy (#3873)

* Support limit push down for GroupBy V2

* Use orderBy spec ordering when applying limit push down

* PR Comments

* Remove unused var

* Checkstyle fixes

* Fix test

* Add comment on non-final variables, fix checkstyle

* Address PR comments

* PR comments

* Remove unnecessary buffer reset

* Fix missing @JsonProperty annotation
","[2017-02-04 01:36:44][jihoonson][pull:comment][3873:99454033]
I think it would be better to swap lhs and rhs if the direction is descending rather than multiplying -1 for every comparison. If you do so, you don't have to passing directions as integers which is less intuitive."
Spark,SATD Repayment,"[2018-01-17 09:27:49][Sameer Agarwal][commit][c132538a164cd8b55dbd7e8ffdc0c0782a0b588c]
[SPARK-23020] Ignore Flaky Test: SparkLauncherSuite.testInProcessLauncher

## What changes were proposed in this pull request?

Temporarily ignoring flaky test `SparkLauncherSuite.testInProcessLauncher` to de-flake the builds. This should be re-enabled when SPARK-23020 is merged.

## How was this patch tested?

N/A (Test Only Change)

Author: Sameer Agarwal <sameerag@apache.org>

Closes #20291 from sameeragarwal/disable-test-2.
","[2018-01-17 08:19:16][sameeragarwal][pull:summary][20291]
## What changes were proposed in this pull request?

Temporarily ignoring flaky test `SparkLauncherSuite.testInProcessLauncher` to de-flake the builds. This should be re-enabled when SPARK-23020 is merged.

## How was this patch tested?

N/A (Test Only Change)"
Trafficcontrol,No Relation,"[2020-02-17 10:09:41][mattjackson220][code-comment][18fe13ac638557b5532813bce8ab3ad2d964fe49]
 Remove fields that are added by glibc
 Note that this is unstable as the identifers are private.
","[2019-10-21 19:59:54][ocket8888][pull:comment][3534:337211148]
Can you make this description match the same field from other two endpoints' documentation?"
Geode,SATD Repayment,"[2019-12-11 09:26:03][Scott Jewell][commit][82c0a739efaa28e4456f045f3dc3d574325cb109]
GEODE-7567: Improve cleanup logic in create_instance.sh (#4459)

* GEODE-7567: Improve cleanup logic in create_instance.sh

* GEODE-7567: Increase number of retry attempts
","[2019-12-10 21:20:19][Scott Jewell][issue:summary][GEODE-7567:13273707]
Improve create_instance cleanup logic"
Apisix Dashboard,SATD Duplication,"[2020-12-02 18:20:34][nic-chen][code-comment][17ad69b5ecfa80b55550d35d68681f55c84f5274]
 todo: this is a temporary method, we'll drop it later
","[2020-12-02 08:09:05][membphis][pull:comment][952:533967586]
need a todo comment: this is a temporary method, we'll drop it later"
Myfaces Tobago,SATD Repayment,"[2014-12-09 16:29:41][Udo Schnurpfeil][commit][a693a4806be054e55aacde43ec510f0f9eae3a46]
TOBAGO-1325: jQuery too slow in IE8: Tobago.Util.selectWithJQuery()
","[2013-10-16 09:22:17][Volker Weber][issue:summary][TOBAGO-1325:12674094]
jQuery too slow in IE8: Tobago.Util.selectWithJQuery()"
Incubator Heron,SATD Repayment,"[2016-05-12 17:27:55][Maosong Fu][commit][2310964983920c0ae4b6fff1b41436118d792aab]
Clean/Remove spi/utils/NetworkUtils (#650)

* Clean/Remove spi/utils/NetworkUtils
1. Remove spi/utils/NetworkUtils, since getFreePort() is duplicated in common/basics/SysUtils,
and getHeronStatus is relocated to SchedulerUtils as constructSchedulerResponse, which is more reasonable.
2. Update the usage on spi/utils/NetworkUtils
3. Add unit tests.

* Fix a unit test bug
","[2016-05-12 21:17:14][maosongfu][pull:summary][650]
Clean/Remove spi/utils/NetworkUtils"
Hadoop,SATD Repayment,"[2019-04-01 15:57:58][Shashikant Banerjee][commit][ef5de292436db56547f05f42a745be32e2b38546]
HDDS-1312. Add more unit tests to verify BlockOutputStream functionalities. Contributed by Shashikant Banerjee.
","[2019-03-19 20:41:43][Shashikant Banerjee][issue:summary][HDDS-1312:13222672]
This jira aims to add more unit test coverage for BlockOutputStream functionalities."
Zookeeper,No Relation,"[2017-12-13 22:45:17][phunt][pull:comment][377:156808074]
Do we are have any room left for this? iiuc ttls are the last, no more space left to consider addl types.

My concern here - won't people be confused by this, e.g. ""are containers extended types""?

What do you think @Randgalt ?
","[2017-10-17 12:36:52][Jordan Zimmerman][issue:comment][ZOOKEEPER-2901:16207580]
Default is set back to false. I really don't think we need to deprecate the high bit as it's now documented and you have to opt in to it. So, keep using Server IDs up to 255 unless you want TTLS then it's 254."
Parquet Mr,SATD Duplication,"[2020-11-03 14:43:29][ggershinsky][pull:summary][841]
1. rename RemoteKmsClient class to LocalWrapKmsClient; it will be used only in rare situations where in-server wrapping in not supported. 

2. this also means the ""wrap.locally"" property is not needed anymore, making the API slightly simpler.
","[2020-11-01 06:25:24][Gidon Gershinsky][issue:summary][PARQUET-1939:13338257]
Users complain that RemoteKmsClient name can be confusing, since this class covers both local and in-server (remote) key wrapping. Still, this class supports only remote KMS servers. But to remove any ambiguity, and to make the API simpler, we will rename this class to LocalWrapKmsClient; it will be used only in rare situations where in-server wrapping in not supported. In all other situations, the basic KmsClient interface will be used directly."
Kafka,SATD Duplication,"[2020-06-01 02:06:06][ijuma][pull:summary][8769]
KAFKA-10074: Improve performance of `matchingAcls`
","[2020-06-01 00:48:18][Ismael Juma][issue:summary][KAFKA-10074:13308606]
Improve performance of `matchingAcls`"
Tvm,SATD Duplication,"[2019-10-14 12:34:09][Animesh Jain][code-comment][bfb811c72c484e00283a20f6b4773659092dfb62]
 TODO - Naive softmax int8 implementation leads to bad accuracy. Currently, we can
 dequantize to FP32 and perform softmax on FP32. We can investigate an integer only softmax
 implementation in future.
","[2019-10-13 04:16:09][zhiics][pull:comment][3900:334262013]
s/MobilenetV2/MobilenetV1

Add a todo for MobilenetV2?"
Calcite,SATD Repayment,"[2015-04-22 15:37:52][Julian Hyde][code-comment][948e45671d04f720a71b79f022e143aa480164d4]
 see [CALCITE-687] Make RemoteDriverTest.testStatementLifecycle thread-safe
","[2015-04-17 18:06:35][Julian Hyde][issue:summary][CALCITE-687:12821946]
Make RemoteDriverTest thread-safe"
Flink,No Relation,"[2020-04-17 08:43:36][twalthr][pull:comment][11290:410080115]
nit: shouldn't `castedExpr`  be called `castExpr` or `sourceExpr` because it has not been casted yet. Otherwise it reads badly in `convertToExpectedType`
","[2020-03-14 01:53:16][Zhenghua Gao][issue:comment][FLINK-16379:17059150]
+1 to merge fromElements to fromValues. 

Construction empty table with Values may be useless because plan with empty LogicalValues could be optimized."
Ignite,SATD Repayment,"[2020-06-22 14:17:49][korlov42][commit][be38229c99dc338abdc93eba76e3d18471341fee]
IGNITE-13166 Flaky H2RowCachePageEvictionTest and IgniteCacheQueryH2IndexingLeakTest tests (#7947)
","[2020-06-19 08:30:54][Konstantin Orlov][issue:summary][IGNITE-13166:13312413]
Flaky H2RowCachePageEvictionTest and IgniteCacheQueryH2IndexingLeakTest tests"
Thrift,SATD Duplication,"[2018-03-30 19:39:49][cwe1ss][pull:summary][1524]
THRIFT-4535: XML docs; code cleanup (tabs->spaces; String->string)
","[2018-03-28 12:43:05][Christian Weiss][issue:summary][THRIFT-4535:13148559]
XML docs; code cleanup (tabs->spaces; String->string)"
Pulsar,SATD Repayment,"[2021-01-28 10:37:25][Enrico Olivelli][code-comment][d1579b7f1be9ab70d74453f9fefaa49d1c48fe00]
 this makes the test easier and predictable
","[2020-12-29 17:12:46][sijie][pull:comment][9083:549782046]
How does this make the test easier and predictable?"
Hadoop,SATD Duplication,"[2019-06-13 22:56:45][bharatviswa504][pull:summary][964]
HDDS-1675. Cleanup Volume Request 2 phase old code.
","[2019-06-13 01:05:10][Bharat Viswanadham][issue:summary][HDDS-1675:13239152]
Cleanup Volume Request 2 phase old code"
Airflow,SATD Repayment,"[2020-12-09 00:03:22][Kamil Breguła][commit][e595d35bf4b57865f930938df12a673c3792e35e]
Simplify publishing of documentation (#12892)

Close: #11423
Close: #11152
","[2020-12-07 19:10:38][mik-laj][pull:summary][12892]
Simplify publishing of documentation"
Hadoop,No Relation,"[2019-08-22 13:08:19][steveloughran][pull:comment][1208:316667252]
If you switch to assertJ it can do more details on the mismatch.
And as the Probe is used through all the test cases can be factored out into its own assertion
","[2019-07-11 13:30:35][Gabor Bota][issue:summary][HADOOP-16423:13244322]
This part is only for logging the inconsistencies.

This issue only covers the part when the walk is being done in the S3 and compares all metadata to the MS.
There will be no part where the walk is being done in the MS and compare it to the S3."
Geode,No Relation,"[2016-10-21 13:25:15][Jared Stewart][code-comment][8bf39571471642beaaa36c9626a61a90bd3803c2]
 delay for first log message is half the time of the interval between subsequent log
 messages
 Terminate the logging thread, recoverycomplete is only true when there are no missing
 colocated regions
","[2016-10-21 13:25:15][Jared Stewart][commit][8bf39571471642beaaa36c9626a61a90bd3803c2]
Added Spotless plugin to enforce formatting standards.
Added Google Java Style guide formatter templates, removed existing formatter templates.

Ran './gradlew clean build' for verification

This closes #268"
Hbase,SATD Repayment,"[2017-12-20 17:58:08][Apekshit Sharma][commit][dc5ec061b5eceaf3d1fdd901263dac100fdccdf1]
HBASE-19491 Improvements to Nighly runs: Fixes findbugs tests, Exclude flaky tests from master.
","[2017-12-12 02:45:59][Apekshit Sharma][issue:summary][HBASE-19491:13124267]
Testing infra improvements
- Exclude flaky tests from nightly master run (Old nightly master run used to exclude flaky tests, but new nightly one which is based on Jenkins stages wasn't using it. Adding it to new nightly job)
- Fixes findbugs check (seems like wasn't working earlier : ""0	findbugs	0m 0s	Findbugs executables are not available."")"
Lucene Solr,No Relation,"[2020-06-29 12:29:49][sigram][pull:comment][1626:446932540]
""Live state"" in SolrCloud terminology is a loaded term ... perhaps it's better to simply use the ""current heap usage"".
","[2020-06-26 11:43:39][Erick Erickson][issue:comment][SOLR-14588:17146249]
I should really have just disabled the test. I don't think reporting circuit breaker info for every request is actually useful, so your solution sounds much better. I have zero investment in keeping the fix I put in place, it was just to reduce the noise until you got some rest ;)."
Reef,SATD Repayment,"[2015-10-15 16:15:17][Mariia Mykhailova][commit][a9fc25862e8b36039adc1a9d2f27108beaeedfd3]
[REEF-523] Add missing Javadoc/triage TODOs in Java code: reef-common

This adds missing Javadoc comments and links to JIRA items in TODOs.
Also fixes several typos.

JIRA:
  [REEF-523](https://issues.apache.org/jira/browse/REEF-523)

Pull request:
  This closes #563
","[2015-10-14 00:17:41][tcNickolas][pull:summary][563]
This adds missing Javadoc comments and links to JIRA items in TODOs.
Also fixes several typos.

JIRA:
  [REEF-523](https://issues.apache.org/jira/browse/REEF-523)

Pull request:
  This closes #"
Flink,SATD Duplication,"[2019-08-02 12:31:02][yuzhao.cyz][code-comment][fab290c4890ab8f18f00bd638989bc1cec9c5f24]
*
	 * SQL dialect that allows some Apache Hive specific grammar.
	 *
	 * <p>Note: We might never support all of the Hive grammar. See the documentation for supported
	 * features.
","[2019-07-25 07:41:22][twalthr][pull:comment][9212:307155699]
""HIVE"" -> ""Hive""
Add ""Note: We might never support all of the Hive grammar. See the documentation for supported features."""
Hadoop,No Relation,"[2019-03-27 04:21:51][toddlipcon][pull:comment][597:269401040]
instead of saving pos/limit here and restoring them later, would it be easier to duplicate() the bytebuffer? then you could easily just set the limit to match 'n' and not worry about it? The loop bounds might become a bit easier, too (while buf.remaining() > 0) etc since you no longer need to consider the passed-in length.
","[2019-03-12 17:27:05][Sahil Takiar][issue:comment][HDFS-3246:16790786]
[~openinx] created a PR: https://github.com/apache/hadoop/pull/597

The latest version fixes a few issues reported by Hadoop QA, and adds some more Javadocs to {{CryptoInputStream}} to make the changes easier to understand.

Let me see if I can find someone more comfortable with libhdfs to review the libhdfs code."
Flink,No Relation,"[2020-03-24 10:44:34][Andrey Zagrebin][commit][813f590f9d92d154ec286377dfc12401aeae1b04]
[FLINK-16225] Improve metaspace out-of-memory error handling thrown in user code

Improve error message, explaining the possible reasons and ways to resolve.
In case of metaspace OOM error, try a graceful TM shutdown.

This closes #11408.
","[2020-03-20 11:52:35][azagrebin][pull:comment][11408:395587291]
I added the Metaspace assumption test. It is a bit tricky to make sure and load all the classes to measure the Metaspace usage so that OOM error is thrown in expected class loading. It was stable locally. If this ever leads to an instability or you also have more doubts, I can remove the commit."
Hadoop,No Relation,"[2006-11-14 22:35:22][Doug Cutting][code-comment][93c41fd87f0f227a9020fc4b60737b8eda01175f]
 Work around backward compatibility issue on IRIX 6.5. On IRIX 6.4+, sh
 is ksh but when the shell is invoked as ""sh"" and the current value of
 the _XPG environment variable is not equal to 1 (one), the special
 positional parameter $0, within a function call, is the name of the
 function.
","[2006-10-13 21:21:01][Owen O'Malley][issue:comment][HADOOP-538:12442097]
Just started looking through the patch, but please set your emacs and/or eclipse to use spaces instead of tabs. It makes it hard to read when the indentation isn't even. Thanks!"
Geode Native,No Relation,"[2017-02-22 17:09:22][pivotal-jbarrett][pull:comment][24:102517638]
I would only suggest avoiding long lines in the CMake files by putting each property on a new line.

```
set_target_properties(apache-geode PROPERTIES
    PUBLIC_HEADER ""${PUBLIC_HEADERS}""
    OUTPUT_NAME ${PRODUCT_LIB_NAME})
```
","[2017-02-17 22:49:33][Ernest Burghardt][issue:summary][GEODE-2508:13044139]
Generize lib naming"
Airflow,No Relation,"[2019-11-12 23:08:40][feluelle][pull:comment][4751:345494522]
I absolutely agree with what Ash is saying. The documentation doesn’t match the implementation and the change would probably need a separate ticket, because it changes the basic concept or meaning of finished tasks.
","[2019-01-01 11:41:09][Amichai Horvitz][issue:summary][AIRFLOW-3607:13207157]
I came across the TODO in airflow/ti_deps/deps/trigger_rule_dep (line 52) that says instead of checking the query for every task let the tasks report to the dagrun. I have a dag with many tasks and the delay between tasks can rise to 10 seconds or more, I already changed the configuration, added processes and memory, checked the code and did research, profiling and other experiments. I hope that this change will make a drastic change in the delay. I would be happy to discuss this solution, the research and other solutions for this issue.  

Thanks"
Iceberg,SATD Duplication,"[2020-08-05 13:46:32][Jingsong Lee][code-comment][fc5e3e5bbde66f0d5c66c4d980d47b9fd1f19f63]
 TODO add AVRO unit test once the RowDataWrapper are ready.
","[2020-08-05 04:22:59][JingsongLi][pull:comment][1232:465463522]
Removed this and add comment:
`TODO add AVRO once the RowDataWrapper are ready.`"
Flink,No Relation,"[2018-05-31 11:45:18][StefanRRichter][pull:comment][5582:192071512]
This method name is not so helpful. It does not tell us anything about what is evaluated. Maybe a javadoc on the public methods would be helpful.
","[2020-12-28 09:15:50][ming li][issue:comment][FLINK-8790:17255484]
Hi, [~sihuazhou]. At present, we use the incremental state of rocksdb to restore when scale up, and found that it is very slow to traverse the state of the corresponding keygroup. Can we now use rocksdb.deleteRange for state clipping?"
Hadoop,No Relation,"[2016-01-19 16:56:15][Zhijie Shen][code-comment][68cbb32e0a4e527f4c02a30c10c3e0db94ee444a]
 TODO: support time series storage
","[2015-05-07 20:45:57][Li Lu][issue:comment][YARN-3134:14533352]
Thanks [~zjshen] and [~junping_du] for the review! In this patch I removed the unrelated columns in Phoenix tables. I also reordered the primary keys so that records for the same user are located closely (consistent with the hbase implementation). 

For the loading cache related issues, there are multiple ways to implement the connection cache, but I think it's hard to reach a concrete conclusion before we actually try it out. So shall we firstly push the current design in, and I'll open a separate JIRA to trace the performance tuning process? 

We've also got some code cleanup work to do, but I put them in a priority lower than getting the performance evaluation done for now."
Arrow,No Relation,"[2019-01-08 19:41:01][Pindikura Ravindra][code-comment(deleted)][bfe6865ba8087a46bd7665679e48af3a77987cef]
 underlying buffer should be able to store 16 values
","[2019-01-08 19:41:01][Pindikura Ravindra][commit][bfe6865ba8087a46bd7665679e48af3a77987cef]
ARROW-4147: [Java] reduce heap usage for varwidth vectors (#3298)

* ARROW-4147: reduce heap usage for varwidth vectors

- some code reorg to avoid duplication
- changed the default initial alloc from 4096 to 3970

* ARROW-4147: [Java] Address review comments

* ARROW-4147: remove check on width to be <= 16:

* ARROW-4147: allow initial valueCount to be 0.

* ARROW-4147: Fix incorrect comment on initial alloc"
Brooklyn Server,SATD Repayment,"[2015-10-14 17:11:07][Svetoslav Neykov][code-comment(deleted)][73f0b448705eaba39a446f9bd8d5e4727129976d]
 TODO Not CAMP specific, move to core, to be reused by other parsers
","[2015-10-14 17:11:07][Svetoslav Neykov][commit][73f0b448705eaba39a446f9bd8d5e4727129976d]
Move ServiceSpecResolver and its implementations to core

To be reused by other plan parsers."
Trafficcontrol,No Relation,"[2020-02-17 10:09:41][mattjackson220][code-comment][18fe13ac638557b5532813bce8ab3ad2d964fe49]
 Add the zero block at position 2 so that it will be assigned a
 zero reference in the lookup blocks.
 TODO: always do this? This would allow us to remove a check from
 the trie lookup, but at the expense of extra space. Analyze
 performance for unicode/norm.
","[2019-10-21 19:18:58][ocket8888][pull:comment][3534:337194113]
""fqdn"" is an initialism (and an `abbr`, should you feel so inclined), should be capitalized. Though, alternatively, I don't think it's necessary to explain how it's stored."
Ignite,SATD Duplication,"[2019-04-04 13:25:46][denis-chudov][pull:summary][6407]
IGNITE-10344 Speed up cleanupRestoredCaches
","[2018-11-20 13:40:46][Pavel Voronkin][issue:summary][IGNITE-10344:13199607]
Speed up cleanupRestoredCaches"
Hive,SATD Repayment,"[2018-12-06 10:51:05][Zoltan Haindrich][commit][8b968c7e46929c3af86da46e316faeb8d17f03df]
HIVE-20985: If select operator inputs are temporary columns vectorization may reuse some of them as output (Zoltan Haindrich reviewed by Teddy Choi)

Signed-off-by: Zoltan Haindrich <kirk@rxd.hu>
","[2018-11-29 16:35:02][Zoltan Haindrich][issue:summary][HIVE-20985:13201391]
If select operator inputs are temporary columns vectorization may reuse some of them as output"
Carbondata,SATD Duplication,"[2016-07-08 14:33:36][ravipesala][pull:summary][32]
[CARBONDATA-47]Simplified datasource format name and storage name in carbondata
","[2016-07-08 14:05:39][Ravindra Pesala][issue:summary][CARBONDATA-47:12987795]
Simplified datasource format name and storage name in carbondata"
Arrow,No Relation,"[2020-05-28 18:10:01][Wes McKinney][commit][e8b317ab2b5dceedf1d21e0169a5b20c05648f18]
ARROW-8926: [C++] Improve arrow/compute/*.h comments, correct typos and outdated language

I also fixed the `Arity` ctor to be explicit which I thought I'd done in #7240 but it is taken care of here.

Closes #7264 from wesm/ARROW-8926

Authored-by: Wes McKinney <wesm+git@apache.org>
Signed-off-by: Wes McKinney <wesm+git@apache.org>
","[2020-05-21 14:33:08][pitrou][pull:comment][7240:428689621]
High-level question: isn't `Cast<ValueType>(Dict(indices, dictionary))` the same as `Take(dictionary, indices)`? So the Take implementation could ideally be reused without additionally hassle."
Systemds,SATD Repayment,"[2018-04-20 00:02:12][Matthias Boehm][code-comment][ba06d0534ba07a03ee1a9ed15c2034043b28c928]
for a special case of CSR inputs where all non-empty rows are dense, we can
create a shallow copy of the values arrays to a ""dense"" block and perform
tsmm with the existing dense block operations w/o unnecessary gather/scatter
","[2018-04-20 00:02:12][Matthias Boehm][commit][ba06d0534ba07a03ee1a9ed15c2034043b28c928]
[SYSTEMML-2261] Performance sparse tsmm (CSR with empty/dense rows)

This patch significantly improves performance for sparse tsmm over
special sparse matrices in CSR format, where all rows are either empty
or completely dense. The trick is that we can simply take the CSR values
array, count the number of dense rows, and use it as a ""dense"" block for
existing dense tsmm operations. This greatly improves performance
because existing dense operations usually perform much close at peak
performance due to better cache-conscious implementations and avoiding
unnecessary gather and scatter operations."
Zookeeper,SATD Duplication,"[2017-07-07 22:56:15][andschwa][pull:summary][306]
ZOOKEEPER-2841: ZooKeeper public include files leak porting changes
","[2017-07-07 22:48:30][Andrew Schwartzmeyer][issue:summary][ZOOKEEPER-2841:13085619]
ZooKeeper public include files leak porting changes"
Trafficcontrol,No Relation,"[2017-11-27 16:55:47][Dan Kirkwood][code-comment(deleted)][7d9b535eb02f873249dcbdceb584559391cbc187]
 This type matches C's ""struct flock"" defined in /usr/include/sys/fcntl.h.
 TODO: move this into the standard syscall package.
","[2017-11-27 16:55:47][Dan Kirkwood][commit][7d9b535eb02f873249dcbdceb584559391cbc187]
remove unneeded dependencies"
Pulsar,No Relation,"[2018-11-30 12:09:10][Boyang Jerry Peng][commit][015e2e5174a1e38167deb47411e598c73d424a19]
Improve and correct status for function, sources, sinks (#3088)

* Improve and correct status for function, sources, sinks

* cleaning up unused protobuf

* cleaning up

* fixing unit tests

* change getstatus -> status

* fix integration tests

* fix integration tests for sources and sinks
","[2018-11-29 02:43:41][jerrypeng][pull:comment][3088:442685798]
Not sure why github isn't showing renaming (and few changes) of FunctionsImpl -> FunctionsImplBase as a simple diff.  Perhaps this can help:

http://www.mergely.com/vNtCDbvV/"
Calcite,SATD Repayment,"[2019-05-06 09:34:13][yuzhao.cyz][code-comment][247c7d4f76a3d7d862ae6f4148cc8e6556efa497]
 Simplify the argument first,
 call ourselves recursively to see whether we can make more progress.
 For example, given
 ""(CASE WHEN FALSE THEN 1 ELSE 2) IS NULL"" we first simplify the
 argument to ""2"", and only then we can simplify ""2 IS NULL"" to ""FALSE"".
","[2019-05-05 06:44:17][danny0405][pull:summary][1198]
[CALCITE-3049] Simplify the operand first for IS NULL and IS NOT NULL"
Netbeans,SATD Repayment,"[2019-08-07 22:15:57][Junichi Yamamoto][commit][2de87ef6c6dc94d047178181f4a7c9ee736b7a10]
[NETBEANS-2910] Suggest using brackets for accessing arrays instead of curly braces
","[2019-07-29 03:36:46][Junichi Yamamoto][issue:summary][NETBEANS-2910:13247565]
Suggest using brackets for accessing arrays instead of curly braces"
Tajo,SATD Duplication,"[2014-12-26 12:15:05][charsyam][pull:summary][321]
TAJO-1270 Fix typos
","[2014-12-26 12:14:23][DaeMyung Kang][issue:summary][TAJO-1270:12763815]
Fix typos"
Nifi Minifi Cpp,No Relation,"[2019-05-24 09:31:35][Daniel Bakai][code-comment][e09a5d41d47823437c4dd064f89f7c8cf7e5ad88]

   * We create the would-be dot renamed file in the target, and because we don't overwrite temporary files,
   * if we really use a dot renamed temporary file, we should fail.
","[2019-05-17 10:33:36][phrocker][pull:comment][558:285070214]
curl_global_init is not thread safe. The singleton pattern appears to model that which is in http-curl, which is lazily initialized."
Zookeeper,No Relation,"[2019-10-21 14:45:48][anmolnar][pull:comment][1106:337060054]
Why not using `ConcurrentHashMap` instead of synchronizing everywhere?
","[2017-08-16 19:49:36][Jordan Zimmerman][issue:comment][ZOOKEEPER-1416:16129317]
Regarding the performance numbers above... They should be balanced by the enormous effort Curator's TreeCache class goes through to emulate Persistent/Recursive watches (which is essentially what it does). I argue that this change will be much more performant and efficient than what TreeCache is doing now."
Incubator Doris,SATD Duplication,"[2020-04-27 13:13:20][HappenLee][pull:summary][3405]
 [Profile] Make running profile clearer and more intuitive to improve usability
","[2020-04-21 10:57:00][HappenLee][issue:summary][3365]
[Proposal] Make running profile clearer and more intuitive to improve usability"
Hbase,SATD Repayment,"[2014-07-15 23:14:14][stack][commit][8a481b87b57035aca9f6ff2833104eb073e2e889]
HBASE-11520 Simplify offheap cache config by removing the confusing ""hbase.bucketcache.percentage.in.combinedcache""
","[2014-07-15 20:42:57][Michael Stack][issue:summary][HBASE-11520:12727466]
Simplify offheap cache config by removing the confusing ""hbase.bucketcache.percentage.in.combinedcache"""
Hudi,SATD Repayment,"[2020-10-01 14:25:29][Mathieu][commit][1f7add92916c37b05be270d9c75a9042134ec506]
[HUDI-1089] Refactor hudi-client to support multi-engine (#1827)

- This change breaks `hudi-client` into `hudi-client-common` and `hudi-spark-client` modules 
- Simple usages of Spark using jsc.parallelize() has been redone using EngineContext#map, EngineContext#flatMap etc
- Code changes in the PR, break classes into `BaseXYZ` parent classes with no spark dependencies living in `hudi-client-common`
- Classes on `hudi-spark-client` are named `SparkXYZ` extending the parent classes with all the Spark dependencies
- To simplify/cleanup, HoodieIndex#fetchRecordLocation has been removed and its usages in tests replaced with alternatives

Co-authored-by: Vinoth Chandar <vinoth@apache.org>
","[2020-09-24 06:51:07][vinothchandar][pull:comment][1827:698151969]
@wangxianghu Looks like we have much less class splitting now. I want to try and reduce this further if possible. 
If its alright with you, I can take over from here, make some changes and push another commit on top of yours, to try and get this across the finish line. Want to coordinate so that we are not making parallel changes,"
Hadoop,No Relation,"[2012-02-17 18:19:31][Aaron Myers][code-comment(deleted)][53b7d6c6bc23d7e723109c3b41e2ce6746ffbaba]
 Skip by reading the data so we stay in sync with checksums.
 This could be implemented more efficiently in the future to
 skip to the beginning of the appropriate checksum chunk
 and then only read to the middle of that chunk.
","[2012-03-14 19:28:25][Todd Lipcon][issue:comment][HDFS-1623:13229534]
Hi Avik. The multi-SBN approach is actually very nearly implemented by what's in trunk. The main missing pieces are actually in the more trivial bits -- for example, we have a few bits of the code that look up ""the other node"" for operations like triggering checkpoints. Those would have to be modified a bit to ""look up the active node"" instead. But nothing fundamental or really difficult."
Nifi Minifi Cpp,SATD Duplication,"[2020-06-19 09:34:22][nghiaxlee][pull:summary][819]
MINIFICPP-1265 - Adding missing license header for Windows ext
","[2020-06-19 08:10:09][Nghia Le][issue:summary][MINIFICPP-1265:13312410]
Adding missing license header for Windows processor"
Groovy,SATD Repayment,"[2019-08-26 13:50:12][Daniel Sun][code-comment(deleted)][8a417f9fa52f0db2b7b48ab514decd7f67c7b010]
 TODO: Convert to functional interface?
","[2019-08-26 13:50:12][Daniel Sun][commit][8a417f9fa52f0db2b7b48ab514decd7f67c7b010]
Minor refactoring: Convert `ProgressCallback` to functional interface"
Incubator Pinot,SATD Duplication,"[2019-08-15 15:26:29][Jialiang Li][code-comment][4f8ffc760f5187883a7ea7561c536dca2d0957b8]
 This registration is not needed when the leadControllerResource is enabled.
 However, the resource can be disabled sometime while the cluster is in operation, so we keep it here. Plus, it does not add much overhead.
 At some point in future when we stop supporting the disabled resource, we will remove this line altogether and the logic that goes with it.
","[2019-07-17 21:22:44][mcvsubbu][pull:comment][4323:304647565]
add a comment that this registration is not needed if the resource is enabled. However, the resource can be disabled sometime while the cluster is in operation, so we keep it here. Also, it does not add much overhead. At some point in future when we stop supporting the disabled resoiurce, we will remove this line altogether and the logic that goes with it."
Commons Lang,No Relation,"[2009-06-23 06:15:50][Henri Yandell][code-comment][c404121979002fca1140b90fb909157549de286f]
 TODO: Replace with a RegexTranslator. That should consume the number of characters the regex uses up?
","[2009-06-30 06:37:23][Henri Yandell][issue:comment][LANG-505:12725491]
Performance fixed. At least the speed is back down to 0.5 seconds, which is close enough for now."
Hadoop,SATD Repayment,"[2011-08-19 03:57:48][Michael Stack][code-comment][4c797e7ba95360e0b09ae0d256fa6ae91de8f853]
 If live datanode count is lower than the default replicas value,
 RollWriter will be triggered in each sync(So the RollWriter will be
 triggered one by one in a short time). Using it as a workaround to slow
 down the roll frequency triggered by checkLowReplication().
","[2011-07-22 06:14:14][Jieshan Bean][issue:comment][HBASE-4095:13069404]
I don't know why it got blocked for a long time. The rollWriter must get the lock of this.cacheFlushLock, if the RS's flushing now, the rollWriter can't be executed in time(The lock is carried by CacheFlush threads).

I think use tryLock is better(If it can't get the lock in several second, we just skip it this time).


  public long startCacheFlush() {
    this.cacheFlushLock.lock();
    return obtainSeqNum();
  }"
Camel,SATD Repayment,"[2016-01-05 17:38:53][Claus Ibsen][commit][df701cc3776833c98a3e2b53f86dfd8f01eabe4b]
CAMEL-9482: Removed option which has been deprecated for a very long time
","[2016-01-05 16:36:32][Claus Ibsen][issue:summary][CAMEL-9482:12927308]
Remove some old options that has been deprecated forever"
Reef,SATD Duplication,"[2015-10-14 00:17:41][tcNickolas][pull:summary][563]
[REEF-523] Add missing Javadoc/triage TODOd in Java code: reef-common
","[2015-07-29 19:44:16][Mariia Mykhailova][issue:summary][REEF-523:12850032]
Add missing Javadoc comments/triage TODO notes in Java code: reef-common"
Incubator Pinot,No Relation,"[2017-03-13 11:58:25][Xiaotian Jiang][code-comment][78672e145bc2d987b03518ae665844598a4f0b08]
 Remove the temp file
 When the file is copied to instead of renamed to the new file, the temp file might be left in the dir
","[2017-03-12 04:15:22][mayankshriv][pull:comment][1136:105548412]
s/Get/Got. Add more information, eg what was the code doing when this happened."
Samza,SATD Duplication,"[2017-05-08 13:29:23][Prateek Maheshwari][code-comment][ad41f9a7fdf30c8b1d91853cbdf70dbef664340e]
 TODO fix in SAMZA-1183
 @Test
","[2017-05-08 13:29:23][Prateek Maheshwari][commit][ad41f9a7fdf30c8b1d91853cbdf70dbef664340e]
Disabled a few flaky tests and added corresponding tickets to fix.

Author: Prateek Maheshwari <pmaheshw@linkedin.com>

Reviewers: Jacob Maes <jmaes@linkedin.com>

Closes #171 from prateekm/disable-flaky-test"
Arrow,SATD Repayment,"[2020-01-02 07:24:58][Kazuaki Ishizaki][commit][cec93999fdef8fe9c83e78ec9f9cc53f9341d71c]
ARROW-7482: [C++] Fix typos

This PR fixes typos in files under `cpp/src/arrow` directory

Closes #6110 from kiszk/ARROW-7482 and squashes the following commits:

b5dc3f012 <Kazuaki Ishizaki> fix lint errors
bb39903f4 <Kazuaki Ishizaki> address review comment
b291f2e01 <Kazuaki Ishizaki> fix lint errors
224796723 <Kazuaki Ishizaki> fix typo

Authored-by: Kazuaki Ishizaki <ishizaki@jp.ibm.com>
Signed-off-by: Sutou Kouhei <kou@clear-code.com>
","[2019-12-31 17:49:14][Kazuaki Ishizaki][issue:summary][ARROW-7482:13277039]
[C++] Fix typos"
Drill,SATD Repayment,"[2018-10-10 09:48:09][Sorabh Hamirwasia][commit][d5146c43986f09f132f4e96966082732a3740181]
DRILL-6766: Lateral Unnest query : IllegalStateException - rowId in right batch of lateral is smaller than rowId in left batch being processed
Note: Issue was in StreamingAgg where if output from one or multiple input batch was splitting into multiple output batch, then remaining input
records were discarded after producing first output batch
closes #1490
","[2018-10-04 18:32:59][sohami][pull:summary][1490]
DRILL-6766: Lateral Unnest query : IllegalStateException - rowId in right batch of lateral is smaller than rowId in left batch being processed"
Myfaces Tobago,SATD Repayment,"[2014-03-05 18:39:25][Udo Schnurpfeil][commit][754426b47430927dd8f5b8ae895054bb6086f4d9]
TOBAGO-1373 - Better JavaScript logging: using browser console and fill browser gaps.
","[2014-03-03 08:33:29][Udo Schnurpfeil][issue:summary][TOBAGO-1373:12698374]
Better JavaScript logging: using browser console and fill browser gaps."
Phoenix,No Relation,"[2018-07-18 18:16:04][Thomas D'Silva][code-comment][4d6dbf9cb20a8299e9484c0d75aceb5e4862ea12]
 if an indexed column was dropped in an ancestor then we
 cannot use this index an more
 TODO figure out a way to actually drop this view index
","[2017-03-21 21:53:48][churro morales][issue:comment][PHOENIX-3534:15935402]
Hey folks I thought I would add a doc to document this approach and what considerations we should be making. 

https://docs.google.com/document/d/16p1FZReNHdQrvUj0NzLJ-Zx79J8-UE8Ku8bRPoql-Pc/edit?usp=sharing"
Drill,No Relation,"[2020-02-27 03:17:58][paul-rogers][pull:comment][1988:384893271]
Tried to move to a test. Code does not work. Functionality itself tested indirectly in new registry unit tests, so just deleted the method.
","[2020-02-17 18:51:59][Paul Rogers][issue:summary][DRILL-7590:13285839]
The plugin registry connects configurations, stored in ZK, with implementations, which are Java classes. The registry handles a large number of tasks including:

* Populating ""bootstrap"" plugin configurations and handling upgrades.
* Reading from, and writing to, the persistent store in ZK.
* Handling ""normal"" (configured) plugins and special system plugins (which have no configuration.)
* Handle format plugins which are always associated with the DFS storage plugin.
* And so on.

The code has grown overly complex. As we look to add a new, cleaner plugin mechanism, we will start by cleaning up what we have to allow the new mechanism to be one of many."
Tvm,SATD Duplication,"[2017-12-24 19:09:57][Lianmin Zheng][code-comment][d218c5fc0072495b41017af5a83c91e79f97ce22]
 The assignment below introduces side-effect, and the resulting value cannot
 be reused across multiple expression, thus a new scope is needed
","[2017-12-19 14:16:35][tqchen][pull:comment][711:157765369]
add a comment:

The assignment introduces side-effect, and the resulting value cannot be reused across multiple expression, thus a new scope is needed"
Phoenix,SATD Repayment,"[2015-09-24 12:03:54][Gabriel Reid][code-comment][5ecd4967f6f9ee8ae90ea1ea7421b43fcba67d14]
 We cache the class loader because calls to Class.getClassLoader are relatively expensive
","[2015-09-24 12:03:54][Gabriel Reid][commit][5ecd4967f6f9ee8ae90ea1ea7421b43fcba67d14]
PHOENIX-2289 Avoid Class.getClassLoader calls

Cache the class loader from the PhoenixContextExecutor class
to avoid relatively expensive calls to Class.getClassLoader."
Beam,SATD Repayment,"[2017-03-28 16:44:32][Amit Sela][code-comment][25569eafeca647561ef10cedc03f06b1de53b8cd]
 using mapPartitions allows to preserve the partitioner
 and avoid unnecessary shuffle downstream.
","[2017-03-28 16:44:32][Amit Sela][commit][25569eafeca647561ef10cedc03f06b1de53b8cd]
[BEAM-1815] Force a ""default"" partitioner based on Spark default parallelism to avoid unnecessary shuffles in
the composite GBK implementation.

Add Javadoc."
Hbase,No Relation,"[2020-01-28 16:45:49][Bharath Vissapragada][code-comment][71f035450df0c8f56622b5151003bc134ca0091b]
*
 * Caches the cluster ID of the cluster. For standby masters, this is used to serve the client
 * RPCs that fetch the cluster ID. ClusterID is only created by an active master if one does not
 * already exist. Standby masters just read the information from the file system. This class is
 * thread-safe.
 *
 * TODO: Make it a singleton without affecting concurrent junit tests.
","[2019-12-06 02:09:36][bharathv][pull:summary][904]
This patch implements the RPCs needed for the meta information
lookup during connection init. New tests added to cover the RPC
code paths. HBASE-23305 builds on this to implement the client
side logic.

Fixed a bunch of checkstyle nits around the places the patch
touches."
Incubator Mxnet,No Relation,"[2016-07-21 19:16:34][piiswrong][pull:comment][2795:234355061]
So the current problem with training is that reservedspace need to be kept as an output but it's size is unknown during shape inference?
A simple fix is to use cudamemalloc to alloc it during op.init. It's not ideal but since it should be a small buffer it's fine for now
","[2016-06-13 00:43:31][piiswrong][issue:comment][2401:225470060]
Thank you very much for the contribution. This is an important feature.
The first should be straight forward. Like the other cudnn ops
An easy way to do the second is to chain up other operators in the c++ side. You just need to dispatch the Tblobs correctly."
Hadoop,SATD Repayment,"[2013-12-31 01:10:01][Vinod Kumar Vavilapalli][code-comment][460ac8cb50e024b60e02a96c2ab27368dfe0944d]
 blockNewEvents is only set when dispatcher is draining to stop,
 adding this check is to avoid the overhead of acquiring the lock
 and calling notify every time in the normal run of the loop.
","[2013-12-17 06:06:38][Jian He][issue:comment][YARN-1121:13850151]
Oh, the reason I added the blockNewEvents check is that I don't want notify() to be called every time in the normal run if the queue is empty. That can possibly create more overhead. And only to be called if dispatcher is stopping.
And In this scenario, I also think the sync should be outside the while loop to protect drained variable?"
Drill,SATD Repayment,"[2017-07-03 18:02:11][Kunal Khatua][commit][0e1e6042f507ac0da2a21d7de3bbed4c0dac549a]
DRILL-5420: ParquetAsyncPgReader goes into infinite loop during cleanup

PageQueue is cleaned up using poll() instead of take(), which constantly gets interrupted and causes CPU churn.
During a columnReader shutdown, a flag is set so as to block any new page reading tasks from being submitted.

closes #862
","[2017-06-28 17:49:20][kkhatua][pull:summary][862]
DRILL-5420: ParquetAsyncPgReader goes into infinite loop during cleanup"
Lucene Solr,No Relation,"[2020-01-28 11:27:18][Robert Muir][commit][e504798a44e5f1577d87ef3a43d9d1e3a859d68a]
LUCENE-9185: add ""tests.profile"" to gradle build to aid fixing slow tests

Run test(s) with -Ptests.profile=true to print a histogram at the end of
the build.
","[2020-01-28 13:43:15][Robert Muir][issue:comment][LUCENE-9185:17025112]
{quote}
It will work but -Ptests.profile=true would be more gradle-sque (it sets a project property as opposed to system property).
{quote}

The tool uses actual system properties for the more advanced options (e.g. {{-Dtests.profile.count=20}}). Seems a little evil to mix -P's and -D's when documenting this? I'll be honest, the difference is super confusing."
Incubator Dolphinscheduler,SATD Repayment,"[2020-04-21 02:25:45][dailidong][commit][eec92ed1fc1a35e22b8e38ac40681a1dd803399b]
simplify and optimize config (#2469)

* [Refactor worker] simplify and optimize config (#2386)

* simplify config

* simplify config

* simplify and optimize config

* Update HadoopUtils.java

optimize HadoopUtils

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java

* Update HttpUtils.java

* Update pom.xml

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java
","[2020-04-20 08:22:51][dailidong][pull:summary][2469]
simplify and optimize config"
Nifi Minifi Cpp,SATD Duplication,"[2017-02-22 15:47:02][Andrew Christianson][code-comment][a9485aeb05defe3e54b179c3b5dcc1735486abcd]
 Fall back to the initial (original) Object.toString().  We don't
		 * currently have pointers to the built-in functions, only the top
		 * level global objects (like ""Array"") so this is now done in a bit
		 * of a hacky manner.  It would be cleaner to push the (original)
		 * function and use duk_call_method().
","[2017-02-16 12:33:23][achristianson][pull:comment][43:101507876]
@phrocker Mainly, creating a shared ProcessContext and SessionFactory which will be used in this thread as well as the threads created in the loop below. I wanted these objects to be cleaned up once they go out of scope in all threads. The raw pointers are only used to integrate with the existing Processor pointer that is passed-in, as well as passing raw pointers to the constructors of the new shared objects. I wanted to minimize function/constructor changes that might have impacts elsewhere in the code base. If we want to move more to having managed pointers across the code base, then some of this can be cleaned up."
Hive,SATD Duplication,"[2014-01-27 17:30:14][Eric N. Hanson][code-comment][b1dcb8b7b42c444b14a91edb4c1251421205e3d3]
*
   * Divide the target object by right, and scale the result to newScale.
   *
   * This uses HiveDecimal to get a correct answer with the same rounding
   * behavior as HiveDecimal, but it is expensive.
   *
   * In the future, a native implementation could be faster.
","[2014-01-22 01:26:17][Eric N. Hanson][issue:comment][HIVE-6243:13878116]
Modified Decimal128.divideDestructive to use HiveDecimal division. This is slow but fixes the bug in the existing divide method. It also provides the same rounding behavior has HiveDecimal for consistency between row-mode and vectorized execution.

At some point in the future, another JIRA can be done to both fix the divide error in the original Decimal128.divideDestructive() and make it use the same rounding behavior as the current HiveDecimal."
Tinkerpop,SATD Duplication,"[2020-10-08 22:01:49][divijvaidya][pull:summary][1343]
TINKERPOP-2440 Simplify driver by delegating keepAlive logic to Netty
","[2020-10-08 21:17:09][Divij Vaidya][issue:summary][TINKERPOP-2440:13334512]
Simplify driver by delegating keepAlive logic to Netty"
Drill,SATD Repayment,"[2018-10-10 09:48:09][Sorabh Hamirwasia][commit][d5146c43986f09f132f4e96966082732a3740181]
DRILL-6766: Lateral Unnest query : IllegalStateException - rowId in right batch of lateral is smaller than rowId in left batch being processed
Note: Issue was in StreamingAgg where if output from one or multiple input batch was splitting into multiple output batch, then remaining input
records were discarded after producing first output batch
closes #1490
","[2018-10-04 18:32:59][sohami][pull:summary][1490]
DRILL-6766: Lateral Unnest query : IllegalStateException - rowId in right batch of lateral is smaller than rowId in left batch being processed"
Ignite,No Relation,"[2020-11-16 14:38:47][agoncharuk][pull:comment][7984:524315198]
Need to add more tests for actual complex indexes: multi-column, various inline sizes.
","[2020-11-27 09:04:10][Ivan Bessonov][issue:comment][IGNITE-13190:17239581]
[~mmuzaf] thank you for review!

I addressed your latest comments and made necessary changes to the code, please take a look. I hope that code is a bit more clean now."
Camel,No Relation,"[2015-01-18 14:44:32][Claus Ibsen][commit][42ded87e1256b2aabdd0bd0ed5f2e87fcac766b1]
CAMEL-7050: DeadLetterChannel should make more clear that it handles any new exception also. Added option to configure this behavior so ppl can turn that off and let new exceptions be unhandled, so transactions can rollback.
","[2014-06-24 05:54:34][Claus Ibsen][issue:comment][CAMEL-7050:14041738]
Yeah as there is a code change in redelivery error handler it affects *every* component in Camel. I wonder if the fix should not be in the fallback error handler, which is used for handling errors in error handlers. IMHO at first though that would see as a better solution."
Incubator Pinot,SATD Repayment,"[2020-04-03 15:27:25][Xiaotian (Jackie) Jiang][commit][ac327bb7aa78fc5f3acf5c8bc84c9add2ade0674]
Optimize ExpressionFilterOperator (#5132)

1. Add BYTES type and multi-value support
2. Directly consturct DocIdSet to save the overhead of filtering
3. Remove the redundant isMatch() for all scan based iterators

Also changed the numEntriesScannedInFilter for MV column to actual values fetched instead of values evaluated and added some TODOs for future filter optimization
","[2020-03-10 00:35:13][Jackie-Jiang][pull:summary][5132]
1. Add BYTES type and multi-value support
2. Directly construct DocIdSet to save the overhead of filtering
3. Remove the redundant isMatch() for all scan based iterators

Also changed the numEntriesScannedInFilter for MV column to actual values fetched instead of values evaluated and added some TODOs for future filter optimization"
Ignite,No Relation,"[2016-11-26 01:15:09][Amir Akhmedov][code-comment][b3616f734209671fc0cd5cd722936c47783a6ca6]
* The word converted into the Text.
","[2016-09-01 23:16:14][Valentin Kulichenko][issue:comment][IGNITE-3699:15456908]
[~aakhmedov], here are my comments.

# I don't like that you used the existing test and replaced {{invoke}} with {{get}}. Please create new test instead for {{get}} and make sure that {{invoke}} also works properly. Overall, you should increase code coverage, not reduce it.
# Can you please explain the change in {{GridCacheAdapter}}?"
Incubator Mxnet,SATD Repayment,"[2018-08-02 19:11:16][Lai Wei][commit][1bd9356b30ecde412663d0020ed769042cf456d6]
[MXNET-771] Fix Flaky Test test_executor.py:test_dot (#11978)

* use assert_almost_equal, increase rtol, reduce matrix size

* remove seed in test_bind

* add seed 0 to test_bind, it is still flaky

* add comments for tracking
","[2018-07-13 05:18:03][szha][issue:summary][11686]
The unit test in title have been using fixed seed to mask flakiness. Suggested action:
1. Evaluate whether the test is flaky without fixed seed. If not, remove seed. Else move to 2
2. If test is flaky, determine whether it's an actual uncaught edge case. If so, fix the operator. Else move to 3
3. If numerical instability is inevitable, adjust tolerance level appropriately."
Spark,SATD Repayment,"[2020-11-30 13:59:51][Josh Soref][commit][485145326a9c97ede260b0e267ee116f182cfd56]
[MINOR] Spelling bin core docs external mllib repl

### What changes were proposed in this pull request?

This PR intends to fix typos in the sub-modules:
* `bin`
* `core`
* `docs`
* `external`
* `mllib`
* `repl`
* `pom.xml`

Split per srowen https://github.com/apache/spark/pull/30323#issuecomment-728981618

NOTE: The misspellings have been reported at https://github.com/jsoref/spark/commit/706a726f87a0bbf5e31467fae9015218773db85b#commitcomment-44064356

### Why are the changes needed?

Misspelled words make it harder to read / understand content.

### Does this PR introduce _any_ user-facing change?

There are various fixes to documentation, etc...

### How was this patch tested?

No testing was performed

Closes #30530 from jsoref/spelling-bin-core-docs-external-mllib-repl.

Authored-by: Josh Soref <jsoref@users.noreply.github.com>
Signed-off-by: Takeshi Yamamuro <yamamuro@apache.org>
","[2020-11-28 23:23:44][jsoref][pull:summary][30530]
[MINOR] Spelling bin core docs external mllib repl"
Ignite,No Relation,"[2019-10-24 09:24:35][pavlukhin][pull:comment][6917:338470344]
According to codey-style `else` should start from new line.
","[2019-10-03 14:42:51][Andrey Mashenkov][issue:comment][IGNITE-12189:16943640]
[~Yuriy_Shuliha], good try. I've left few comments to the PR.

Change in PlatformCache can broke text queries in .NET. Let's make a stub and fix it later within a new ticket.
Other my comments relates to code styles."
Arrow,No Relation,"[2021-02-09 08:59:00][Hongze Zhang][code-comment][d25660ed5f57b167878c96cafc23361421a73ca8]
/ \class DisposableScannerAdaptor
/ \brief An adaptor that iterates over a Scanner instance then returns RecordBatches
/ directly.
/
/ This lessens the complexity of the JNI bridge to make sure it to be easier to
/ maintain. On Java-side, NativeScanner can only produces a single NativeScanTask
/ instance during its whole lifecycle. Each task stands for a DisposableScannerAdaptor
/ instance through JNI bridge.
/
","[2020-04-25 05:56:29][emkornfield][pull:comment][7030:414989937]
it seems like a a bad idea to collect an iterator if the intention is for the iterator to provide laziness?"
Hive,SATD Repayment,"[2020-08-12 07:51:41][dh20][commit][f49f19183b4436039c03c6b072dc67bf0b231a55]
HIVE-23922: Improve code quality, UDFArgumentException.getMessage Method requires only two parameters (#1307)
","[2020-07-24 08:32:17][hao][issue:summary][HIVE-23922:13319120]
Improve code quality, UDFArgumentException.getMessage Method requires only two parameters"
Ignite,SATD Repayment,"[2020-08-05 17:04:12][Vladsz83][commit][ec94d35c0fbdc8c261c647a97d6debd3eeb5e00d]
IGNITE-13208 : Simplify IgniteSpiOperationTimeoutHelper (#7988)
","[2020-07-02 18:42:52][Vladimir Steshin][issue:summary][IGNITE-13208:13314762]
Simplify IgniteSpiOperationTimeoutHelper"
Cxf,No Relation,"[2020-11-12 16:52:23][dufoli][pull:comment][721:522258207]
@rmannibucau I have added basic codes for it but it is complicated for something. 
ClassCreator class generate the JAXButils createNamespaceWrapper and it work but it work because we are in same module (core) but other classcreator are in dependencies... so if we switch to new system class creation need to be moved to core which seems a bad idea to me.
","[2021-01-07 06:16:13][olivier dufour][issue:comment][CXF-8340:17260252]
I have released the quarkus extension.🍾🎊
Here is the release note. It has removed 1000 line of code. 

Enhancement:

class generation used cxf generation => fix a lot of potential bugs and add many features
use vertx routing instead of servlet and filter. => performance improvment
update to CXF 3.4.2
update to Quarkus 1.10.5

BugFix:

use serviceName instead of name on webservice annotation
avoid Null pointer exception if no webservice defined"
Cloudstack,SATD Repayment,"[2011-08-19 16:11:48][Sheng Yang][code-comment][7ccc833114bae575962b69b212edb080b99c412d]
for redundant router, grap the lock to prevent racy with keepalived process
","[2011-08-19 16:11:48][Sheng Yang][commit][7ccc833114bae575962b69b212edb080b99c412d]
Fix potential redundant router FAULT state by dnsmasq

This message may show during redundant router start up:

FAULT (Restarting DNS forwarder and DHCP server: dnsmasq failed!)

This caused by edithost.sh is racy with keepalived process. They both want to
restart dnsmasq.

Even in normal condition, it's very hard to reproduce this bug. Add file lock
for edithost.sh should solve it."
Nifi Minifi Cpp,No Relation,"[2017-12-13 15:39:09][Caleb Johnson][code-comment][df353561c8a8a0a0d1178a76f03b966b44542834]
 Avoid unnecessary sorts by preserving the ROWSET_SORTED flags
      ** where possible
","[2017-11-22 14:13:15][phrocker][pull:comment][185:346361349]
@calebj can you define a top level variable for the path to civet and rocksdb and use that instead of the hardcoded path?"
Flink,SATD Duplication,"[2012-04-24 20:36:30][Tommy Neubert][code-comment][c64c8079fa4ec088d202b6e5ffd4e9c36ede34b7]
 TODO Reuse target (problem: result could be any kind of NumericNode)
","[2012-04-24 20:36:30][Tommy Neubert][commit][c64c8079fa4ec088d202b6e5ffd4e9c36ede34b7]
marked all expressions which dont reuse the target node during evaluation with   TODO Reuse target"
Superset,No Relation,"[2020-12-15 18:47:40][Beto Dealmeida][commit][8bda6b0bd98bf6082fcf87b536f96a09050e06d8]
feat: show missing parameters in query (#12049)

* feat: show missing parameters in query

* Fix lint

* Address comments

* Simplify error message

* Use f-string in helper function
","[2020-12-15 17:49:30][betodealmeida][pull:comment][12049:543557216]
Yeah, I'll leave a TODO here."
Trafficcontrol,No Relation,"[2020-10-26 11:49:58][Zach Hoffman][code-comment(deleted)][6b3cfa00155e038d6e4ce195fc9b138479b8fce8]
 TODO: need to set e.prev.level to e.level if e.level is smaller?
","[2020-10-26 11:49:58][Zach Hoffman][commit][6b3cfa00155e038d6e4ce195fc9b138479b8fce8]
License go-acme/lego dependencies (#5187)

* Move go repositories to traffic_ops_golang vendor directory:
  - contrib.go.opencensus.io
  - google.golang.org
  - go.opencensus.io
  - gopkg.in
  - go.uber.org

* Remove duplicate packages between github.com/go-acme/lego/vendor and the
rest of the repo

* Move github.com-hosted packages to traffic_ops_golang vendor directory

* Move github.com/dgrijalva/jwt-go to main vendored directory so
traffic_ops_auth can use it, too

* Remove duplicate vendored packages

* Remove unused dependency cloud.google.com/go/compute/metadata

* Do not track the golang standard library"
Incubator Doris,SATD Repayment,"[2019-09-19 17:37:02][ZHAO Chun][commit][17e52a4bacec63179525143a8e862e8bf68c9d7b]
Improve LRUCache to get better performance (#1826)

In this CL, I move the entry's deleter out of LRUCache's mutex block,
which can let others access this cache without waiting free cache entry.
","[2019-09-18 12:25:15][imay][pull:summary][1826]
Improve LRUCache to get better performance"
Arrow,No Relation,"[2021-01-03 20:47:31][Dandandan][pull:comment][9070:551052647]
That would be a bit less trivial to get rid of than I thought, but at some point you could make a case either to convert those string arrays to use 64 bit indexes or to split the batches to have 2^32 size, or something like that.
","[2020-12-29 07:02:41][Jorge Leitão][issue:comment][ARROW-11030:17255842]
No idea why: I cannot find a N*N operation in `new`, so AFAI can tell, it should not even be polynomial. :/

I agree that having an average of 20 rows per batch may be breaking some of the assumption we make about the performance of arrays."
Lucene Solr,SATD Repayment,"[2016-04-04 12:51:03][Robert Muir][commit][c1a3e1b8d04ffc94e502b086e0544c0e0494d5a8]
LUCENE-7159: Speed up LatLonPoint point-in-polygon performance
","[2016-04-01 02:56:38][Robert Muir][issue:summary][LUCENE-7159:12955174]
improve spatial point/rect vs. polygon performance"
Parquet Mr,No Relation,"[2013-03-21 09:10:37][Julien Le Dem][code-comment(deleted)][f9c25b690457cc5788142feba2c31ee169b1736e]
 TODO: proper exception
","[2014-07-18 23:15:35][julienledem][pull:comment][17:15138762]
It would be great to find a way to reuse those statuses without using side effects."
Camel,SATD Duplication,"[2011-05-23 11:07:38][Willem Ning Jiang][code-comment][e9b000f27e273b08e50ef606195957d48d7f33f3]
 We need to write a warning message when the exception and fault message be set at the same time
","[2011-05-23 11:04:30][Willem Jiang][issue:summary][CAMEL-4005:12508045]
Log warning message when the exchange fault message and exception are set at the same time"
Groovy,SATD Duplication,"[2012-01-07 20:28:15][Paul King][code-comment][05524a5f29f068acaafb97cd8094839e86b669c1]
 TODO M12N move this to groovy-testng
","[2012-01-07 20:28:15][Paul King][commit][05524a5f29f068acaafb97cd8094839e86b669c1]
add groovy-testng plus TODO comments"
Beam,No Relation,"[2016-09-12 17:40:15][Dan Halperin][code-comment(deleted)][ed7c4aaf96f766c8d82d3422a02a9c95446e7fb8]
[BEAM-398] Inconsistent synchronization
","[2016-09-13 04:41:04][manuzhang][pull:comment][943:246571885]
ok, then how are we supposed to run `@RunnableOnService` tests locally now. I tried `mvn integration-test` but no tests are executed."
Flink,SATD Duplication,"[2017-07-15 00:47:16][greghogan][pull:summary][4346]
The Simplify parameter should accept and set the parallelism when calling the Simplify algorithms.
    
The LocalClusteringCoefficient ""count triangles"" reduce now uses the assigned (""little"") parallelism as this computation is proportional to the number of vertices (the combine computation is proportional to the potentially much larger number of triangles).

The ignored CombineHint on the HITS all-reduces have been removed.
","[2017-07-14 20:54:20][Greg Hogan][issue:summary][FLINK-7199:13087299]
The {{Simplify}} parameter should accept and set the parallelism when calling the {{Simplify}} algorithms."
Kafka,SATD Duplication,"[2020-06-25 18:30:20][lct45][pull:summary][8929]
KAFKA-4996: Fix findbugs multithreaded correctness warnings for streams
","[2017-03-31 21:19:15][Colin McCabe][issue:summary][KAFKA-4996:13060808]
Fix findbugs multithreaded correctness warnings for streams"
Tvm,SATD Repayment,"[2017-10-22 11:17:21][Tianqi Chen][commit][0f1e0ff086d321ba9ece924f7e3589496a4b6fdb]
[PASS] More robust UnrollLoop configuratin (#576)
","[2017-10-22 18:03:40][tqchen][pull:summary][576]
[PASS] More robust UnrollLoop configuratin"
Tvm,No Relation,"[2018-10-30 15:29:36][Jared Roesch][code-comment][10ea05e64508309e834f9b983037c96e3231e706]
 TVM's calling convention is that the final argument is the output
 buffer. To preserve the illusion of being a functional language
 we need to allocate space for the output buffer based on the
 return type.
","[2018-10-29 05:04:12][MarisaKirisame][pull:comment][1954:228802046]
indent"
Fluo,SATD Repayment,"[2014-12-04 12:38:42][Mike Walch][commit][c9bb1761242e0788e5d1fd939d859c1d6793df65]
Merge pull request #358 from mikewalch/fluo-348

Closes #348 - Clean up ScannerConfiguration and create unit test
","[2014-11-21 16:36:33][mikewalch][issue:summary][348]
Clean up ScannerConfiguration and create unit test"
Brooklyn Server,No Relation,"[2013-11-05 17:31:02][ahgittin][code-comment][2c24b8d1fb19d595127c36b3bcccae4c0d99bb40]
 TODO Parsing ""f(\""x\"", 1)"" fails, because it interprets 1 as a function rather than a number. Is that expected?
","[2018-06-05 15:36:16][duncangrant][pull:summary][969]
This PR follows on from #968 
It adds 2 commits.  The first adds tests for the functionality fixed in #968 
The second changes the logic in #968 in a way that I think is equivalent but I haven't managed to add the requisite test coverage to prove this."
Reef,SATD Repayment,"[2015-11-16 09:33:18][Dongjoon Hyun][commit][fc5d9079bb080120932da496635b8e1bcf9c7f54]
[REEF-949] Remove unnecessary TODO comment in Mesos-runtime module

Since the current code already submits its executing user to Mesos,
this PR simply removes a TODO comment to prevent further confusion.

JIRA:
  [REEF-949](https://issues.apache.org/jira/browse/REEF-949)

Pull request:
  This closes #643
","[2015-11-15 16:32:45][Dongjoon Hyun][issue:summary][REEF-949:12913158]
At first look, I thought the following TODO comment means we need to add `MesosUser` parameter for `REEFScheduler`.

{code}
final Protos.FrameworkInfo frameworkInfo = Protos.FrameworkInfo.newBuilder()
        .setUser("""") // TODO: make it configurable.
{code}

However, the current code already submits *its executing user* to Mesos correctly. I tested with `root` and `hadoop` account on Mesos 0.25.

In short, we had better remove the comment simply in order to prevent further confusion."
Geode,SATD Repayment,"[2017-09-22 09:22:23][Kirk Lund][commit][f5f59f060adf009a44c604d4f050cb290b415159]
GEODE-3638: cleanup minor issues found while prepping dunit talk

* fix some dunit rules
* add some dunit rule tests
* add dunit examples
","[2017-09-18 16:23:25][Kirk Lund][issue:summary][GEODE-3638:13103000]
Cleanup DUnit aka DistributedTest framework"
Hadoop,SATD Duplication,"[2019-06-29 22:14:29][bharatviswa504][pull:summary][1038]
HDDS-1736. Cleanup 2phase old HA code for Key requests.
","[2019-06-29 22:01:30][Bharat Viswanadham][issue:summary][HDDS-1736:13242320]
Cleanup 2phase old HA code for Key requests."
Accumulo,No Relation,"[2014-01-22 16:36:34][Sean Busbey][code-comment][dfafd9c1104d8359ca1eabe345661c541766d57f]
 Check for null, because we expect spans to come in much faster than flush calls.
           In the case of failure, we'd rather avoid logging tons of NPEs.
","[2014-01-22 16:36:34][Sean Busbey][commit][dfafd9c1104d8359ca1eabe345661c541766d57f]
ACCUMULO-2213 Make writer recovery in the Tracer more robust.

    * Cleans up writer reseting in the TraceServer, avoids overly broad catching.
    * tones down log levels in TraceServer to WARN because trace information is transient and we retry everything."
Camel,SATD Repayment,"[2014-05-27 18:26:06][Akitoshi Yoshida][commit][de56e0bddfaa007e6c224ed5a7e5abb085a95cc6]
CAMEL-7468: Make xmlTokenizer more xml-aware so that it can handle more flexible structures
","[2014-05-27 14:22:24][Akitoshi Yoshida][issue:summary][CAMEL-7468:12716817]
Make xmlTokenizer more xml-aware so that it can handle more flexible structures"
Zookeeper,No Relation,"[2017-11-27 15:10:13][Abraham Fine][code-comment(deleted)][75411ab34a3d53c43c2d508b12314a9788aa417d]
 The CallbackHandler interface here refers to
 javax.security.auth.callback.CallbackHandler.
 It should not be confused with Zookeeper packet callbacks like
  org.apache.zookeeper.server.auth.SaslServerCallbackHandler.
","[2017-11-27 15:10:13][Abraham Fine][commit][75411ab34a3d53c43c2d508b12314a9788aa417d]
ZOOKEEPER-2935: [QP MutualAuth]: Port ZOOKEEPER-1045 implementation from branch-3.5 to trunk

Author: Abraham Fine <afine@apache.org>

Reviewers: phunt@apache.org

Closes #417 from afine/ZOOKEEPER-2935 and squashes the following commits:

99bfbe94 [Abraham Fine] Add debugging line and improve ivy.xml by removing unnecessary excludes
1d6c7de5 [Abraham Fine] Fix missing test.data.kerberos.dir in build.xml
06d0b6fa [Abraham Fine] ZOOKEEPER-2935: [QP MutualAuth]: Port ZOOKEEPER-1045 implementation from  branch-3.5 to trunk.

Change-Id: I2b88221c0006e4336a39f74fd5a87d1aded68c90"
Spark,No Relation,"[2017-02-16 12:32:45][Sean Owen][commit][0e2405490f2056728d1353abbac6f3ea177ae533]
[SPARK-19550][BUILD][CORE][WIP] Remove Java 7 support

- Move external/java8-tests tests into core, streaming, sql and remove
- Remove MaxPermGen and related options
- Fix some reflection / TODOs around Java 8+ methods
- Update doc references to 1.7/1.8 differences
- Remove Java 7/8 related build profiles
- Update some plugins for better Java 8 compatibility
- Fix a few Java-related warnings

For the future:

- Update Java 8 examples to fully use Java 8
- Update Java tests to use lambdas for simplicity
- Update Java internal implementations to use lambdas

## How was this patch tested?

Existing tests

Author: Sean Owen <sowen@cloudera.com>

Closes #16871 from srowen/SPARK-19493.
","[2017-02-10 23:30:18][srowen][pull:comment][16871:100645304]
I see, so we need scalac to target 1.7 byte code for the Scala code it emits in 2.10. That would be fine for moving to Java 8 if javac (8) were handling Java code using Java 8, because the result would just be a mix of 7 and 8 bytecode but no big deal. Do I have that right?"
Incubator Pinot,SATD Repayment,"[2020-06-09 21:42:50][Xiaotian (Jackie) Jiang][code-comment][2d28c0f8fce781e094dacd8d53b6299ee42c5979]
 Terminate the process and wait for the clean up to be done
","[2020-06-06 00:42:34][Jackie-Jiang][pull:summary][5508]
- For all the Quickstarts, add shutdown hook once the instances are set up so that the hook can always be executed
- Use TERM signal instead of KILL so that process can execute the shutdown hook
- Wait for process to fully terminate before starting the next one
- Correctly handle query response before the table being ready"
Geode,No Relation,"[2018-09-21 10:50:50][Juan José Ramos][code-comment(deleted)][be52507b73e46cf1b8578b23c4ea41ee40afc625]
 TODO Auto-generated method stub
","[2018-09-21 10:50:50][Juan José Ramos][commit][be52507b73e46cf1b8578b23c4ea41ee40afc625]
GEODE-5314: Cleanup and document MBeanStatsMonitor child classes

- Fixed minor warnings.
- Added JUnit Tests for all modified classes.
- There's only one thread updating the mutable values so it's been
  decided to keep volatiles instead of moving to atomics.
- Documentation improved to better explain the thread-safety of the
  classes."
Ignite,SATD Duplication,"[2016-08-12 11:26:26][ptupitsyn][pull:summary][953]
IGNITE-3368 .NET: Improve test coverage
","[2016-06-24 16:21:05][Pavel Tupitsyn][issue:summary][IGNITE-3368:12982735]
.NET: Improve test coverage"
Druid,No Relation,"[2016-06-14 23:32:54][gianm][pull:comment][2998:67076946]
Btw the hashtable growing is there because these clear times (>100ms) are slow enough that they have a substantial impact on query performance – for simple queries the buffer-clearing actually takes up most of the time.
","[2016-05-19 17:36:35][gianm][issue:comment][2987:220397452]
I was thinking they would be fixed size just like the processing buffers (probably the same size to keep things simple). If a merge buffer isn't big enough to do the merging work, the query could either fail or it could write to temp files on disk (query's choice). If however much disk space we allow the queries to use is ALSO not enough then the query fails."
Flink,SATD Repayment,"[2015-01-18 09:22:30][Stephan Ewen][commit][f38e2039969f613c18edda2528e4e7b5018d46ad]
[FLINK-1384] [webfrontend] Remove unused JS libraries
","[2015-01-10 17:20:31][Stephan Ewen][issue:summary][FLINK-1384:12766656]
The following files seem to be unused and should be removed.

flink-runtime/resources/web-docs-infoserver/js/flot/chart-data-flot.js
flink-runtime/resources/web-docs-infoserver/js/flot/excanvas.min.js
flink-runtime/resources/web-docs-infoserver/js/flot/jquery.flot.pie.js"
Helix,SATD Duplication,"[2021-02-05 15:25:43][kaisun2000][code-comment][80de34b6facac640e50cc3692fd589bbcfd8caeb]
 Drop instance from admin tools and controller sending message to the same instance are
 fundamentally async. The race condition can also happen in production.  For now we stabilize
 the test by disable controller and re-enable controller to eliminate this race condition as
 a workaround. New design is needed to fundamentally resolve the expose issue.
","[2021-02-05 15:25:43][kaisun2000][commit][80de34b6facac640e50cc3692fd589bbcfd8caeb]
Fix TestCrushAutoRebalanceNonRack.testLackEnoughInstances unstable issue (#1630) (#1631)

This test still fails in production due to the race condition that the controller sending message is async
to test dropping instance. Thus when there is a message on the queue, dropping would throw
an exception. Here the test is stabilized by stopping the controller as a workaround to avoid such race condition."
Systemds,No Relation,"[2020-09-21 11:18:44][baunsgaard][commit][1f136eb3d0fdc17cc66c5c93006cc3ab6d81fc34]
[MINOR] Python API hardening, and stability

Minor changes in Python API startup for ease of startup if SystemDS is
installed somewhere else it will use that SystemDS.
This practically means that if you have SystemDS home set, it will allow
the python to use that SystemDS, while if it is not set, it will default
back to the installed jar files from the PIP install.

This is a debated topic in #992, where it is argued that it would make
it harder for a user if the PIP does not contain the jar files.

- Fix dual setup of systemds_context
- Added to usertest
","[2020-07-17 13:54:58][kev-inn][pull:comment][992:660120240]
Shouldn't pip packages not be dependant on other ressources? That would at least make it much simpler to install and I would be much in favor of a single `pip install` command."
Zookeeper,SATD Repayment,"[2018-09-28 14:38:24][Fangmin Lyu][code-comment][fdde8b006458f7b989c894af0eac7e124d271a1e]
 We can guarantee that when this line is executed, the cnxn of this 
 watcher has already been marked as stale (this method is only called 
 from ServerCnxn.close after we set stale), which means no watches 
 will be added to the watcher manager with this watcher, so that we
 can safely clean up this dead watcher. 

 So it's not necessary to have this line in the addRemovePathRWLock. 
 And moving the addDeadWatcher out of the locking block to avoid
 holding the write lock while we're blocked on adding dead watchers 
 into the watcherCleaner.
","[2018-09-23 04:48:47][lvfangmin][pull:comment][590:219688430]
Clean the dead watchers need to go through all the current watches, which is pretty heavy and may take a second if there are millions of watches, that's why we're doing lazily batch clean up here, we don't want to block addDeadWatcher, which is called from the Cnxn.close while we're doing the clean work.

The totalDeadWatchers is used to avoid OOM when the watcher cleaner cannot catch up (we haven't seen this problem even with heavy reconnecting scenario), it is suggested to be set to something like 1000 * watcherCleanThreshold. The watcherCleanThreshold is used to control the batch size when doing the clean up, there is trade off between GC the dead watcher memory and the time complexity of cleaning up, so we cannot set this too large."
Incubator Weex,No Relation,"[2017-12-22 15:40:06][Hanks][code-comment(deleted)][8668b0f9ee4c42407c69240542b80dda4729848f]
 First, split based on boolean or ||
","[2017-12-22 15:40:06][Hanks][commit][8668b0f9ee4c42407c69240542b80dda4729848f]
- [example] remove legacy .we examples

Remove source codes of .we examples, then rebuild the examples, replace the generated bundles in ios and android."
Beam,No Relation,"[2017-04-26 22:28:06][robertwb][pull:comment][2644:113577978]
Oh, that would be much nicer. I'll see if I can get this to work.
","[2019-10-25 00:49:11][Valentyn Tymofieiev][issue:comment][BEAM-115:16959333]
I will rename that TODO to use https://issues.apache.org/jira/browse/BEAM-366."
Lucene Solr,No Relation,"[2016-03-02 09:22:20][Steve Rowe][code-comment(deleted)][9427b7402da33cccff9692bb4d7146dad4bb16e1]
* Chain several Iterators, so that this iterates
 *  over all of them in sequence.
 *
 * @deprecated This class is no longer used by Solr, and may be removed in future versions
","[2016-03-02 09:22:20][Steve Rowe][commit][9427b7402da33cccff9692bb4d7146dad4bb16e1]
SOLR-8764: Remove deprecated methods and classes"
Shardingsphere Elasticjob,SATD Duplication,"[2020-10-19 19:29:09][Liang Zhang][code-comment][dc25797275052f4519e7c59331be295bb3ee9d44]
 TODO default value is 3000
 TODO default value is 3000
","[2020-10-19 19:29:09][Liang Zhang][commit][dc25797275052f4519e7c59331be295bb3ee9d44]
Add todo to default value (#1600)"
Lucene Solr,No Relation,"[2013-12-02 18:42:23][Mark Robert Miller][code-comment][7ab2e1f787c252a8e931e40cce2a8d4b5edd7910]
 field to use to determine and enforce document uniqueness.
","[2009-09-10 18:30:12][Jason Venner (www.prohadoop.com)][issue:comment][SOLR-1301:12753754]
Within a Map/Reduce task, there is usually a significant constraint on available ram, cpu and disk bandwidth.

For my current use case, if we turn on the various background write threads, I will need to make these configurable to help me manage the task resource consumption.

In the ideal world, the Map/Reduce framework, via cluster and job configuration, is taking care of running the tasks in parallel, and the tuning to optimize throughput is happening at that level."
Hadoop,No Relation,"[2013-03-24 15:56:18][Suresh Srinivas][code-comment][698e3f8ae57f1a587b4f06711990cd1f0eff4ef5]
 Skip ""sticky bit"" tests on Windows.
","[2013-05-15 16:36:05][Chris Nauroth][issue:comment][HDFS-2802:13658521]
I just want to drop a quick note about Windows compatibility for snapshots.  I've done a full test run of all snapshots tests on Windows.  Out of all those new tests, only 1 failed!  It was {{TestNestedSnapshots#testSnapshotLimit}}.  It failed on test timeout while trying to create 2^16 snapshots.  I suspect the failure is just due to poor performance on my VM rather than a Windows compatibility concern.  If so, then this is easily fixed by tuning the test timeout.  Nice job everyone on implementing a major new feature without accidental platform dependencies!"
Arrow,SATD Repayment,"[2020-01-27 08:44:49][David Li][code-comment][16441d4a1564c3152a914860c5dee634a6587ab2]
 Unlike DoGet, this method fairly reliably will write the message to the stream, so even without the fix
 for ARROW-7343, this won't leak memory.
 However, it will block if FlightClient doesn't check for cancellation.
","[2020-01-27 08:44:49][David Li][commit][16441d4a1564c3152a914860c5dee634a6587ab2]
ARROW-7343: [Java][FlightRPC] prevent leak in DoGet

This changes ArrowMessage and FlightService/FlightClient so that if gRPC fails to actually write the message to the stream (as it occasionally does), we don't leak the memory associated with ArrowMessage. It also fixes a case where clients could block indefinitely in DoPut.

Closes #6003 from lidavidm/flight-leak and squashes the following commits:

ff61c7891 <David Li> ARROW-7343:  fix leak in DoGet/blocking in DoPut

Authored-by: David Li <li.davidm96@gmail.com>
Signed-off-by: David Li <li.davidm96@gmail.com>"
Incubator Pagespeed Ngx,SATD Duplication,"[2013-11-21 21:26:15][Otto van der Schaaf][code-comment][9bbe912bd7173da8c4844b84552d8af1692e5902]
 Some tests are flakey under valgrind. For now, add them to the expected failures
 when running under valgrind.
","[2013-11-21 21:26:15][Otto van der Schaaf][commit][9bbe912bd7173da8c4844b84552d8af1692e5902]
Valgrind: Add an automated test

This makes nginx run in the background under valgrind,
with both a master and a child process.
Valgrind errors will be redirected to `valgrind.log`.
When `USE_VALGRIND` is set, all system tests will be run under valgrind,
and at the end a new test is appended which ensures no valgrind errors
where encountered.

It is also worth noting that:
- There is a new file, `valgrind.sup`, which contains a few suppressions.
- Some tests behave flakey under valgrind. For now these are appended
  to the expected failures (when under valgrind only).
- 'Possibly lost' errors are all suppressed to get the amount of false
  positives manageable."
Ignite,No Relation,"[2016-05-23 19:42:45][sboikov][code-comment][ee7e2c7d55a98f496e82ccd544090297b9e33e38]
 TODO IGNITE-2953: uncomment the following assert when the issue will be fixed.
                              assertEquals(value(0), res);
","[2016-03-31 13:11:35][Artem Shutak][issue:comment][IGNITE-2899:15219846]
Found that {{BinaryOffheapValue}} leaks to {{EntryProcessor}}'s user code via {{entry.getValue()}}. The issue happens under the following conditions:
- User uses {{cache.withKeepBinary()}}
- invokeAll operation
- ATOMIC cache in OFFHEAP_TIRED data mode

I will fix the founded issue in bounds of this task."
Kafka,SATD Repayment,"[2015-02-03 09:16:55][Jay Kreps][commit][1c6d5bbac672cbf49591aed0889510b10e3285fa]
KAFKA-1915: Add checkstyle for java code.
","[2015-02-03 05:47:17][Jay Kreps][issue:summary][KAFKA-1915:12771942]
Integrate checkstyle for java code"
Hadoop,SATD Repayment,"[2015-04-22 13:48:16][Jakob Homan][commit][e54a3e1f4f3ea4dbba14f3fab0c395a235763c54]
HADOOP-11850: Typos in hadoop-common java docs. Contributed by Surendra Singh Lilhore.
","[2015-04-20 19:13:28][Surendra Singh Lilhore][issue:summary][HADOOP-11850:12822424]
Typos in hadoop-common java docs"
Systemds,SATD Repayment,"[2018-08-03 19:17:15][EdgarLGB][commit][382f847de6e33cdb5386b5eb5912eb5da0dff8d6]
[MINOR] Various paramserv refactorings and code cleanups

Closes #814.
","[2018-08-03 22:52:03][EdgarLGB][pull:summary][814]
Hi @mboehm7 ,

Here is the PR for cleaning up and refactoring some code as well as polishing the ps script.

Thanks for the review,
Guobao"
Lucene Solr,No Relation,"[2020-06-24 21:49:05][madrob][pull:comment][1606:445191314]
I'm not sure this is the right error code. A 5xx code usually indicates a server error - and I'm not sure how we effectively convey to clients that this error is something that is ok to retry. They might log the message, but retry logic will typically look at the code returned as a first branch in the decision tree. Need to think about this and maybe look at some examples.
","[2020-06-25 16:22:09][Andrzej Bialecki][issue:comment][SOLR-14588:17145066]
[~atris] please see the comment above - the title of this issue and the CHANGES entry is quite misleading (it's actually a ""max JVM heap usage"" breaker, not just ""JVM"", which is meaningless) and the docs are lacking."
Lucene Solr,SATD Repayment,"[2017-01-30 21:04:42][yonik][code-comment][c8edbe8663769392d422e84c05f45530833e48cc]
 Verify if the collection deletion result in proper cleanup of snapshot metadata.
","[2017-01-28 04:49:02][Hrishikesh Gadre][issue:summary][SOLR-10049:13038618]
During the collection deletion the snapshot metadata cleanup is not happening (even though the actual index files associated with the snapshot are being deleted). We should ensure that the snapshot metadata is cleaned properly during the collection deletion."
Druid,SATD Repayment,"[2019-08-03 12:05:21][Eugene Sevastianov][code-comment][3f3162b85e269749bf0aa848f435409b3a1db8fe]
 The field is empty, removing it because an empty array field may be misleading
 for the recipients of the truncated response context.
","[2019-08-01 18:30:16][leventov][pull:comment][8157:309838142]
I think the logic of this block should avoid producing empty array because it may be misleading."
Hadoop,SATD Repayment,"[2011-03-04 03:52:23][Owen O'Malley][code-comment][55e27baed59a13f41bbab65d6843b2ca693d652f]

       Further SaslException should be ignored during cleanup and
       original exception should be re-thrown.
","[2010-02-16 23:50:42][Kan Zhang][issue:comment][HADOOP-6543:12834553]
Add a new patch that ignores the previous findbugs warning, since further SaslExceptions should be ignored during cleanup and the original exception should be re-thrown."
Hadoop,No Relation,"[2016-01-28 17:43:17][Karthik Kambatla][code-comment][ee005e010cff3f97a5daa8000ac2cd151e2631ca]
 If the original create failed for a legit but transitory
 reason, the append will fail because the file now doesn't exist,
 resulting in a confusing stack trace.  To avoid that, we set
 the cause of the second exception to be the first exception.
 It's still a tiny bit confusing, but it's enough
 information that someone should be able to figure it out.
","[2016-01-27 20:34:44][Karthik Kambatla][issue:comment][HADOOP-12702:15120115]
Looks mostly good. Few minor comments:
# Should close() call flush()?
# rollLogDirIfNeeded: The comments in the method are wrongly indented. And, the exception message at the end should be fixed up to say ""Failed to *create* new log file""."
Hadoop,No Relation,"[2006-11-14 22:35:22][Doug Cutting][code-comment][93c41fd87f0f227a9020fc4b60737b8eda01175f]
 Substitute the hardcoded libdirs into the rpath.
","[2006-11-07 22:24:36][Owen O'Malley][issue:comment][HADOOP-538:12447943]
I think the naming of the .so's is confusing. How about:

lib/native/Linux-i386-32/libhadoop.so     // prebuilt library checked into svn
build/hadoop-*/lib/native/prebuilt/Linux-i386-32/libhadoop.so    // prebuilt packaged location

The compiled library would still be packaged into:
build/hadoop-*/lib/native/Linux-i386-32/libhadoop.so

I think we should remove the ""package-native"" target and just make the ""package"" target copy any compiled libraries (for all platforms) into the package directory.

So to do a full build, it would be:

ant clean compile-native tar"
Kafka,No Relation,"[2019-09-25 11:58:54][Colin Patrick McCabe][commit][92688ef82ccbeee6014ae9c1db64fb4289b7bdd7]
MINOR: improve the Kafka RPC code generator (#7340)

Move the generator checkstyle suppressions to a special section, rather
than mixing them in with the other sections.  For generated code, do not
complain about variable names or cyclic complexity.

FieldType.java: remove isInteger since it isn't used anywhere.  This way, we
don't have to decide whether a UUID is an integer or not (there are arguments
for both choices).  Add FieldType#serializationIsDifferentInFlexibleVersions
and FieldType#isVariableLength.

HeaderGenerator: add the ability to generate static imports.  Add
IsNullConditional, VersionConditional, and ClauseGenerator as easier ways of
generating ""if"" statements.
","[2019-09-20 14:54:31][jsancio][pull:comment][7340:326667568]
Right. I was reading the code to see where this condition is checked. So that it is easier to verify should we change the documentation to `other.highest() >= highest would be true`.?"
Reef,No Relation,"[2014-10-22 16:59:09][Markus Weimer][code-comment][50444bba1e068613bf28eda1600d303b849f0a05]
*
 * A vertex in the object graph.  There is no edge type, since that would be redundant.
","[2014-10-22 16:59:09][Markus Weimer][commit][50444bba1e068613bf28eda1600d303b849f0a05]
Initial merge of Wake, Tang and REEF into one repository and project

  * Wake is now a subproject of REEF in reef-wake
  * Tang is now a subproject of REEF in reef-tang
  * All maven artifacts are now in the org.apache.reef namespace
  * All packages are now in the org.apache.reef namespace
  * All Avro types are now in the org.apache.reef namespace
  * All Protocol Buffers types are now in the org.apache.reef namespace
  * Cleaned up some dead code and POM entries"
Hive,No Relation,"[2019-05-16 22:54:56][vineetgarg02][pull:comment][630:284927275]
With this change instead of having a static instance now we will create a different instance each time this rule needs to be executed. What is the reason to change this?
","[2019-03-01 01:06:57][Jesus Camacho Rodriguez][issue:summary][HIVE-21365:13218787]
Using subprograms to decrease number of planner instantiations and benefit fully from metadata providers caching, among other benefits."
Pulsar,No Relation,"[2020-11-16 10:19:11][feynmanlin][code-comment][f8848c83656c25e27eaf5b2df2fa9d8626302227]
remove topic-level policies, namespace-level should be used, interval becomes 2 seconds
","[2020-11-16 10:19:11][feynmanlin][commit][f8848c83656c25e27eaf5b2df2fa9d8626302227]
Support topic-level DeduplicationSnapshotInterval (#8552)

Master Issue: #8237

### Motivation
Currently we take de-duplication snapshots based on size. If the topic has relatively low traffic, the de-duplication cursor will not move. This can cause messages that are not able to be deleted based on the retention policy. We should add a policy to take de-duplication snapshots based on time.

### Modifications
add api get/set/remove topic-level `DeduplicationSnapshotInterval`

### Verifying this change
TopicDuplicationTest.java"
Zookeeper,No Relation,"[2018-02-22 16:11:32][Randgalt][pull:comment][377:170009123]
I put it in `OldEphemeralType` so it's easier to remove and reason about. The emulation is a separate concern.
","[2017-09-22 22:58:34][Patrick D. Hunt][issue:comment][ZOOKEEPER-2901:16177298]
It's very unfortunate that we have to turn ttl off by default. I'm wondering if we should relax the b/w compat requirement in this case - esp given it's a config option and one that we could highlight in the release notes and in the LOG message if the server were ""misconfigured"". What do folks think?"
Beam,SATD Duplication,"[2021-01-13 13:09:10][Brian Hulette][commit][4451c030ef79e69938ca03106fea7e195833c9a6]
[BEAM-11531] Remove transform implementation (#13705)

* Remove transform implementation

* move to attrs on DeferredSeries, TODO for transform
","[2021-01-13 18:10:52][TheNeuralBit][pull:comment][13705:556729387]
Done. Also added a jira/TODO for transform"
Cloudstack,No Relation,"[2015-12-05 19:11:21][Remi Bergsma][commit][e37842cbd3407c934a6ecc2515b60742b52d1738]
Merge pull request #1108 from rafaelweingartner/master-lrg-cs-hackday-004

Removed the PlannerBase class because it is does not bring contribution to ACS' code.Removed the PlannerBase class because it is does not bring contribution to ACS' code.

We changed com.cloud.deploy.FirstFitPlanner, now it doesnt extends the PlannerBase and implements the com.cloud.deploy.DeploymentPlanner.

We also removed the method com.cloud.deploy.DeploymentPlanner.check(VirtualMachineProfile, DeploymentPlan, DeployDestination, ExcludeList) that was not used anywhere.

Additionally, we removed the _ from FirstFitPlanner's attributes name, in order to have them in a more standard way.

* pr/1108:
  Removed PlannerBase empty class

Signed-off-by: Remi Bergsma <github@remi.nl>
","[2015-12-01 10:11:51][DaanHoogland][pull:comment][1108:46260293]
this class shows way more diffs than needed. please check line endings and force push."
Hive,SATD Duplication,"[2016-09-08 09:42:26][Jesus Camacho Rodriguez][code-comment][58d1befa2131254b53122b3573189ac1c5022217]
 TODO: we could generate vector row batches so that vectorized execution may get triggered
","[2016-09-07 04:55:06][ashutoshc][pull:comment][98:77759847]
May want to leave a TODO to generate vector row batches here so that vectorized execution may get triggered."
Shardingsphere Elasticjob,SATD Duplication,"[2020-10-19 19:29:09][Liang Zhang][code-comment][dc25797275052f4519e7c59331be295bb3ee9d44]
 TODO default value is 3000
 TODO default value is 3000
","[2020-10-19 11:29:04][terrymanu][pull:summary][1600]
Add todo to default value"
Trafficcontrol,No Relation,"[2020-02-17 10:09:41][mattjackson220][code-comment][18fe13ac638557b5532813bce8ab3ad2d964fe49]
 For enums we need to provide the integer constant.
","[2020-02-10 15:37:51][mattjackson220][pull:comment][3534:377138820]
so this one was also copied from above but the above use has ""// empty response object because Perl"" . is that something we still need? or can i change both of these to be api.HandleErr instead?"
Flink,SATD Repayment,"[2021-02-27 07:18:40][Piotr Nowojski][code-comment][01352aa7ddd5e9abf15984ff77fa929b1eabaff4]
 Go through the serialization/deserialization to provide better test coverage in the
 unit tests using test harnesses. Otherwise bugs in event serialisation would be only
 visible in ITCases or end to end tests.
","[2021-02-27 07:18:40][Piotr Nowojski][commit][01352aa7ddd5e9abf15984ff77fa929b1eabaff4]
[FLINK-21517][tests] Test harnesses should not bypass serialization stack for events

Since FLINK-19297 we accidentally removed a test coverage for event (de)serialization from a lot of the unit tests,
that were/are using test harnesses. For example because of that I almost broke 1.12.2 release,
since `stop-with-savepoint --drain` was never only tested using test harnesses (didn't have an ITCases
and/or end to end test)."
Drill,No Relation,"[2016-11-04 15:57:44][Parth Chandra][commit][ee3489ce3b6e5ad53e5c3a59b6e2e4e50773c630]
DRILL-4800: Various fixes. Fix buffer underflow exception in BufferedDirectBufInputStream. Fix writer index for in64 dictionary encoded types. Added logging to help debug. Fix memory leaks. Work around issues with of InputStream.available() ( Do not use hasRemainder; Remove check for EOF in BufferedDirectBufInputStream.read() ). Finalize defaults. Remove commented code.
Addressed review comments

This closes #611
","[2016-11-04 16:49:46][paul-rogers][pull:comment][611:86586621]
...FieldsiSerial --> ..FieldsSerial (remove extra ""i"")"
Cxf,No Relation,"[2020-11-28 17:16:07][dufoli][pull:comment][721:735258154]
I have tried many things to code what you want without success.  So I will stick to old implementation but if you want to change that in another patch feel free to do so. Because I am not enough skilled to do it. It s too complicated for me ;-)
","[2020-10-26 18:50:48][Andriy Redko][issue:comment][CXF-8340:17220930]
Indeed great news, [~dufoli] , would you be open to share to configuration files for native-image creation, it would greatly help us, thank you."
Incubator Pinot,SATD Duplication,"[2016-12-15 13:27:58][Jackie-Jiang][commit][8cb6e4873034283b327d674638a90c6bfe839713]
Add backward compatible for the new selection only logic. (#910)

In the old code, the selection only columns order in data schema
might be different with the actual order. Add code to handle this,
and after server update to the latest version, remove the code for
backward compatible to get the highest performance.
","[2016-12-15 21:26:29][mcvsubbu][pull:comment][910:92703189]
I suggest to create a jira ticket that has the version number of the server that must be deployed everywhere before we can remove this code."
Lucene Solr,No Relation,"[2015-05-22 18:58:29][Erick Erickson][code-comment][375899fdbd3512fc33c5c872c88c244cdf3f7541]
 Start to index some documents to instantiate the new tlog
","[2015-04-27 10:33:47][Renaud Delbru][issue:comment][SOLR-6273:14513880]
Here is a new patch with the following changes:

- Renamed 'slice' into 'shard'

- Removed an optimisation in the replication of tlog files which could lead to duplicate tlog entries on a slave node. We were trying to avoid transferring tlog files that were already present on the slave nodes in order to reduce network transfer. However, tlog files between the master and slave can differ, overlap, etc. making the comparison difficult to achieve. We removed this optimisation and now during a recovery the tlog replication will transfer all the tlog files from the master to the slave, and replace on the slave node all the existing tlog files."
Samza,SATD Duplication,"[2017-04-14 15:05:24][shanthoosh][pull:summary][124]
SAMZA-1209: Improve error handling in LocalStoreMonitor
","[2017-04-13 03:50:40][Shanthoosh Venkataraman][issue:summary][SAMZA-1209:13063686]
Improve error handling in LocalStoreMonitor"
Geode,SATD Duplication,"[2017-02-28 06:09:04][metatype][pull:summary][409]
GEODE-880 Remove unused classes
","[2016-01-29 01:30:09][Kirk Lund][issue:summary][GEODE-880:12934977]
Remove unused classes"
Drill,No Relation,"[2020-01-09 16:31:13][Paul Rogers][code-comment][0af04cd44622c288278965b13685907fd1e40fb4]
 TODO: Move this logic to TypesHelper or the ValueVector so it
 is more generic and reusable.
","[2020-01-03 04:52:56][paul-rogers][pull:comment][1944:362705846]
OK, so the right way to do this would be to either a) provide a method on the VV base class, or better, generate a `TypeHelper `method since this info can be computed from just the type."
Beam,No Relation,"[2016-07-14 16:42:11][Kenneth Knowles][code-comment][79c26d9c1577aac50a3e8f475d75629c87ba2c87]
 Remember the field description of the instrumented type.
","[2016-07-01 03:36:30][kennknowles][pull:comment][521:229846570]
This is awesome. It is a lot to chew on. I need to learn more about the meaning of various bytebuddy interfaces. Given the tests, I am pretty happy. I'd love even more tests, given the potential fragility and debugging challenges of dropping to bytecode. I will think a bit about what they might be."
Helix,No Relation,"[2020-01-09 11:24:00][Huizhi L][code-comment][2d9e8247a3197141ebe39813f3fe088a01e9b3e3]

     * Filter out stale sessions. If a session id is not null and not the same as current session
     * id, this session is expired. With this filtering, expired sessions are NOT handled,
     * so performance is expected to improve.
","[2019-12-23 22:46:12][jiajunwang][pull:comment][642:361019555]
nit, just my personal opinion, this is too verbose. This var is very clear to be recording and logging what exception we see during the operation."
Hadoop,No Relation,"[2012-10-19 02:25:55][Tsz-wo Sze][code-comment][d5d2628e4477b3e20391f8ad3a32c2889f44a4fb]
*
   * Simple test of how fast the code path is to write edits.
   * This isn't a true unit test, but can be run manually to
   * check performance.
   * 
   * At the time of development, this test ran in ~4sec on an
   * SSD-enabled laptop (1.8ms/batch).
","[2012-11-01 22:52:57][Sanjay Radia][issue:comment][HDFS-2802:13489103]
Aaron
  wrt to your alternate proposal, folks can get confused about which of the two series of documents matched the patches in the Jira. Can you please rename yours as snapshot-alternate-design-proposal.{tex,pdf} and also reflect that in the title inside the document."
Helix,SATD Repayment,"[2015-11-20 15:54:34][Lei Xia][commit][7bbb20be67a939a57f33d8f6d7c814b1dc246575]
[HELIX-616] Change JobQueue to be subclass of Workflow instead of WorkflowConfig.
","[2015-11-20 23:50:11][Lei Xia][issue:summary][HELIX-616:12915033]
Currently, JobQueue is subclass of WorkflowConfig instead of Workflow.  It is not possible for client to create an initial queue with jobs in it.  It has to call create() to create an empty queue, and call enqueue() to add job to the queue. The problem is once create() call returns, the queue is already starts to run, if the queue is recurrent queue, the initial schedule run of the queue contains empty job set."
Hbase,No Relation,"[2017-07-06 21:58:32][Michael Stack][code-comment][6786b2b63e9ec7fe45c5ed800a54f4f80358c3c3]
*
   * Parse a 32-bit unsigned integer from the text.  Unlike the Java standard
   * {@code Integer.parseInt()}, this function recognizes the prefixes ""0x""
   * and ""0"" to signify hexadecimal and octal numbers, respectively.  The
   * result is coerced to a (signed) {@code int} when returned since Java has
   * no unsigned integer type.
","[2017-06-26 20:25:54][Michael Stack][issue:comment][HBASE-17056:16063706]
Remove 25MB worth of code!

This patch depends on our new hbase-thirdparty project being available.

Removes all generated code. Simplifies poms. Fixed doc too."
Ignite,SATD Repayment,"[2016-06-29 18:30:09][dkarachentsev][code-comment(deleted)][93ed85b5ef92d664d16318096a077c797d3449fa]
 TODO: GG-11220 cleanup when cache/partition is destroyed.
","[2016-06-29 18:30:09][dkarachentsev][commit][93ed85b5ef92d664d16318096a077c797d3449fa]
GG-11220 - Cleanup metadata storage when cache/partition is destroyed"
Hbase,No Relation,"[2018-06-25 12:13:04][Michael Stack][commit][0db2b628d6db90b5ad300773d81e9cdb7dd0ebcd]
HBASE-20770 WAL cleaner logs way too much; gets clogged when lots of work to do

General log cleanup; setting stuff that can flood the log to TRACE.
","[2018-06-22 04:58:48][Reid Chan][issue:comment][HBASE-20770:16520017]
Possibly some new files added? {{Removing}} without following error or warn or exception should be cleaned, like below.
{code}
2018-06-21 01:19:12,761 DEBUG org.apache.hadoop.hbase.master.cleaner.HFileCleaner: Removing hdfs://ns1/hbase/archive/data/default/IntegrationTestBigLinkedList/e98cdb817bb3af5fa26e2b885a0b2ec6/meta/bd49572de3914b66985fff5ea2ca7403
{code}
Were you running IntegrationTestBigLinkedList? I could try on local."
Incubator Pinot,SATD Duplication,"[2017-06-12 14:27:55][Jennifer Dai][code-comment][6e4a60fa49048b9a04b17cc6e0ef2f2219de72fc]
 TODO: TInclude the generated file name in the response to the server
","[2017-06-12 18:40:28][mcvsubbu][pull:comment][1491:121493484]
Add a TODO to include the generated file name in the response to server"
Dubbo,SATD Repayment,"[2019-12-11 20:38:40][Tyrael][commit][938a46641ce76df26a01d5f7543b474219c78240]
Finish AccessLogFilter TODO (#5270)
","[2019-10-31 08:30:02][wangkezun][pull:summary][5270]
fix AccessLogFilter TODO"
Hbase,SATD Repayment,"[2018-02-22 09:40:20][Josh Elser][code-comment][4cf846d08570256115ac8c2787d0f7fbf162be23]
 25KB
 As of 2.0.0-beta-2, this 1KB of ""Cells"" actually results in about 15KB on disk (HFiles)
 This is skewed a bit since we're writing such little data, so the test needs to keep
 this in mind; else, the quota will be in violation before the test expects it to be.
 1KB
 Sanity check: the below assertions will fail if we somehow write too much data
 and force the table to move into violation before we write the second bit of data.
","[2018-02-22 09:40:20][Josh Elser][commit][4cf846d08570256115ac8c2787d0f7fbf162be23]
HBASE-20035 Stabilize the flaky TestQuotaStatusRPCs

The test will fail if the quota moves to violation before
the second half of the test.

Signed-off-by: Michael Stack <stack@apache.org>"
Myfaces Tobago,No Relation,"[2010-06-11 16:36:16][Udo Schnurpfeil][code-comment][2141b2407900305987d877bd79b727cde16b9b53]
 XXX is there a better way? Get it from Tobagos generated faces-config.xml?
","[2010-06-11 16:36:16][Udo Schnurpfeil][commit][2141b2407900305987d877bd79b727cde16b9b53]
clean up testing classes
 - add new base class for JSF-tests (with proper initilized objects)
 - removing dependencies to shale (using myfaces-test12 instead)
 - removing Mock classes for JSF of Tobago (using myfaces-test12 instead)
 - moving other test helper from tobago-jsf-compat to tobago-core
 - remove duplicate code"
Incubator Pinot,No Relation,"[2020-06-05 18:16:31][Xiaotian (Jackie) Jiang][commit][34435931c23427720c0c8eab99f045cb459e0a44]
Enhance and simplify the filtering (#5444)

Removed the methods that complicate the code but provide no value:
- BlockDocIdSet
  - getRaw
- FilterBlockDocIdSet
  - getMinDocId
  - getMaxDocId
  - setStartDocId
  - setEndDocId
- BlockDocIdIterator
  - currentDocId
- ScanBasedDocIdIterator
  - isMatch

Uniformed the behavior of all filter-related classes to bound the return docIds with numDocs
Simplified the logic of AND/OR handling
Pushed down the AND smart handling logic to BlockDocIdIterator to ensure the best performance:
- AndDocIdSet might return RangelessBitmapDocIdIterator which can be merged with other iterators
- OrDocIdSet might return BitmapDocIdIterator which can be merged with other iterators

Tested all the queries (10K PQL, 10K SQL) within the query file using HybridClusterIntegrationTest
","[2020-06-02 06:10:35][chenboat][pull:comment][5444:433641032]
i think a better name could be candidateDocId because the while loop() is searching for the next doc Id exists in all iterators. maxDocId to many ppl mean the maximum doc id in the iterator."
Geode,SATD Duplication,"[2019-12-10 21:49:01][gemzdude][pull:summary][4459]
Improve cleanup logic in create_instance.sh

Delete any existing instance with our name in all available zones.
","[2019-12-10 21:20:19][Scott Jewell][issue:summary][GEODE-7567:13273707]
Improve create_instance cleanup logic"
Fluo,SATD Repayment,"[2014-12-04 12:38:42][Mike Walch][commit][c9bb1761242e0788e5d1fd939d859c1d6793df65]
Merge pull request #358 from mikewalch/fluo-348

Closes #348 - Clean up ScannerConfiguration and create unit test
","[2014-12-02 13:14:14][mikewalch][pull:summary][358]
Closes #348 - Clean up ScannerConfiguration and create unit test"
Incubator Brooklyn,No Relation,"[2016-01-20 21:07:12][Alex Heneveld][code-comment][2a432cf38a2fb0571e4f76604c3a532b1f89c2c6]
 not the cleanest way to enforce a clean shutdown, but a simple and effective way;
 * usage is restricted to BrooklynRestApiLauncher and subclasses, to stop it inline.
 * the main app stops the server in a more principled way using callbacks.
","[2015-07-29 13:52:15][neykov][pull:comment][771:35760368]
All apps are stopping by now, but you are right the suggested name will better reflect the code in it."
Nifi Minifi Cpp,No Relation,"[2019-06-14 15:35:54][Marc Parisi][code-comment(deleted)][23b30f7e5521efe0ec488057036a1b52f19132fe]
 Op will be reused for forwarding response.
","[2019-06-14 15:42:24][phrocker][pull:summary][594]
MINIFICPP-923: remove librdkafka, and deal with some bugs"
Pulsar,No Relation,"[2019-09-16 03:56:03][Sergii Zhevzhyk][code-comment][716daff074cd84cf20f38c79ee96f0b651f2550c]
 CHECKSTYLE.OFF: MethodName
","[2019-09-05 19:46:09][sijie][pull:comment][5115:321447891]
Use `CHECKSTYLE.OFF` and `CHECKSTYLE.ON` comments.

```
// CHECKSTYLE.OFF: MethodName
...
// CHECKSTYLE.ON: MethodName
```"
Nifi,No Relation,"[2017-05-02 13:24:07][Andy LoPresto][commit][7d242076ce1d0a555e2ea68d88f29b7461d37b9a]
NIFI-3594 Implemented encrypted provenance repository.
Added src/test/resources/logback-test.xml files resetting log level from DEBUG (in nifi-data-provenance-utils) to WARN because later tests depend on MockComponentLog recording a certain number of messages and this number is different than expected if the log level is DEBUG.

This closes #1686.

Signed-off-by: Bryan Bende, Yolanda M. Davis, and Mark Payne
","[2017-04-24 14:37:08][markap14][pull:comment][1686:112963050]
Was this TODO intended to remain here? Not sure what is actually to be done..."
Lucene Solr,No Relation,"[2018-04-10 06:57:13][Karl Wright][commit][661fdf3a43e6d7a8b8b28254f69387209bafcd75]
LUCENE-8245: Add more tests that demonstrate problems with GeoComplexPolygon.
","[2018-04-09 11:52:28][Ignacio Vera][issue:comment][LUCENE-8245:16430421]
I don't think it either. I will add later today or tomorrow a random test that it is extremely good to find all these cases. It can be used to validate solutions."
Hive,No Relation,"[2016-08-10 10:11:38][Mithun RK][code-comment][925f195523aba1e2bfbfebf06c6b87fafa4dbd67]
 TODO: periodically reload a new HiveConf to check if stats reporting is enabled.
","[2016-08-10 10:11:38][Mithun RK][commit][925f195523aba1e2bfbfebf06c6b87fafa4dbd67]
HIVE-13754: Fix resource leak in HiveClientCache (Chris Drome, via Mithun Radhakrishnan)"
Incubator Pinot,SATD Repayment,"[2018-03-11 18:26:14][Subbu Subramaniam][commit][da16c679272bd5b09721d4edc0910dd3a5bb8734]
Issue-2583: Step 1 to support generic streams (#2606)

* Issue-2583: Step 1 to support generic streams

- Create a new package com.linkedin.pinot.core.realtime.stream in pinot-core.
- Move KafkaStreamMetadata to com.linkedin.pinot.core.realtime.stream, renaming it to StreamMetadata
- Get rid of (unused) StreamMetadata
- Move (and rename) classes to be kafka-agnostic (which they are for most parts)
- Add TODO in a couple of places where classes are kafka-specific

* Moved StreamMetadata to different package as suggested in review comment
","[2018-03-09 02:07:06][mcvsubbu][pull:summary][2606]
- Create a new package com.linkedin.pinot.core.realtime.stream in pinot-core.
- Move KafkaStreamMetadata to com.linkedin.pinot.core.realtime.stream, renaming it to StreamMetadata
- Get rid of (unused) StreamMetadata
- Move (and rename) classes to be kafka-agnostic (which they are for most parts)
- Add TODO in a couple of places where classes are kafka-specific"
Geode,SATD Repayment,"[2015-07-29 09:33:03][Kirk Lund][code-comment][94939c1f9cc3e09c4beee1155404dd82b9aca13f]
*
 * Suite of tests for the test.golden Golden Test framework classes.
","[2015-07-29 09:33:03][Kirk Lund][commit][94939c1f9cc3e09c4beee1155404dd82b9aca13f]
GEODE-127: Improve test reliability and execution speed.

Recategorize tests involving spawned processes and file system I/O as
IntegrationTests.

Improve reliability and shorten execution time. Fix up asynchronous waits,
correct JUnit 4 syntax and misc code tidying.

Add new TestSuite classes for targeted testing of test.golden and
test.process packages."
Ambari,No Relation,"[2016-12-20 09:54:41][Nate Cole][code-comment][749a5b2dc583a5571b28e2710f0018abe7f12383]
*
   * Closes <code>c</code> logging any <code>IOException</code> as warning via this class' logger.
","[2016-12-20 09:54:41][Nate Cole][commit][749a5b2dc583a5571b28e2710f0018abe7f12383]
AMBARI-19419. Code cleanup: empty blocks (Attila Doroszlai via ncole)"
Cxf,SATD Repayment,"[2017-08-10 14:00:07][Daniel Kulp][code-comment(deleted)][5f277de68568c7e3df68c2f5f40a09faf353192f]
 TODO Auto-generated method stub
 TODO Auto-generated method stub
","[2017-08-10 14:00:07][Daniel Kulp][commit][5f277de68568c7e3df68c2f5f40a09faf353192f]
Remove a bunch of pointless ""TODO Auto-generated method"" comments"
Qpid Dispatch,SATD Repayment,"[2018-10-30 13:46:41][Ted Ross][commit][413d727b6e1772d87a23f88261cdced4940d33ee]
DISPATCH-1159 - Removed the term ""uplink"" from the edge router implementation.
","[2018-10-30 17:46:32][Ted Ross][issue:summary][DISPATCH-1159:13195180]
Remove the term ""uplink"" from the edge router - It's confusing"
Hadoop,SATD Repayment,"[2020-03-12 12:29:03][Szilard Nemeth][commit][5ead9c15ca6766769d2dd73e91d050ecdede724c]
YARN-9997. Code cleanup in ZKConfigurationStore. Contributed by Andras Gyori
","[2019-11-28 12:14:38][Szilard Nemeth][issue:summary][YARN-9997:13271201]
Code cleanup in ZKConfigurationStore"
Helix,SATD Duplication,"[2020-04-23 12:27:36][Ali Reza Zamani Zadeh Najari][code-comment][cae7afedea9aedce18a67666861ffd9e4268f295]
 Since line instances will be the same across all _routingTableRefMap, here one of the keys
 will be used without considering PropertyType
 TODO each table will keep a separate instance list.This can be improve by only keeping one
 copy of the data
","[2020-03-13 23:27:52][jiajunwang][pull:comment][834:392526766]
This could be a potential concern since each table will keep a separate instance list. There should be only one copy of the data. Let's add a TODO here for the future improvement."
Drill,No Relation,"[2016-06-09 01:39:02][jcmcote][pull:comment][512:66370984]
The CharSequenceWrapper does the same work as the Java String. That is convert the utf-8 bytes to a sequence of chars.
However it re-uses the CharBuffer instead of constantly allocating new arrays and letting them garbage collect. This will eliminate lots of churn in the GC.
","[2016-04-02 02:37:59][jean-claude][issue:summary][DRILL-4573:12955465]
All the functions using the java.util.regex.Matcher are currently creating Java string objects to pass into the matcher.reset().

However this creates unnecessary copy of the bytes and a Java string object.

The matcher uses a CharSequence, so instead of making a copy we can create an adapter from the DrillBuffer to the CharSequence interface.

Gains of 25% in execution speed are possible when going over VARCHAR of 36 chars. The gain will be proportional to the size of the VARCHAR."
Drill,SATD Repayment,"[2014-08-06 16:44:22][Hanifi Gunes][commit][28fbdad886583bc7193833abb06deea327ec8fbe]
DRILL-1202: fixes memory leak issues: i) ProducerConsumerBatch should clean up resources ii) FragmentExecutor should clean up gracefully at faulty & non-faulty runs regardless
","[2014-07-28 00:31:18][Steven Phillips][issue:summary][DRILL-1202:12730102]
ProduceConsumer operator causing memory leaks"
Brooklyn Server,SATD Duplication,"[2016-06-08 22:10:14][Aled Sage][code-comment][8dc292b9489711356501978d321b3d69049b9375]
 TODO: At some point in the future, this should probably be refactored to get the name of the machine in WinRmMachineLocation and set it as the hostname sensor
","[2016-06-06 14:35:34][nakomis][pull:comment][150:65900734]
At some point in the future, this should probably be refactored to get the name of the machine in `WinRmMachineLocation` and set it as the hostname sensor. Please add a TODO note here suggesting the same"
Incubator Pinot,No Relation,"[2020-08-10 11:58:00][JasperJiaGuo][commit][ce32362417fe16595e459e447b92b59fd4b03f48]
Addressed issues in code review: (#5774)

1. for MV use dictionary encoding only
2. renamed code
3. cleaned up some conditions
4. added a few java docs

fix testcase

added license

added cardinality regulator

restart test

restart test

resolve comments

removed logging

test
","[2020-08-05 15:02:53][siddharthteotia][pull:comment][5774:465793876]
javadoc please"
Arrow,SATD Repayment,"[2020-03-20 11:58:28][François Saint-Jacques][code-comment][f308749d71078cfec42ec1c58d64560c49de066c]
 The RecordBatchProjector is shared accross ScanTasks of the same
 Fragment. The resize operation of missing columns is not thread safe.
 Ensure that each ScanTask gets his own projector.
","[2020-03-18 19:29:44][fsaintjacques][pull:summary][6661]
The RecordBatchProjector is shared accross ScanTasks of the same Fragment. The resize operation of missing columns is not thread safe. This change ensure that each ScanTask gets his own projector. The copy should not be costly since it's copying empty vectors and one shared pointer."
Incubator Heron,SATD Repayment,"[2018-06-04 13:23:41][Neng Lu][code-comment][c13198b79037246d5baecd8cc35f5454b5db27d5]
 heron doesn't clean checkpoints stored on local disk automatically
 localFS cleans checkpoints before store and limits the number of checkpoints saved
","[2018-05-30 20:31:57][nlu90][pull:summary][2910]
The current implementation of LocalFSStorage would cause unlimited checkpoints to be saved on local disk and thus out of disk space problem.

This PR fixes the problem by adding a limit of the number of checkpoints saved on local disk and clean unnecessary checkpoints every time before trying to store a new checkpoint. The most recent N checkpoints will be saved and any older checkpoints will be deleted.

Tested on local mac and worked as expected."
Netbeans,No Relation,"[2019-03-29 18:50:26][Matthias Bläsing][code-comment][5b7a0c664ed19c943c2c9866b530d1d40f1c8bfc]
 /home/matthias/src/incubator-netbeans/ide/css.lib/src/org/netbeans/modules/css/lib/Css3.g:1166:33: ( ( IDENT | MINUS )? less_selector_interpolation ( less_selector_interpolation_exp | ( IDENT | MINUS | DIMENSION | LENGTH )+ )? )
 /home/matthias/src/incubator-netbeans/ide/css.lib/src/org/netbeans/modules/css/lib/Css3.g:1167:5: ( IDENT | MINUS )? less_selector_interpolation ( less_selector_interpolation_exp | ( IDENT | MINUS | DIMENSION | LENGTH )+ )?
","[2019-03-29 18:50:26][Matthias Bläsing][commit][5b7a0c664ed19c943c2c9866b530d1d40f1c8bfc]
Merge pull request #1172 from matthiasblaesing/css-variables

[NETBEANS-747] Implement basic support for variable syntax in CSS grammar"
Orc,SATD Duplication,"[2018-03-26 10:05:04][stiga-huang][pull:comment][233:376114199]
LGTM. We just need to document that users should pass in UTC timestamps when using the c++ writer.
Thanks, @wgtmac!
","[2018-04-06 05:07:49][Lefty Leverenz][issue:comment][ORC-322:16427978]
On March 26 @stiga-huang wrote: ""LGTM. We just need to document that users should pass in UTC timestamps when using the c++ writer.""

So does this need to be documented along with umbrella ORC-179?"
Systemds,SATD Repayment,"[2018-09-20 10:44:27][Niketan Pansare][code-comment][69f2d377c456f9baea1e248818d544b54ee00e6f]
 Aggressive write to disk when the cache is used in the write-mode.
 This avoids the need to depend on finalize to perform writing.
","[2018-09-20 10:44:27][Niketan Pansare][commit][69f2d377c456f9baea1e248818d544b54ee00e6f]
[SYSTEMML-445] Write to disk when the cache is used in the write-mode

- This avoids the need to depend on finalize to perform writing."
Incubator Brooklyn,SATD Repayment,"[2015-04-17 09:34:37][Alex Heneveld][code-comment][ff31a41d463c8b5b0b52abdb66968dc9bdf2abdd]
 transformation is not going to change, but this design makes it easier to support changing config in future. 
 if it's an efficiency hole we can switch to populate the transformation at start.
","[2015-04-17 14:22:25][ahgittin][pull:comment][595:28597808]
it wouldn't change, but this design makes it easier to support changing config in future. if it's an efficiency hole we can switch to populate this at start.  will add a comment to this effect."
Camel,SATD Repayment,"[2016-11-07 20:12:06][Tadayoshi Sato][commit][583bec8fb6d5595170d6ab36981d4acdcb9de4c2]
CAMEL-10446 - Need to consolidate header mapping logic between Camel and CXF messages
","[2016-11-05 12:33:49][Tadayoshi Sato][issue:summary][CAMEL-10446:13018595]
Need to consolidate header mapping logic between Camel and CXF messages"
Hbase,SATD Duplication,"[2013-05-15 15:09:37][Michael Stack][code-comment][f19b0360c1ff27df7a0023b27da2076897553483]
 Else, its signal from depths of ScannerCallable that we need to reset the scanner.
 TODO: Why wrap this in a DNRIOE when it already is a DNRIOE?
 Clear region.
 Set this to zero so we don't try and do an rpc and close on remote server when
 the exception we got was UnknownScanner or the Server is going down.
 This continue will take us to while at end of loop where we will set up new scanner.
","[2013-05-15 07:48:49][Michael Stack][issue:comment][HBASE-8531:13658150]
The patch committed against this issue added our being able to ride over RegionServerStoppedExceptions when nexting.  Above exception is a RSSE showing up when trying to open a scanner.  Before this patch, a RSSE was NOT a DNRIOE.  Now it is.  So, before this patch we would be retrying on scanner open.

But then inside in next, there was odd logic where it would convert the RSSE to a DNRIOE so scanner would be reset up if we got one of these mid-scan.  This I removed.

Logic here is a little tangled.  Let me put back this bit of hackery w/ comments so we get retry on open and nexting."
Incubator Dolphinscheduler,SATD Repayment,"[2020-04-21 02:25:45][dailidong][commit][eec92ed1fc1a35e22b8e38ac40681a1dd803399b]
simplify and optimize config (#2469)

* [Refactor worker] simplify and optimize config (#2386)

* simplify config

* simplify config

* simplify and optimize config

* Update HadoopUtils.java

optimize HadoopUtils

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java

* Update HttpUtils.java

* Update pom.xml

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java

* Update HadoopUtilsTest.java
","[2020-04-20 08:22:51][dailidong][pull:summary][2469]
simplify and optimize config"
Shardingsphere,No Relation,"[2020-10-26 04:18:47][terrymanu][pull:comment][7914:511712213]
It is better to change java doc `use cache` to `whether use cache`
","[2020-11-02 02:21:52][Arviiin][issue:comment][7869:720201177]
I prefer the second way also.
but duplicated dbType  is a little strange to use."
Nifi,No Relation,"[2018-12-06 06:34:10][rahulbhanushali][pull:comment][3034:444764113]
Yes, the reason being I still this logs on 1.80. and the node doesn't connect to the cluster.
There's no  other log apart from this in the file so I am assuming this may be the reason the node doesn't connect to the cluster.
","[2018-10-09 15:34:32][Joe Witt][issue:comment][NIFI-5479:16643642]
i think we should simply update logback to silence the annotation parser warnings.  we could file an additional followup JIRA to evaluate if we want to make any classpath improvements based on what it is signaling.  but we should make the warns go away as they could lead to confusion for the user"
Incubator Brooklyn,No Relation,"[2015-04-12 20:00:53][Alex Heneveld][code-comment][f7142a3333fdabdbec0e6eb606e7b595fd8491ef]
 evaluate immediately, or return null
 200ms seems a reasonable compromise for tasks which require BG evaluation
 but which are non-blocking
 TODO better would be to have a mode in which tasks are not permitted to block on
 external events; they can submit tasks and block on them (or even better, have a callback architecture);
 however that is a non-trivial refactoring
","[2015-04-12 20:00:53][Alex Heneveld][commit][f7142a3333fdabdbec0e6eb606e7b595fd8491ef]
make enrichers easier to configure from yaml

* entity spec keeps the list of specs, for things like enrichers, because equality (set duplication) is not very good for specs
* makes many of the basic enrichers easier to configure from yaml, with more flexible config
* in particular `Transformer` can be given a value supplier, e.g. `$brooklyn:formatString`
* adds a `Joiner` enricher which does `Strings.join`, handy for converting a list to something which can be used in bash
* good example of all of these in test-app-with-enrichers-slightly-simpler.yaml, referenced in the docs reference page"
Incubator Mxnet,No Relation,"[2019-08-07 13:29:43][Xinyu Chen][code-comment][ce62873ae24299242a9c809fd7b83060a0374163]
 TODO(xinyu-intel): tmp solution to save param_dict and reload for SymbolBlock
 will enhance SymbolBlock to load args, auxs directly.
","[2019-08-07 13:29:43][Xinyu Chen][commit][ce62873ae24299242a9c809fd7b83060a0374163]
Add quantization support for GluonCV (#15754)

* enhance quantization api

* integrate gluoncv solution

* support gluon ssd

* enhance api

* [TODO]split to another PR

* enhance example script

* add wildcard match for exclude layers

* support int8 dtype parameter

* enable dataiter api

* use try method

* add unit test for quantize gluon

* fix lint

* fix lint 2

* fix temporary directory in python2

* fix lint

* fix try import and add todo

* trigger"
Kafka,No Relation,"[2018-05-10 12:27:45][Chia-Ping Tsai][commit][4f7c11a1df26836c7a15f062a5431adb3d371a86]
KAFKA-6870 Concurrency conflicts in SampledStat (#4985)

Make `KafkaMetric.measurableValue` thread-safe

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>
","[2018-05-09 09:40:24][rajinisivaram][pull:comment][4985:387683248]
@chia7712 Can you add one unit test please?"
Karaf,SATD Repayment,"[2011-05-10 17:50:53][Jean-Baptiste Onofre][code-comment][2b501cf411006983759fcc392f965fd719c3d8c3]
 manage if the log4j.appender.out.file property is not present in
 the etc/org.ops4j.pax.logging.cfg file
","[2011-05-09 09:53:46][Stephane Chomat][issue:summary][KARAF-625:12506579]
Missing property 'log4j.appender.out.file' in the file org.ops4j.pax.logging.cfg caused a NPE"
Calcite,No Relation,"[2020-11-12 17:39:03][yuzhao.cyz][commit][5e9943aa1f51a97068fc37d53dea1d447570becc]
[CALCITE-4364] `a IN (1, 2) AND a = 1` should be simplified to `a = 1`
","[2020-11-10 18:30:41][Julian Hyde][issue:comment][CALCITE-4364:17229426]
The new {{flattenOperands}} is very similar to existing {{composeConjunction}} and {{flattenAnd}} methods in {{RexUtil}}. Could you somehow re-use those methods? Perhaps if you handle AND and OR separately.

The {{canNotMerge}} method (dealing with 3-valued logic) is much needed. But are there tests for it?

Can you reverse the sense of it, to {{canMerge?}}"
Druid,No Relation,"[2020-03-10 02:57:16][Clint Wylie][code-comment][8b9fe6f58461f1fc3f453c14f1634f9e779aeb71]
 nothing to cleanup
","[2020-03-06 07:41:29][clintropolis][pull:comment][9407:388752431]
I think I would agree that this area probably needs a refactor, maybe more suitable to be done in a follow-up PR, but will try to at least add some javadocs to clarify that the `QueryExceptions` are intended to be the main exceptions we surface from the API provided by `QueryResource` and `SqlResource`. Currently `QueryInterruptedException` is specifically caught and tied to HTTP 500 errors in these classes, so I split out `QueryCapacityExceededException` so that I could catch it separately and respond with the 429 status code (or 503, whatever we end up going with)."
Kafka,No Relation,"[2016-04-04 21:13:05][rajinisivaram][pull:comment][1183:58449885]
@hachikuji Thank you for the review. I was not sure of the implications of not failing unsent requests. Hence tried to keep the code as close to the existing semantics as possible. I like the idea of only expiring requests on timeout. Are coordinator changes always associated with a connection failure? If they are, then it shouldn't be hard, otherwise it may be harder to ensure all the edge cases are handled.
","[2016-04-08 15:10:24][Rajini Sivaram][issue:comment][KAFKA-3488:15232311]
[~guozhang] Since requests from the consumer tend to be small, the impact of retrying sends shouldn't be too bad. When sends to a destination are unblocked, it would typically be possible to send another batch of buffered requests."
Kafka,No Relation,"[2016-02-18 02:08:56][junrao][pull:comment][764:53263334]
This comment is a bit hard to understand. Given the comments at the beginning, we probably don't need the comment here.
","[2016-02-19 18:45:27][Jun Rao][issue:comment][KAFKA-3025:15154642]
[~becket_qin], thanks again for the patch. Currently, in Log.append(), we always do a second shallow iteration after validateMessagesAndAssignOffsets() to check the size of the compressed message. An optimization that we can do is that if there is no re-compression, we can skip the second shallow iteration since the size of the compressed message won't change. Could you file a separate jira to track that? It's not super critical since the shallow iteration is cheap."
Lucene Solr,No Relation,"[2013-12-02 18:42:23][Mark Robert Miller][code-comment][7ab2e1f787c252a8e931e40cce2a8d4b5edd7910]
 FIXME also add in SpoolDirectorySource
 FIXME also add in SpoolDirectorySource
","[2010-04-27 23:53:51][Alexander Kanarsky][issue:comment][SOLR-1301:12861621]
This is the version of the patch rewritten to use the new mapreduce API in hadoop 0.20. I did a quick port of the patch from 2010-02-02 11:57 AM without any optimizations, just to make it work with a new syntax. There are some slight changes around local filesystem temp file name generation etc. The CSVReducer class added just to pass a proper context to use counters in BatchWriter, if you know the better way to do this, please let me know. Tested with hadoop 0.20.2 on csv data, with both compressed and non-compressed output; seems to be OK, but no extensive regression testing performed. Code review and suggestions/corrections are welcome."
Incubator Pinot,SATD Repayment,"[2016-07-27 13:16:16][Puneet Jaiswal][commit][dfa4a8f25fa23a4458f5d92376a06a72b8463836]
TE: removing unused DAO classes. (#320)

* thirdeye : removing unused classes

* adding results util function

* restoring code for backward compatibility

* optimizing function update with anomaly-result
","[2016-07-27 17:54:37][puneetjaiswal][pull:summary][320]
TE: removing unused DAO classes."
Lucene Solr,No Relation,"[2012-07-20 01:01:39][Simon Willnauer][code-comment(deleted)][7d4507c9cddf90ae64c9f3bdbaec1f187e917187]
*
   * The following constructors are for use by you for whatever
   * purpose you can think of.  Constructing the exception in this
   * manner makes the exception behave in the normal way - i.e., as
   * documented in the class ""Throwable"".  The fields ""errorToken"",
   * ""expectedTokenSequences"", and ""tokenImage"" do not contain
   * relevant information.  The JavaCC generated code does not use
   * these constructors.
","[2014-03-15 21:04:38][Alan Woodward][issue:comment][LUCENE-2878:13936304]
Ooh, hello.

So the LUCENE-2878 branch is a bit of a mess, in that it has two semi-working versions of this code: Simon's initial IntervalIterator API, in the o.a.l.search.intervals package, and my DocsEnum.nextPosition() API in o.a.l.search.positions.  Simon's code is much more complete, and I've been using a separately maintained version of that in production code for various clients, which you can see at https://github.com/flaxsearch/lucene-solr-intervals.  I think the nextPosition() API is nicer, but the IntervalIterator API has the advantage of actually working.

The github repository has some other stuff on it too, around making the intervals code work across different fields.  The API that I've come up with there is not very nice, though.

It would be ace to get this moving again!"
Superset,No Relation,"[2020-08-10 10:20:43][Jason Davis][commit][8b9292ed057540aaae3fe1d09952345261e92bc9]
fix: add retry to SQL-based alerting celery task (#10542)

* added retry and minimized sqlalchemy object lives

* pylint

* added try catch

* adjusted naming

* added scoped session

* update tests for dbsession

* added requested changes

* nit todo

Co-authored-by: Jason Davis <@dropbox.com>
","[2020-08-07 10:15:58][dpgaspar][pull:comment][10542:466951728]
nit: can we call it `db_session`"
Lucene Solr,No Relation,"[2018-03-01 17:00:00][Erick Erickson][code-comment][b4e33a038569f97752abd61a26e8af0b652e5b44]
 currently this test is fine with a single shard with a single replica and it's simpler. Could easily be
 extended to multiple shards/replicas, but there's no particular need.
","[2017-10-17 20:48:47][Erick Erickson][issue:comment][SOLR-11503:16208311]
This isn't ideal in that it writes the core.properties file twice. That said, it's only when creating the core which is only done when you have a CREATE_OP core command so it's only done once over the lifetime of the replica.

I'm a little afraid to call ZkController().preRegister differently than it is now, or extract the guts of it, I'll look some more though. This seems like the minimally-risky change.

I suppose we could call ZkController.preRegister core before calling createFromDescriptor everywhere (including before calling coresLocator.create), but then next time somebody needed to rearrange things they could forget to call preRegister.

Still to come:
1> tests
2> dealing with coreNodeName not being in the properties file and legacyCloud=false."
Pulsar,SATD Repayment,"[2018-03-15 15:18:18][Boyang Jerry Peng][commit][6fbd8c3c63c66cd1bfc08d04c2c553ffb78e0b55]
Functions metrics prometheus (#1373)

* adding pulsar function stats to broker prometheus

* refactoring class name

* adding missing license header

* refactoring code and removing function's metrics sink

* fixing header

* adding instance liveness check

* adding null check

* adding unittest
","[2018-03-14 20:06:35][jerrypeng][pull:comment][1373:373157111]
@merlimat thanks for the review. I have added a unit test"
Incubator Brooklyn,No Relation,"[2013-06-07 01:29:46][Peter Veentjer][code-comment][e0c573b0b52348452fac8ffe260015c97e481838]
* Default String representation is simplified name of class, together with selected fields.
","[2013-06-07 01:29:46][Peter Veentjer][commit][e0c573b0b52348452fac8ffe260015c97e481838]
Merge pull request #777 from aledsage/cleanup/AbstractEntity

Cleanup: AbstractEntity"
Geode,No Relation,"[2016-10-21 13:25:15][Jared Stewart][code-comment][8bf39571471642beaaa36c9626a61a90bd3803c2]

         * doing this so that other VMs will apply this no matter what. If it is an ""update"" they
         * will not apply it if they don't have the key. Because this is probably a retry, it will
         * never get applied to this local AbstractRegionMap, and so will never be flipped to a
         * 'create'
          event.invokeCallbacks(this, true, true);
    } finally {



      if (re == null /* || re.isTombstone()
","[2016-10-21 13:25:15][Jared Stewart][commit][8bf39571471642beaaa36c9626a61a90bd3803c2]
Added Spotless plugin to enforce formatting standards.
Added Google Java Style guide formatter templates, removed existing formatter templates.

Ran './gradlew clean build' for verification

This closes #268"
Hive,SATD Repayment,"[2015-03-23 06:46:44][Rui Li][commit][f2d73e9341c75abee41a1366d2bd4f786d4a1cda]
HIVE-10006: RSC has memory leak while execute multi queries.[Spark Branch] (Chengxiang via Rui, reviewed by Xuefu)

git-svn-id: https://svn.apache.org/repos/asf/hive/branches/spark@1668521 13f79535-47bb-0310-9956-ffa450edef68
","[2015-03-18 09:41:51][Chengxiang Li][issue:summary][HIVE-10006:12782804]
RSC has memory leak while execute multi queries.[Spark Branch]"
Incubator Mxnet,SATD Duplication,"[2018-06-13 18:06:54][azai91][pull:summary][11262]
[MXNET-542] Fix mkldnn performance regression + improve test logging
","[2018-06-13 18:05:47][Alexander][issue:summary][MXNET-542:13165894]
Fix MKLDNN performance regression"
Tvm,SATD Duplication,"[2020-08-18 16:19:39][Yizhi Liu][code-comment][ff2a76f90bc2f3b9eeb6e57c820aa300cfd2ab49]
 TODO(sgrechanik-h): NOTs could be pushed down using De Morgan laws
 before running this function but this case didn't seem to be important enough.
","[2020-08-02 18:39:31][sergei-grechanik][pull:comment][6078:464109667]
`not`s could be pushed down using De Morgan laws before running this function but this case didn't seem to be important enough, and I was lazy to implement it, so now this function treats them as opaque expressions."
Arrow,SATD Repayment,"[2020-04-14 15:13:44][Krisztián Szűcs][commit][b0902ab32f26681c9e99a0b61a5ab5d6d03a20df]
ARROW-8444: [Documentation] Fix spelling errors across the codebase

Quickly run `codespell` which found a couple of misspellings.

Closes #6931 from kszucs/spelling

Authored-by: Krisztián Szűcs <szucs.krisztian@gmail.com>
Signed-off-by: Benjamin Kietzman <bengilgit@gmail.com>
","[2020-04-14 12:35:36][Krisztian Szucs][issue:summary][ARROW-8444:13298261]
[Documentation] Fix spelling errors across the codebase"
Druid,SATD Repayment,"[2019-12-23 18:33:22][Suneet Saldanha][commit][dec619ebf4972fb59257b31649a4d416319b00a2]
Optimize CachingLocalSegmentAllocator#getSequenceName (#8909)

* Optimize CachingLocalSegmentAllocator#getSequenceName

Replace StringUtils#format with string addition to generate the sequence
name for an interval and partition. This is faster because format uses a
Matcher under the covers to replace the string format with the variables.

* fix imports and add test

* Add comment about optimization

* Use renamed function for TaskToolbox

* Move tests after refactor

* Rename tests
","[2019-12-17 23:29:48][jihoonson][pull:comment][8909:359083627]
Thanks for adding tests. I think we prefer to use a short but intuitive name for tests and add comments if necessary."
Incubator Pinot,SATD Duplication,"[2017-11-20 11:05:59][Xiaotian Jiang][code-comment][17d87445392a7b9da14c27324e353052b3b2839e]
 NOTE: cannot use ImmutableRoaringBitmap.flip() because the library has a bug in that method
 TODO: the bug has been fixed in the latest version of ImmutableRoaringBitmap, update the version
","[2017-11-20 18:12:40][Jackie-Jiang][pull:comment][2085:152068745]
The bug has been fixed in newer version. Added a TODO to update the version later."
Helix,SATD Repayment,"[2020-10-21 15:31:01][Neal Sun][commit][2c615543bd86e50d76dd4d7006d1c90e130e9755]
ExpiredJob Workaround for Selective Update Race Conditions (#1470)

This PR implements a workaround for determining expired jobs
that avoids selective update race condition: if JobConfig doesn't
exist in the cache, check ZK directly.
","[2020-10-19 21:27:54][kaisun2000][pull:comment][1470:508072950]
This is public API change. I know it is added recently, but are we sure this won't break some other code using TaskUtil?

The other way can be simply add a check after line 85 to see if any expiredJobs are in the config and remove them from the expiredJob set."
Samza,SATD Duplication,"[2017-06-07 19:13:20][shanthoosh][pull:summary][219]
TasksResource(/tasks/) in samza-rest is relying on `JobModelManager.readJobModel` to get jobmodel from (CoordinatorStream, jobConfig). This created binary dependencies of systemstreams defined in task.inputs of job config into samza-rest. Managing those dependencies is hard and unnecessary. 

This PR updates `TasksResource` to use `LocalityManager` to read task to container locality. 
In the future, this api will read jobmodel from `SamzaMetadatasystem` store.
","[2017-06-07 22:59:08][Shanthoosh Venkataraman][issue:summary][SAMZA-1329:13078158]
TasksResource(/tasks/) in samza-rest is relying on JobModelManager.readJobModel to get jobmodel from (CoordinatorStream, jobConfig). This created binary dependencies of systemstreams defined in task.inputs of job config into samza-rest. Managing those dependencies is hard and unnecessary.

This PR updates TasksResource to use LocalityManager to read task to container locality.
In the future, this api will read jobmodel from SamzaMetadatasystem store."
Drill,SATD Duplication,"[2017-12-04 02:29:01][sachouche][pull:summary][1060]
DRILL-5846: Improve parquet performance for Flat Data Types
","[2017-10-05 20:40:34][Salim Achouche][issue:summary][DRILL-5846:13107351]
Improve Parquet Reader Performance for Flat Data types"
Druid,SATD Repayment,"[2019-12-23 18:33:22][Suneet Saldanha][commit][dec619ebf4972fb59257b31649a4d416319b00a2]
Optimize CachingLocalSegmentAllocator#getSequenceName (#8909)

* Optimize CachingLocalSegmentAllocator#getSequenceName

Replace StringUtils#format with string addition to generate the sequence
name for an interval and partition. This is faster because format uses a
Matcher under the covers to replace the string format with the variables.

* fix imports and add test

* Add comment about optimization

* Use renamed function for TaskToolbox

* Move tests after refactor

* Rename tests
","[2019-11-19 19:45:54][suneet-s][pull:comment][8909:555678481]
I didn't find any tests for this class. Since the logic is very trivial I decided to skip adding a unit test for this.

cc @jihoonson"
Hbase,SATD Repayment,"[2017-12-20 17:58:08][Apekshit Sharma][commit][dc5ec061b5eceaf3d1fdd901263dac100fdccdf1]
HBASE-19491 Improvements to Nighly runs: Fixes findbugs tests, Exclude flaky tests from master.
","[2017-12-12 02:45:59][Apekshit Sharma][issue:summary][HBASE-19491:13124267]
Testing infra improvements
- Exclude flaky tests from nightly master run (Old nightly master run used to exclude flaky tests, but new nightly one which is based on Jenkins stages wasn't using it. Adding it to new nightly job)
- Fixes findbugs check (seems like wasn't working earlier : ""0	findbugs	0m 0s	Findbugs executables are not available."")"
Lucene Solr,SATD Duplication,"[2019-09-05 13:11:29][iverase][pull:summary][857]
LUCENE-8968: Improve performance of WITHIN and DISJOINT queries for Shape queries
","[2019-09-05 13:10:06][Ignacio Vera][issue:summary][LUCENE-8968:13255001]
Improve performance of WITHIN and DISJOINT queries for Shape queries"
Incubator Pinot,SATD Repayment,"[2018-02-09 14:51:27][Mayank Shrivastava][commit][4e4ab11bd4609a9a7ff499f25259601b0cea825a]
Re-factor: Code re-factor to separate out realtime specific references (#2476)

from fixed-byte readers/writers.

1. Created an interface PinotDataBufferMemoryManager, that is now passed
to fixed-byte readers/writers.

2. Eliminated segmentName being stored in memory manager. Instead, now
callers allocating memory pass an allocationContext
(segmentName:columnName), that is used for logging within memory
manager. RealtimeOffHeapMemoryManager still has dependency on segment
name, that is harder to remove, and will explode this PR, therefore not
addressed.

3. Fixed code-style for all touched files.
","[2018-02-09 18:59:25][mayankshriv][pull:summary][2476]
1. Created an interface PinotDataBufferMemoryManager, that is now passed
to fixed-byte readers/writers.

2. Eliminated segmentName being stored in memory manager. Instead, now
callers allocating memory pass an allocationContext
(segmentName:columnName), that is used for logging within memory
manager. RealtimeOffHeapMemoryManager still has dependency on segment
name, that is harder to remove, and will explode this PR, therefore not
addressed.

3. Fixed code-style for all touched files."
Myfaces Tobago,SATD Repayment,"[2009-11-04 11:56:16][Udo Schnurpfeil][commit][efb1218e76389ac98ddbee6a2b52ac4fc2aaafd3]
TOBAGO-812: Refactor Style Handling of components: Don't put style in the component attributes
","[2009-10-30 15:13:15][Udo Schnurpfeil][issue:summary][TOBAGO-812:12439535]
Refactor Style Handling of components"
Accumulo,No Relation,"[2018-11-01 20:43:52][ctubbsii][pull:comment][743:230191166]
I do not think this should be removed, along with its functionality. I seem to recall multiple table scanning to be a high-demand feature when this was first added. However, it is redundant with AccumuloInputFormat, since that is a trivial case of this one. I think the AccumuloInputFormat should be modified to support multiple tables, so we can eliminate one of these, but still keep the ability to scan multiple tables.
","[2018-11-08 21:33:15][keith-turner][issue:comment][753:437163763]
Passing the job in at the end of the fluent chain allows for sanity checks to be done all at once.  It also makes it very clear when the job is mutated.  Could do something like the following.

```java
AccumuloInputFormat.settings().clientInfo(clientInfo).table(""test"").scanAuths(Authorizations.EMPTY)
            .addIterator(is).configure(job);
```"
Trafficcontrol,No Relation,"[2020-02-17 10:09:41][mattjackson220][code-comment][18fe13ac638557b5532813bce8ab3ad2d964fe49]
 ErrCodeMalformedPolicyDocumentException for service response error code
 ""MalformedPolicyDocument"".

 The request was rejected because the policy document was malformed. The error
 message describes the specific error.
","[2020-02-05 18:51:56][ocket8888][pull:comment][3534:375442356]
This still needs to document the format, which I'm pretty sure is RFC3339."
Drill,SATD Duplication,"[2017-08-14 22:19:24][Paul Rogers][code-comment][073ea68197cdc37e2ca9414da96e9df39ec49fcc]
 Must hold two input batches. Use half of the rest for the spill batch.
 In a really bad case, the number here may be negative. We'll fix
 it below.
","[2017-07-19 01:31:24][paul-rogers][pull:comment][860:128134981]
Buffer, in the sense of the amount of memory set aside for the spill batch. We work backwards to get the spill batch size.

Yes, in the worst case, the estimated spill batch size will be negative, meaning we don't even have room to hold two input batches, let alone any spill batches.

The negative number is not fixed. Instead, the resulting spill batch row count is clamped at a minimum of 1 in `rowsPerBatch()`. Also, we whine to the log file that we've got too little memory and that Bad Things are likely to happen."
Kafka,No Relation,"[2017-01-09 20:17:16][Guozhang Wang][commit][109aa353686cc0a9e4448c2b48da63f1d79acae6]
MINOR: Maybe decorate inner topics for SourceNode

When creating the source node in TopologyBuilder, we need to decorate its input topics if they are inner (i.e. repartition) topics with the prefix.

Also did some minor cleanup in the printing function for better visualization in debugging.

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Eno Thereska, Damian Guy, Eno Thereska, Jun Rao

Closes #2320 from guozhangwang/KMinor-source-topic-fix
","[2017-01-06 17:09:29][mjsax][pull:comment][2320:94981192]
I guess doing this incrementally will not work. What about one (or multiple) PR that add `final` wherever possible over all files (maybe package by package to split it up in multiple PRs)? It's dumb work, but I would volunteer...

If we do in incrementally, it also distracts from actual code changes for a PR and add noise that makes reviewing harder."
Flink,No Relation,"[2020-07-28 14:39:19][aljoscha][pull:comment][13007:461634390]
Again, I really like the thorough new Javadoc!
","[2020-01-29 09:58:52][Timo Walther][issue:summary][FLINK-15803:13282140]
This will allow to use aggregate functions with the new type inference. It requires different changes through the stack. This should be implemented after we have support for structured types. It also includes a long-term solution for the concept of DataViews with the new type system."
Tinkerpop,SATD Repayment,"[2014-06-13 06:56:06][Stephen Mallette][code-comment(deleted)][107613e8bb7fd0a37459bed18c3fe96c01b19483]
 TODO: test
","[2014-06-13 06:56:06][Stephen Mallette][commit][107613e8bb7fd0a37459bed18c3fe96c01b19483]
Remove todo for map test."
Brooklyn Server,SATD Repayment,"[2019-01-31 10:38:18][Thomas Bouron][commit][f54c1e204b85e031bfb57375c0c6421f55b7f317]
Merge pull request #1032 from ahgittin/make-logout-just-logout

fix session sharing and simplify logout
","[2019-01-27 02:37:18][ahgittin][pull:summary][1032]
fix session sharing and simplify logout"
Incubator Pinot,SATD Duplication,"[2019-07-24 17:36:13][Xiaotian (Jackie) Jiang][code-comment][1d45f87be735327ddc6273df8d561d123af9b301]
 TODO: Enable periodic rebalance per 10 seconds as a temporary work-around for the Helix issue:
       https://github.com/apache/helix/issues/331. Remove this after Helix fixing the issue.
","[2019-07-22 23:37:47][Jackie-Jiang][pull:summary][4459]
Enable periodic rebalance as a temporary work-around for the Helix issue"
Beam,SATD Repayment,"[2020-04-09 10:44:35][Kamil Wasilewski][commit][79b2d87b59819ee55fb8600e8a845c6ba5b98d64]
[BEAM-9085] Fix performance regression in SyntheticSource on Python 3 (#11092)
","[2020-03-10 15:58:24][kamilwu][pull:summary][11092]
[BEAM-9085] Fix performance regression in SyntheticSource on Python 3"
Activemq Artemis,SATD Repayment,"[2018-09-27 17:29:18][Clebert Suconic][code-comment][94be096861f1baa12180d8375a60f4bcb1d9792c]
If runtime exception, we must remove from the cache to avoid filling up the cache causing it to be full.
The client would get still know about this as the exception bubbles up the call stack instead.
","[2018-08-09 07:59:23][michaelandrepearce][pull:comment][2187:208837845]
@jbertram
So i think to solve the issue of the responseCache still having reference and the memory leak, we can just add in the code that acks the commands upto the latest, we can just also call the cache, it will mean a double invocation but as you noted for the interim with your flag it actually wont have effect.

Thought? Ill send a pr in a bit to your branch"
Spark,No Relation,"[2016-10-03 14:12:03][Jason White][code-comment(deleted)][1f31bdaef670dd43999613deae3620f4ddcd1fbf]
 There is a bug in py4j.java_gateway.JavaClass with auto_convert
 https://github.com/bartdag/py4j/issues/161
 TODO: use auto_convert once py4j fix the bug
","[2016-10-03 14:12:03][Jason White][commit][1f31bdaef670dd43999613deae3620f4ddcd1fbf]
[SPARK-17679] [PYSPARK] remove unnecessary Py4J ListConverter patch

## What changes were proposed in this pull request?

This PR removes a patch on ListConverter from https://github.com/apache/spark/pull/5570, as it is no longer necessary. The underlying issue in Py4J https://github.com/bartdag/py4j/issues/160 was patched in https://github.com/bartdag/py4j/commit/224b94b6665e56a93a064073886e1d803a4969d2 and is present in 0.10.3, the version currently in use in Spark.

## How was this patch tested?

The original test added in https://github.com/apache/spark/pull/5570 remains.

Author: Jason White <jason.white@shopify.com>

Closes #15254 from JasonMWhite/remove_listconverter_patch."
Fluo,SATD Repayment,"[2014-08-07 15:05:08][Mike Walch][commit][0cdf7dba6ed142a2f076155a95624125e32efb32]
Merge pull request #109 from keith-turner/fluo-26

fixes #26 made lock recovery more efficient by caching and batching
","[2014-07-31 22:10:31][keith-turner][pull:summary][109]
fixes #26 made lock recovery more efficient by caching and batching"
Hadoop,No Relation,"[2013-10-17 05:32:42][Andrew Wang][code-comment][da1f4419e3cd01f1274565c1db84ae500b018274]

  This file contains pool and user allocations for the Fair Scheduler.
  Its format is explained in the Fair Scheduler documentation at
  http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/FairScheduler.html
  The documentation also includes a sample config file.
","[2013-07-13 00:16:21][Todd Lipcon][issue:comment][HDFS-4949:13707576]
Yes, I think the explicit caching policies would operate mostly on a whole-file granularity. The DNs, though, can do local LRU tracking of sub-blocks. This is useful for cases like querying a Parquet file where a single file is made up of subranges corresponding to different columns. Some columns may be hot while others are cold, and if the DN can notice this and start offering zero-copy for the hot columns, it will be a significant performance win."
Ignite,SATD Repayment,"[2015-03-04 19:57:37][sevdokimov][code-comment(deleted)][d6cf7b4626c41b744493454b0531c24db93a64ae]
 todo IGNITE-70 Add link to documentation
","[2015-03-04 19:57:37][sevdokimov][commit][d6cf7b4626c41b744493454b0531c24db93a64ae]
# IGNITE-70 remove ""todo IGNITE-70""."
Hadoop,No Relation,"[2013-04-13 02:13:59][Aaron Myers][code-comment][801b484f9787b7c70e146aa82f9131a9ee473fed]
 There are remaining bytes from a small read available. This usually
 means this read is unaligned, which falls back to the slow path.
","[2008-12-15 18:40:18][Owen O'Malley][issue:comment][HDFS-347:12656687]
I think this patch is going the wrong way. Giving up the security and sanity of a single data path is a *really* high cost. I think it is much more important to get the pread performance up than add a second, security-destroying datapath."
Hbase,No Relation,"[2016-07-19 07:27:32][Dima Spivak][code-comment][9454daf25bcc704d8403a403282c9bf0090b1101]
 Save the InterfaceAudience package name as a variable to make annotation listing more convenient.
","[2016-07-19 07:27:32][Dima Spivak][commit][9454daf25bcc704d8403a403282c9bf0090b1101]
HBASE-16241 Allow specification of annotations to use when running check_compatibility.sh

* Also some trivial cleanup of spacing to undo poor formatting decisions
  of the past.

Signed-off-by: stack <stack@apache.org>
Signed-off-by: Sean Busbey <busbey@apache.org>"
Tajo,SATD Duplication,"[2015-07-17 10:04:36][jihoonson][pull:summary][634]
TAJO-1343: Improve the memory usage of physical executors
","[2015-02-12 07:41:30][Jihoon Son][issue:summary][TAJO-1343:12774471]
Improve the memory usage of physical executors"
Ignite,SATD Duplication,"[2018-04-20 14:44:39][tledkov-gridgain][pull:summary][3889]
IGNITE-8347  Memory leaks on restart Ignite node with enabled persistence at ThreadLocal
","[2018-04-20 14:14:17][Taras Ledkov][issue:summary][IGNITE-8347:13154034]
Memory leaks on restart Ignite node with enabled persistence at ThreadLocal"
Bigtop,SATD Repayment,"[2013-05-02 15:06:07][Anatoli Fomenko][code-comment(deleted)][95d8631d28c4635eb94095bcc2c9b76fb97146a2]
 FIXME: BIGTOP-648 workaround for HBASE-6263
","[2013-05-02 15:06:07][Anatoli Fomenko][commit][95d8631d28c4635eb94095bcc2c9b76fb97146a2]
BIGTOP-960. Remove workaround for HBASE-6263 in hbase-thrift start"
Arrow,No Relation,"[2018-08-09 13:31:10][Wes McKinney][code-comment][78a4d651221c399c8e9779efa96e324a9caaa09c]
 Create a single instance of PyBytesView here to prevent unnecessary object
 creation/destruction
","[2018-08-09 14:52:08][wesm][pull:comment][2366:411785552]
The `#include`s are a mess. I'm going to look at dockerizing IWYU so that's easier for us to clean up on a more regular basis"
Carbondata,SATD Repayment,"[2018-04-23 16:28:35][ravipesala][commit][8b33ab240126e999e9196369025917370172eee4]
[CARBONDATA-2376] Improve Lucene datamap performance by eliminating blockid while writing and reading index

Problem:
Currently DataMap interface implementations use blockid and blockletid while writing index files, Actually blockid is not needed to store in index files as it only requires blockletid. So it adds more memory and disk size to write index files.

Solution:
Use taskname as index name to identify the indexname. And filter the blocklets directly by avoiding blockids.And pass the taskName as indexname to identify the blockid from blocletdatamap.

Corrected the implementations of LuceneDatamap, BloomFilterDataMap, CGDataMap, FGDataMap and MinMaxDataMap

This closes #2206
","[2018-04-22 05:03:56][ravipesala][pull:summary][2206]
[CARBONDATA-2376] Improve Lucene datamap performance by eliminating blockid while writing and reading index."
Geode,SATD Repayment,"[2019-07-03 09:57:19][Alberto Bustamante Reyes][commit][d4d1b38282b12de6f3d5a0db5feb97da7915affc]
GEODE-6934: Remove unused class ManagementCommand
","[2019-07-03 10:51:04][Alberto Bustamante Reyes][issue:summary][GEODE-6934:13242968]
Remove unused class ManagementCommand"
Trafficserver,No Relation,"[2016-04-19 09:10:28][Alan M. Carroll][commit][5abf6aca383e34b5aa1c0e3248936d858806acbe]
TS-4046: Prevent memory leak of HTTP heap for server intercept case.
This close #577.
","[2015-12-02 07:37:50][Chao Xu][issue:comment][TS-4046:15035414]
do we need to replace ""HdrHeap *m_heap"" in HdrHeapSDKHandler with “Ptr<HdrHeap> m_heap” ？

{code}
475 inline void
476 HdrHeapSDKHandle::clear()
477 {
478   m_heap = NULL;   <---- mem leak as described in this issue if here is the last one to keep the memory area
479 }
{code}"
Beam,No Relation,"[2017-10-16 23:35:57][mairbek][pull:comment][3729:144996500]
This is also more space efficient comparing to the Java serialization [which basically saved a list of (column name,value) pairs]. So the reshuffling happens faster.
","[2017-03-03 22:20:22][Guy Molinari][issue:comment][BEAM-1542:15895141]
I have created a fork called NextDevBoard and have checked in a very primitive version of this.  The checkstyle plugin is failing the build so I'm running -Dcheckstyle.skip=true until I can fix this.   There is much to do including lots and lots of cleanup.   Split bundles must be implemented for the Source but I wanted to get the Sink working first.   There are custom coders for the spanner Mutation and Struct classes."
Incubator Pinot,SATD Duplication,"[2016-12-15 13:27:58][Jackie-Jiang][code-comment][8cb6e4873034283b327d674638a90c6bfe839713]
 TODO: remove the code for backward compatible after server updated to the latest code.
","[2016-12-15 19:24:02][Jackie-Jiang][pull:summary][910]
In the old code, the selection only columns order in data schema
might be different with the actual order. Add code to handle this,
and after server update to the latest version, remove the code for
backward compatible to get the highest performance."
Beam,SATD Duplication,"[2018-07-02 16:55:52][Charles Chen][code-comment][a56ce43109c97c739fa08adca45528c41e3c925c]
 TODO(BEAM - 3730)
","[2018-06-20 21:05:21][charlesccychen][pull:comment][5337:196942268]
Can you please add a `TODO(BEAM-3730)` comment here too?"
Flink,No Relation,"[2019-11-15 00:11:50][caoyingjie][commit][a9b126640c41b767c26b5a1537a45c3102574a3c]
[FLINK-14472][runtime] Implement back-pressure monitor with non-blocking outputs

The previous back pressure monitor relies on detecting task threads that are stuck in LocalBufferPool#requestBufferBuilderBlocking. After the implementation of non-blocking network output in FLINK-14396, the back pressure monitor should be adjusted accordingly.

In detail, we reimplement the back pressure monitor based on the availability of output buffers. If there is at-least one available buffer in output's LocalBufferPool, then the task is not back pressured and vice versa. Furthermore this way can also solve the previous invalid monitor case if the buffer is not requested by task thread.

This closes #10083
","[2019-11-11 07:22:37][zhijiangW][pull:comment][10083:344583125]
All the above logics before this action is almost the same with the first test `testGetOperatorBackPressureStats`. So it is better to extract the logic in first test and reuse here. Then we only need to create the second `BackPressureStats` and verify it in following parts."
Incubator Pinot,SATD Duplication,"[2016-12-15 13:27:58][Jackie-Jiang][code-comment][8cb6e4873034283b327d674638a90c6bfe839713]
 TODO: remove the code for backward compatible after server updated to the latest code.
","[2016-12-15 13:27:58][Jackie-Jiang][commit][8cb6e4873034283b327d674638a90c6bfe839713]
Add backward compatible for the new selection only logic. (#910)

In the old code, the selection only columns order in data schema
might be different with the actual order. Add code to handle this,
and after server update to the latest version, remove the code for
backward compatible to get the highest performance."
Lucene Solr,No Relation,"[2008-07-30 19:35:58][Shalin Shekhar Mangar][code-comment][79e77502f604281492b9dfb66ddf9beaf30e4150]
 This entry enables an int hash representation for filters (DocSets)
         when the number of items in the set is less than maxSize.  For smaller
         sets, this representation is more memory efficient, more efficient to
         iterate over, and faster to take intersections.
","[2008-02-20 06:18:14][Otis Gospodnetic][issue:comment][SOLR-469:12570588]
Haven't looked at the patch, but I've read most of http://wiki.apache.org/solr/DataImportHandler

Small comment: don't name that config file ""data-config.xml"".  ""data"" is *so* generic.  What is this?  It's a RDBMS indexing tool implemented as a request handler.  I'd pick a better, more specific name both for the config and the handler itself - DataImportHandler - does it import from a file?  A BDB?  RDBMS?  Another search engine?  Can't tell from a generic name.

Really well documented, good job, and I'm looking forward to seeing this in Solr!"
Drill,No Relation,"[2017-04-21 14:51:36][Paul Rogers][code-comment][3e8b01d5b0d3013e3811913f0fd6028b22c1ac3f]
 TypeSafe gets unhappy about a leading slash, but other functions
 require it. Silently discard the leading slash if given to
 preserve the test writer's sanity.
","[2017-04-03 22:40:29][paul-rogers][pull:comment][788:109541450]
Refactored some. To reuse all code, I'd need to create a class so we can grab the typed value in the middle of the other stuff. The few lines of repetition are the price of avoiding a trivial class. Since this is test code, I'm inclined to live with the (reduced) repetition. Take a look and let me know what you think. Also added a `singletonString()` method (because, why not?) and a new `reader()` method with some of the common code."
Incubator Doris,SATD Repayment,"[2019-09-19 17:37:02][ZHAO Chun][commit][17e52a4bacec63179525143a8e862e8bf68c9d7b]
Improve LRUCache to get better performance (#1826)

In this CL, I move the entry's deleter out of LRUCache's mutex block,
which can let others access this cache without waiting free cache entry.
","[2019-09-18 12:25:15][imay][pull:summary][1826]
Improve LRUCache to get better performance"
Hbase,No Relation,"[2018-08-17 00:04:05][Sean Busbey][code-comment][2676d498f5b515dfb7cb6b08d3458480b1b6bfbc]
 All tests: All testcases which were run.
 Hanging test: A testcase which started but never finished.
 Failed test: Testcase which encountered any kind of failure. It can be failing atomic tests,
   timed out tests, etc
 Timeout test: A Testcase which encountered timeout. Naturally, all timeout tests will be
   included in failed tests.
","[2018-04-11 16:00:38][Sean Busbey][issue:summary][HBASE-20387:13151682]
We need a flaky list per-branch, since what does/does not work reliably on master isn't really relevant to our older maintenance release lines.

We should just make the invocation a step in the current per-branch nightly jobs, prior to when we need the list in the stages that run unit tests. We can publish it in the nightly job as well so that precommit can still get it. (and can fetch it per-branch if needed)"
Trafodion,SATD Repayment,"[2019-07-02 20:41:57][Dave Birdsall][commit][5e7f19703cbf7829189733d3b0d62e3176d4366c]
[TRAFODION-3314] Avoid generating redundant DDL in OSIM for unique constraints
","[2019-07-01 23:10:23][Dave Birdsall][issue:summary][TRAFODION-3314:13242619]
OSIM generates redundant DDL for unique constraints"
Drill,SATD Repayment,"[2018-05-22 13:05:33][hmaduri][code-comment][3af718f050f28210d4c5dcf359c617b2300dd736]
 project is required to rename the columns so as to disambiguate the same column name from
 unnest operator and the regular scan.
","[2018-05-22 13:05:33][hmaduri][commit][3af718f050f28210d4c5dcf359c617b2300dd736]
DRILL-6431: Unnest operator requires table and a single column alias to be specified.
Fixing the issues related to star column renaming, same field name renaming
and also enforcing that an alias column is required for the unnest operator."
Flink,No Relation,"[2019-02-20 11:07:23][StefanRRichter][pull:summary][7768]
…gher stability

The test failures look similar to what we saw before when the scale of the test was to big. I guess there is some variance in the performance of machines that Travis provides, so I scaled down the test a bit further.
","[2019-02-21 15:10:58][Stefan Richter][issue:comment][FLINK-11541:16774149]
I analyzed it a bit more and it seems that the changes to run the execution graph single-threaded can have a negative impact on performance with slow CPUs and very large deployment descriptors, because the serialization of the deployment descriptors is now all done in one thread.

I think we can solve this problem by using the future executor for the  calls to `submitTask` and then sync back the result into the main thread. Will prepare a fix."
Arrow,SATD Repayment,"[2020-01-02 07:24:58][Kazuaki Ishizaki][commit][cec93999fdef8fe9c83e78ec9f9cc53f9341d71c]
ARROW-7482: [C++] Fix typos

This PR fixes typos in files under `cpp/src/arrow` directory

Closes #6110 from kiszk/ARROW-7482 and squashes the following commits:

b5dc3f012 <Kazuaki Ishizaki> fix lint errors
bb39903f4 <Kazuaki Ishizaki> address review comment
b291f2e01 <Kazuaki Ishizaki> fix lint errors
224796723 <Kazuaki Ishizaki> fix typo

Authored-by: Kazuaki Ishizaki <ishizaki@jp.ibm.com>
Signed-off-by: Sutou Kouhei <kou@clear-code.com>
","[2019-12-31 17:49:14][Kazuaki Ishizaki][issue:summary][ARROW-7482:13277039]
[C++] Fix typos"
Karaf,SATD Repayment,"[2015-09-28 14:24:26][Freeman Fang][code-comment][266e1da6040d84e4267a8aa7cc66e8201c11ca7a]
to avoid the File name too long exception
","[2015-09-28 06:06:14][Freeman Yue Fang][issue:summary][KARAF-4022:12896704]
to avoid the File name too long Exception.

For example if we use a wrap:uri_with_osgi_instructions bundle in startupFeatures, then the auto-generated bundle file name could exceed the OS filename size(256), hence we get the File name too long Exception"
Incubator Pinot,SATD Repayment,"[2020-08-05 21:23:37][Xiaotian (Jackie) Jiang][commit][ffa954194e61e330c625a795cae94c15a54a2694]
Pre-generate aggregation functions in QueryContext (#5805)

`AggregationFunction` itself is stateless, so we can share it among all the segments to prevent the overhead of creating it per segment. This can significantly improve the performance of high selectivity queries that hit lots of segments.

- Remove the `accept(visitor)` from the `AggregationFunction` interface which may make it stateful
- Make `DistinctCount` and `DistinctCountBitmap` stateless by caching the dictionary within the result holder
","[2020-08-04 19:59:16][Jackie-Jiang][pull:summary][5805]
## Description
`AggregationFunction` itself is stateless, so we can share it among all the segments to prevent the overhead of creating it per segment. This can significantly improve the performance of high selectivity queries that hit lots of segments.

- Remove the `accept(visitor)` from the `AggregationFunction` interface which may make it stateful
- Make `DistinctCount` and `DistinctCountBitmap` stateless by caching the dictionary within the result holder

## Release Notes
Interface change: `accept(visitor)` is removed from `AggregationFunction`
All the implementation of the `AggregationFunction` should be stateless so that it can be shared among all the segments."
Druid,No Relation,"[2020-07-01 20:02:28][maytasm][pull:comment][10120:448587442]
Added a override system property `druid.sql.planner.hepMatchLimit` that can override the default value of 1200
This system property is not documented though as it should not be modify by user without deep investigation into Calcite/HepProgram use by Druid. Assuming you are doing investigation on determining new value for matchLimit in Druid code, then you will see this system property anyway.
","[2020-03-06 07:35:21][Chunwei Lei][issue:comment][CALCITE-3845:17053103]
IMO, there are 3 ways to fix this issue:

1) do not push nullability CAST to CASE

2) do not simplify {{cast(true): boolean nullable}} to true

3) do not consider as reduced if the case happens

Personally I prefer 3."
Incubator Pinot,No Relation,"[2017-11-13 18:13:48][Xiaotian Jiang][commit][30098c87c236dffab3c90dd8b8073da37152d5b5]
Remove BlockId class and nextBlock(BlockId) API in Operator (#2099)

1. Remove BlockId class
2. Remove nextBlock(BlockId) API in Operator because we should never index on block
3. Add the type of block to Operator for clarity
4. Change getNextBlock() API in BaseOperator to be protected so that we always call nextBlock() for tracking purpose
NOTE: inside filter operator, nextBlock() should be called only once
","[2017-11-14 01:01:40][snleee][pull:comment][2099:150711726]
Can we add the documentation on the reason why you put this as `protected`? I see that you put the explanation on the pr message but it would be helpful to put a documentation here."
Reef,SATD Repayment,"[2015-10-15 16:15:17][Mariia Mykhailova][commit][a9fc25862e8b36039adc1a9d2f27108beaeedfd3]
[REEF-523] Add missing Javadoc/triage TODOs in Java code: reef-common

This adds missing Javadoc comments and links to JIRA items in TODOs.
Also fixes several typos.

JIRA:
  [REEF-523](https://issues.apache.org/jira/browse/REEF-523)

Pull request:
  This closes #563
","[2015-10-14 00:17:41][tcNickolas][pull:summary][563]
This adds missing Javadoc comments and links to JIRA items in TODOs.
Also fixes several typos.

JIRA:
  [REEF-523](https://issues.apache.org/jira/browse/REEF-523)

Pull request:
  This closes #"
Incubator Pinot,SATD Repayment,"[2020-05-29 14:08:03][Sidd][commit][b40dd992874f9bc38b911870e041a8f6e24c3776]
Faster bit unpacking (Part 1) (#5409)

* Faster bit unpacking

* Add unit tests

* new

* Improved degree of vectorization and more tests

* fix build

* cleanup

* docs

* change file name

* address review comments and add more benchmarks

Co-authored-by: Siddharth Teotia <steotia@steotia-mn1.linkedin.biz>
","[2020-05-18 22:59:26][siddharthteotia][pull:summary][5409]
Faster vectorized bit unpacking (Part 1)"
Dubbo,SATD Repayment,"[2018-09-14 17:31:18][cvictory][commit][577eb77cce6cd0e52fe581e406f7d9b2e9a34a7c]
Merge pull request #2468, Simplify registry data and add a new service data store seperated from registry #2030 (#2468)
","[2018-09-07 08:33:31][cvictory][pull:summary][2468]
Simplify registry data and add a new service data store seperated from registry #2030"
Geode,No Relation,"[2016-09-14 11:08:18][Hitesh Khamesra][code-comment][8ea08da3d2baa64ca631641430b54d71ce3ff362]
protected void cleanupHighWater() {
  cleanup(highWater);
}
","[2015-07-10 18:18:41][Anthony Baker][issue:comment][GEODE-37:14622703]
Yes.  As noted in [1] we may choose to avoid renaming certain classes used in Client/Server messaging to avoid breaking backwards compatibility.

[1] http://mail-archives.apache.org/mod_mbox/incubator-geode-dev/201507.mbox/%3cCAGHyZ6KR2DtumcLcOjASa0AS4XqnZQD75zA92Xt4mmq7f57kxQ@mail.gmail.com%3e"
Bookkeeper,SATD Repayment,"[2016-12-29 02:11:40][Sijie Guo][commit][d7105aa88f29faecd779c4371fb023775e2c7e40]
DL-159: ReadAhead Improvement (part 2) - New ReadAhead Reader using the LogSegmentEntryReader interface

Provide a new ReadAhead reader using the log segment entry reader interface. It does reading entries in a batch in parallel for batches, rather than reading entries in batch by batch. This would help mitigate the slow bookie problem.

The core change is the new ReadAheadEntryReader.
","[2016-12-29 08:26:47][Sijie Guo][issue:summary][DL-159:13031036]
Current readahead is a batch-read based sequential reads. It doesn't handle slow bookies very well. This change is to improve the readahead behavior to use a more streaming solution to read ahead."
Parquet Mr,SATD Duplication,"[2016-03-24 20:33:20][nezihyigitbasi][pull:summary][338]
If an exception occurs when closing the input stream `f`, the codecs
will not be released. This may cause native memory leaks for some codecs. \cc @rdblue
","[2016-03-24 20:32:56][Nezih Yigitbasi][issue:summary][PARQUET-571:12953374]
If an exception occurs when closing the input stream `f`, the codecs will not
be released. This may cause native memory leaks for some codecs."
Cloudstack,No Relation,"[2011-06-21 01:12:06][Alex Huang][code-comment][5771b35a7a77ea9f895b9e2379f2c90ddb349574]
* 
   * The category of the logging event. This field is not serialized
   * for performance reasons.
   *
   * <p>It is set by the LoggingEvent constructor or set by a remote
   * entity after deserialization.
   * 
   * @deprecated This field will be marked as private or be completely
   * removed in future releases. Please do not use it.
   *
","[2011-06-21 01:12:06][Alex Huang][commit][5771b35a7a77ea9f895b9e2379f2c90ddb349574]
new log4j jar files and now the ability to get rid of the stupid cglib stack traces in our logs"
Arrow,No Relation,"[2016-06-06 23:32:38][fengguangyuan][commit][9ce13a06726874c04433100127f74e6ea4afa855]
ARROW-60: [C++] Struct type builder API

Implement the basic classes, `StructArray` and `StructBuilder,` meanwhile,

add the perspective test cases for them.

Other necessary methods will be added subsequently.

Author: fengguangyuan <root@node20.(none)>

Closes #66 from fengguangyuan/ARROW-60 and squashes the following commits:

190967f [fengguangyuan] ARROW-60: [C++] Struct type builder API Add field index and TODO comment.
ae74c80 [fengguangyuan] ARROW-60: Struct type builder API Add RangeEquals method to implement Equals method.
fa856fd [fengguangyuan] ARROW-60:[C++] Struct typebuilder API Modify Validate() refered to the specification.
bfabdc1 [fengguangyuan] ARROW-60: Struct type builder API Refine the previous committed patch. Add validate methods for testing StructArray and StructBuilder. TODO, Equals methods also need to be tested, but now it's not convient to do it.
5733de7 [fengguangyuan] ARROW-60: Struct type builder API
","[2016-04-23 14:14:00][wesm][pull:comment][66:60829153]
for the StructBuilder, perhaps these methods should be `builder_->field(i)` to be more clear as noted above"
Superset,No Relation,"[2019-07-16 21:36:56][Maxime Beauchemin][code-comment][d65b039219c9825ad50ec03ad73a1638710c73c9]
 Handling schema being '' or None, which is easier to handle
 in python than in the SQLA query in a multi-dialect way
","[2019-07-16 21:36:56][Maxime Beauchemin][commit][d65b039219c9825ad50ec03ad73a1638710c73c9]
Improve examples & related tests (#7773)

* [WiP] improve load_examples

related to #7472, longer term we will generate the examples by exporting
them into tarball as in #7472. In the meantime, we need this subset of
the features:

* allowing specifying an alternate database connection for examples
* allowing a --only-metadata flag to `load_examples` to load only
  dashboard and chart definitions, no actual data is loaded

* Improve logging

* Rename data->examples

* Load only if not exist

* By default do not load, add a force flag

* fix build

* set published to true"
Activemq Artemis,No Relation,"[2017-06-30 16:17:19][Francesco Nigro][code-comment][7075e2e457d6d87f6a870da07658d47d5d29d461]
the fill will give a big performance hit when done in parallel of other writings!
","[2017-06-30 16:17:19][Francesco Nigro][commit][7075e2e457d6d87f6a870da07658d47d5d29d461]
ARTEMIS-1266 Mapped Journal refactoring

The MAPPED journal refactoring include:
 - simplified lifecycle and logic (eg fixed file size with single mmap memory region)
 - supports for the TimedBuffer to coalesce msyncs (via Decorator pattern)
 - TLAB pooling of direct ByteBuffer like the NIO journal
 - remove of old benchmarks and benchmark dependencies"
Kafka,No Relation,"[2019-05-08 09:31:05][Dhruvil Shah][code-comment][e6cff21fd8c5add0eb7e55417a91f0530a7d3a32]
 We may be able to recover from this exception if metadata for this topic is no longer needed
","[2019-01-07 21:56:42][hachikuji][pull:comment][5542:245811620]
@dhruvilshah3 I agree the argument cuts both ways. Long term, if we assume that we will eventually drop support for 0.10 clients, then it would be a shame to have an unneeded config policy left around. Perhaps we can just choose the behavior we like best for ""disallow."" If we choose the strict behavior, then dropping support for 0.10 will probably be the prerequisite for making it the default, which may be reasonable. I'm not sure we've ever documented how long the clients should continue working with older brokers."
Drill,No Relation,"[2015-10-13 16:35:22][Chris Westin][commit][27364122ca0a82c6dd5552f292b2711bb2b28cf5]
DRILL-3920: Additional tests added to TestValueVectors for serialization and loading.
Some light cleanup of a few vector implementations.

closes #194
","[2015-10-12 22:31:52][hnfgns][pull:comment][194:41808424]
the logic in clear() seems duplicating close(). we should directly call close perhaps."
Camel,SATD Repayment,"[2015-12-10 15:15:44][Claus Ibsen][commit][e6b06ad05f3b14d7df9be581f0a0108291eae3eb]
CAMEL-9410: camel-netty-http - should default to port 80 and 443
","[2015-12-10 13:53:55][Claus Ibsen][issue:summary][CAMEL-9410:12920768]
camel-netty-http - should default to port 80 and 443"
Airflow,SATD Repayment,"[2019-07-20 11:00:26][Kamil Breguła][commit][96933b07978ec1414a928f65ffda0dde926dd079]
[AIRFLOW-4952] Remove unused arguments in tests (#5586)
","[2019-07-15 19:13:26][turbaszek][pull:comment][5586:303592391]
The `unused-argument` is quite popular in tests, so maybe we can unify the process of fixing this error. What about using `*args, **kwargs` in such cases? Thank to proposed change in `pylintrc` this will resolve the problem and preserve all logic."
Reef,SATD Duplication,"[2016-03-29 07:21:22][sdudoladov][pull:summary][911]
[REEF-1261] Enable ConstructorWithoutParamsCheck from sevntu-checkstyle
","[2016-03-17 20:12:27][Sergey Dudoladov][issue:summary][REEF-1261:12951320]
 Enable ConstructorWithoutParamsCheck from sevntu-checkstyle"
Beam,SATD Repayment,"[2019-09-25 16:13:35][Maximilian Michels][code-comment][948c6fae909685e09d36b23be643182b34c8df25]
 Use loops here due to the horrible performance of Java Streams:
 https://medium.com/@milan.mimica/slow-like-a-stream-fast-like-a-loop-524f70391182
","[2019-09-24 18:29:03][lukecwik][pull:comment][9374:327769381]
nit: [streams are siginficantly slower than for loops even with JDK 12](https://medium.com/@milan.mimica/slow-like-a-stream-fast-like-a-loop-524f70391182)"
Incubator Pinot,SATD Duplication,"[2017-07-24 16:27:14][Xiaotian Jiang][code-comment][d6e37665863bdbe10138d730f00200cbcd2e0c1b]
 Disabled because with multiple servers, there is no way to check and guarantee that all servers get all segments
 reloaded, which cause the flakiness of the tests.
","[2017-07-24 18:00:05][Jackie-Jiang][pull:summary][1700]
With multiple servers, there is no way to check and guarantee that all servers get all segments reloaded, which cause the flakiness of the tests.
To fix that, in OfflineClusterIntegrationTest, only start one server.
Added a MultiNodesOfflineClusterIntegrationTest to keep the same coverage for multiple brokers and multiple servers."
Camel,SATD Repayment,"[2016-11-07 20:12:06][Tadayoshi Sato][commit][583bec8fb6d5595170d6ab36981d4acdcb9de4c2]
CAMEL-10446 - Need to consolidate header mapping logic between Camel and CXF messages
","[2016-11-05 12:33:49][Tadayoshi Sato][issue:summary][CAMEL-10446:13018595]
In the current codebase of {{camel-cxf}} and {{camel-cxf-transport}}, the header mapping logic between CXF and Camel messages is scattered around {{DefaultCxfRsBinding}}, {{CxfHeaderHelper}}, and other classes. It should be consolidated into a single place, e.g. {{CxfHeaderHelper}}, as much as possible.

I'd like to call it a ""bug"" because due to this lack of unified header mappings I observe some CXF-specific headers accidentally flow into the Camel world and vice versa."
Kafka,SATD Repayment,"[2015-10-28 10:11:05][Guozhang Wang][commit][b6fe164dd6f9483469c0b0661c24467e33e91cd9]
MINOR: Clean-up MemoryRecords variables and APIs

Author: Guozhang Wang <wangguoz@gmail.com>

Reviewers: Jun Rao

Closes #348 from guozhangwang/MemoryRecordsCapacity
","[2015-10-21 21:41:04][guozhangwang][pull:summary][348]
MINOR: Clean-up MemoryRecords variables and APIs"
Reef,SATD Repayment,"[2015-11-16 09:33:18][Dongjoon Hyun][commit][fc5d9079bb080120932da496635b8e1bcf9c7f54]
[REEF-949] Remove unnecessary TODO comment in Mesos-runtime module

Since the current code already submits its executing user to Mesos,
this PR simply removes a TODO comment to prevent further confusion.

JIRA:
  [REEF-949](https://issues.apache.org/jira/browse/REEF-949)

Pull request:
  This closes #643
","[2015-11-15 16:32:45][Dongjoon Hyun][issue:summary][REEF-949:12913158]
At first look, I thought the following TODO comment means we need to add `MesosUser` parameter for `REEFScheduler`.

{code}
final Protos.FrameworkInfo frameworkInfo = Protos.FrameworkInfo.newBuilder()
        .setUser("""") // TODO: make it configurable.
{code}

However, the current code already submits *its executing user* to Mesos correctly. I tested with `root` and `hadoop` account on Mesos 0.25.

In short, we had better remove the comment simply in order to prevent further confusion."
Hawq,SATD Repayment,"[2015-11-14 15:41:01][rlei][commit][3691f2367371001b1ac56156affb587d07459c56]
HAWQ-158. Remove legacy command line tools and help.
","[2015-11-13 10:14:17][Radar Da Lei][issue:summary][HAWQ-158:12912782]
Remove legacy command line tools which not in use"
Incubator Pinot,SATD Duplication,"[2018-11-27 15:00:20][Akshay Rai][code-comment][61b4814cca55ad18c9270a5fd402003859a48c07]
 TODO: The old UI relies on notified tag to display the anomalies. After the migration
 we need to clean up all references to notified tag.
","[2018-11-27 15:00:20][Akshay Rai][commit][61b4814cca55ad18c9270a5fd402003859a48c07]
[TE] Make new alerter tag old anomalies as notified (#3554)

The current UI relies on notified tag to fetch and display the anomalies.Due to this behavior, when an old pipeline anomaly is alerted using the new alerter it doesn't show up on the UI. The notified tag needs to be cleaned up after the migration."
Nutch,No Relation,"[2005-12-29 00:37:13][Andrzej Bialecki][code-comment(deleted)][b8bd3f133b29d794833bdcffc1bfd0d41d421066]
 When we delete a link, we do it by MD5 and apply
   it to the index first.  A single delete instruction
   may remove many items in the db, during the earlier
   processing.  However, unlike the index-processing stage,
   here we can expect a new DEL instruction for every 
   item that we remove from the db.
","[2005-12-29 00:37:13][Andrzej Bialecki][commit][b8bd3f133b29d794833bdcffc1bfd0d41d421066]
Mega-cleanup patch:

* remove obsolete classes and packages

* move new classes to the more appropriate packages

* change the bin/nutch script appropriately

* change the Protocol API in preparation for patches implementing
  flexible re-fetch schedules.

Please report any errors (if any? :).



git-svn-id: https://svn.apache.org/repos/asf/lucene/nutch/trunk@359668 13f79535-47bb-0310-9956-ffa450edef68"
Druid,SATD Duplication,"[2019-11-20 21:22:55][Jonathan Wei][code-comment][dc6178d1f2332fe03e18576713ad517c87d4d031]
 Ideally the following filter should be simplified to (dim2 == 'a' || dim2 IS NULL), the
 (dim2 != 'a') component is unnecessary.
","[2019-11-20 20:02:01][gianm][pull:comment][8566:348717641]
The new filter is `dim2 = 'a' OR (dim2 IS NULL AND dim2 != 'a')`. It seems a bit… weird. Ideally it should be simplified to `dim2 = 'a' OR dim2 IS NULL`. It's fine for now, but could you add a comment about this?"
Hbase,SATD Repayment,"[2015-11-06 16:23:55][Apekshit(Appy) Sharma][commit][08963189a298504e4e4ae70a1a139112a2eba59e]
HBASE-14767 - Remove deprecated functions from HBaseAdmin Deprecated in HBASE-12083 (1.0.0, 2.0.0, 0.99.2) - HBaseAdmin(Configuration)

  Deprecated in HBASE-10479 (0.99.0, hbase-10070)
  - HBaseAdmin(Connection)

  Deprecated in HBASE-11826 (0.99.0, 1.0.0, 2.0.0)
  - flush()
  - compact()
  - majorCompact()
  - split()
  - getCompactionState()

- Changes many declarations from HBaseAdmin to Admin
(Apekshit)

Signed-off-by: stack <stack@apache.org>
","[2015-11-05 03:04:14][Apekshit Sharma][issue:summary][HBASE-14767:12910596]
Remove deprecated functions from HBaseAdmin"
Jena,No Relation,"[2015-03-14 21:07:12][Andy Seaborne][code-comment][0d5eaad9e178331be81a57e2259528831db5db6a]
 This should not be very expensive.
","[2015-03-14 21:07:12][Andy Seaborne][commit][0d5eaad9e178331be81a57e2259528831db5db6a]
Typos"
Lucene Solr,No Relation,"[2021-02-22 10:45:13][Julie Tibshirani][code-comment][f43fe7642e9f1eb48b7438e2b132d9efc641edb6]
 TODO: we could skip this if !hasTerms; but
 that's rare so won't help much
 metadata
","[2021-02-11 18:09:16][jpountz][pull:comment][2310:777686222]
> I wonder if we should not version PFUtil classes, instead move then to a package under Util and change the visibility of the methods. Those classes seems more like a utility to me.

I've become a bit wary of having shared utility classes for codecs given how it makes the code harder to evolve (e.g. I have the FST and PackedInts classes in mind). I'd rather like to copy this utility class wherever it's needed so that every file format that uses bit packing can more easily update the logic to fits its own needs."
Hive,No Relation,"[2015-05-07 14:16:25][jpullokk][code-comment][809fcb01457ab7ba09786f237ce558e81c53ee49]
 TODO: This should inherit from VolcanoCost and should just override isLE
 method.
","[2015-04-29 00:17:59][Ashutosh Chauhan][issue:comment][HIVE-10526:14518417]
Wondering if its better to separate io & cpu cost as well :
{code}
return (this == other) || 
      ((Math.abs((this.io) - (other.getio())) < RelOptUtil.EPSILON) 
      &&((Math.abs((this.cpu) - (other.getCpu())) < RelOptUtil.EPSILON) 
      && (Math.abs((this.rowCount - other.getRows())) < RelOptUtil.EPSILON));
{code}"
Camel,SATD Repayment,"[2015-12-10 15:15:44][Claus Ibsen][commit][e6b06ad05f3b14d7df9be581f0a0108291eae3eb]
CAMEL-9410: camel-netty-http - should default to port 80 and 443
","[2015-12-10 13:53:55][Claus Ibsen][issue:summary][CAMEL-9410:12920768]
camel-netty-http - should default to port 80 and 443"
Arrow,No Relation,"[2016-10-10 15:07:51][wesm][pull:comment][164:252651125]
There's a lot of duplicated boilerplate for configuring shared libs -- we should create some cmake functions to make this easier / cleaner -- see ARROW-330
","[2016-10-03 01:39:04][Wes McKinney][issue:summary][ARROW-312:13009149]
This is now much easier to do with ARROW-293 and ARROW-302"
Spark,SATD Repayment,"[2020-11-30 13:59:51][Josh Soref][commit][485145326a9c97ede260b0e267ee116f182cfd56]
[MINOR] Spelling bin core docs external mllib repl

### What changes were proposed in this pull request?

This PR intends to fix typos in the sub-modules:
* `bin`
* `core`
* `docs`
* `external`
* `mllib`
* `repl`
* `pom.xml`

Split per srowen https://github.com/apache/spark/pull/30323#issuecomment-728981618

NOTE: The misspellings have been reported at https://github.com/jsoref/spark/commit/706a726f87a0bbf5e31467fae9015218773db85b#commitcomment-44064356

### Why are the changes needed?

Misspelled words make it harder to read / understand content.

### Does this PR introduce _any_ user-facing change?

There are various fixes to documentation, etc...

### How was this patch tested?

No testing was performed

Closes #30530 from jsoref/spelling-bin-core-docs-external-mllib-repl.

Authored-by: Josh Soref <jsoref@users.noreply.github.com>
Signed-off-by: Takeshi Yamamuro <yamamuro@apache.org>
","[2020-11-28 23:23:44][jsoref][pull:summary][30530]
[MINOR] Spelling bin core docs external mllib repl"
Hawq,SATD Repayment,"[2015-11-14 15:41:01][rlei][commit][3691f2367371001b1ac56156affb587d07459c56]
HAWQ-158. Remove legacy command line tools and help.
","[2015-11-13 10:14:17][Radar Da Lei][issue:summary][HAWQ-158:12912782]
Remove legacy command line tools which not in use"
Beam,SATD Duplication,"[2017-04-13 11:24:01][echauchot][pull:summary][2523]
[BEAM-1272] Align the naming of ""generateInitialSplits"" and ""splitIntoBundles"" to better reflect their intention
","[2017-01-15 11:35:56][Stas Levin][issue:summary][BEAM-1272:13035013]
Align the naming of ""generateInitialSplits"" and ""splitIntoBundles"" to better reflect their intention"
Trafodion,SATD Duplication,"[2019-10-03 22:05:13][selvaganesang][pull:summary][1860]
[TRAFODION-3329] Code cleanup in Type 2 driver
","[2019-10-02 22:22:01][Selvaganesan Govindarajan][issue:summary][TRAFODION-3329:13260200]
Remove unused code in T2 driver"
Drill,SATD Repayment,"[2018-05-21 15:06:50][Salim Achouche][commit][399fc99827c5eff413cb1aa8489af09cc1266ff3]
DRILL-5846: Improve parquet performance for Flat Data Types

closes #1060
","[2017-12-04 02:29:01][sachouche][pull:summary][1060]
DRILL-5846: Improve parquet performance for Flat Data Types"
Nifi Minifi Cpp,No Relation,"[2017-02-22 15:47:02][Andrew Christianson][code-comment][a9485aeb05defe3e54b179c3b5dcc1735486abcd]
 XXX: keys is an internal object with all keys to be processed
	 * in its (gapless) array part.  Because nobody can touch the keys
	 * object, we could iterate its array part directly (keeping in mind
	 * that it can be reallocated).
","[2017-02-16 12:08:59][achristianson][pull:comment][43:101504064]
@phrocker No problem. It makes it a lot easier to avoid memory management bugs."
Samza,SATD Repayment,"[2020-01-14 12:03:24][Ke Wu][commit][eaa0491d7527d9e8c6fbe3ed923cf2aa1034d21c]
Clean up unused org.apache.samza.autoscaling module (#1250)

Issues: samza-autoscaling module is not used.

Changes: remove the unused module.

API Changes:
None

Upgrade Instructions:
None

Usage Instructions:
None

Tests: build
","[2020-01-11 01:41:01][kw2542][pull:summary][1250]
Clean up unused org.apache.samza.autoscaling module"
Lucene Solr,No Relation,"[2010-09-28 06:16:16][Steven Rowe][code-comment][3c26a9167cc3a4f5d338e9b74d0af61d6de9d773]
 ÷ 0030 × 0031 ÷ 002E × 2060 ÷	#  ÷ [0.2] DIGIT ZERO (Numeric) × [8.0] DIGIT ONE (Numeric) ÷ [999.0] FULL STOP (MidNumLet) × [4.0] WORD JOINER (Format_FE) ÷ [0.3]
","[2010-05-09 05:07:20][Steven Rowe][issue:comment][LUCENE-2167:12865541]
Attached a patch that removes lookahead/chaining.  All tests pass.

UAX29Tokenizer is now in the same ballpark performance-wise as StandardTokenizer:

||Operation||recsPerRun||rec/s||elapsedSec||
|StandardTokenizer|1262799|658,737.06|1.92|
|ICUTokenizer|1268451|542,768.94|2.34|
|UAX29Tokenizer|1268451|668,661.56|1.90|"
Incubator Pinot,SATD Duplication,"[2016-12-15 13:27:58][Jackie-Jiang][commit][8cb6e4873034283b327d674638a90c6bfe839713]
Add backward compatible for the new selection only logic. (#910)

In the old code, the selection only columns order in data schema
might be different with the actual order. Add code to handle this,
and after server update to the latest version, remove the code for
backward compatible to get the highest performance.
","[2016-12-15 19:24:02][Jackie-Jiang][pull:summary][910]
In the old code, the selection only columns order in data schema
might be different with the actual order. Add code to handle this,
and after server update to the latest version, remove the code for
backward compatible to get the highest performance."
Lucene Solr,No Relation,"[2009-05-09 10:36:41][Michael McCandless][code-comment][d4f98095200d1c48c24597809f8e61e961aad3f7]
 TODO: The following should be changed to first obtain a Scorer and then ask it
 if it's going to return in-order or out-of-order docs, and create TSDC
 accordingly.
","[2009-04-15 18:57:19][Shai Erera][issue:comment][LUCENE-1593:12699314]
I thought that when we move to 3.0 we're not expected to support jar drop-in-ability? Those two methods are already declared final, so no one could override them. The only problem now is with jar drop-in-ability.

If I'm wrong, and we are suppose to support it, then I can offer new names for these two and deprecate them:
* toppablePut(), toppableAdjustTop() - least favored of mine, but I write them here anyway.
* putWithOverflow, adjustTopWithOverflow - the 'withOverflow' is consistent with insert, but unlike insert, there's no overflow here.
* offer/add (for put) and updateTop.

You can suggest yours too. However I do think that if jar drop-in-ability is not required in 3.0, we should not change the names and just document the impl changes in 3.0."
Lucene Solr,No Relation,"[2020-08-14 17:52:31][Ishan Chattopadhyaya][code-comment][590d35c66e22cb356c331af41356f63de1cc20a4]
*
   * HACK to work around SOLR-11775.
   * Asserts that the 'actual' argument is a (non-null) Number, then compares it's 'longValue' to the 'expected' argument
","[2019-05-02 07:27:07][Ishan Chattopadhyaya][issue:comment][SOLR-13350:16831454]
Updated patch with the following:
# Added an executor service (which is used for the multi-threaded search).
# TODO: JoinQParserPlugin closes the ""from core"" on every thread of the search (using a close hook). This causes problems with multiple core close calls for the same request. Tried to handle it naively for now (to make the tests pass). Does someone have ideas to tackle it properly?
# TODO: Add a parameter to selectively enable multi-threaded search. Use that parameter randomly with tests.

Right now, except the Join tests (esp. TestCrossCoreJoin), all pass."
Kafka,SATD Duplication,"[2016-11-04 12:49:29][dguy][pull:summary][2103]
The `StoreChangeLogger` currently keeps a cache of dirty and removed keys and will batch the changelog records such that we don't send a record for each update. However, with KIP-63 this is unnecessary as the batching and de-duping is done by the caching layer. Further, the `StoreChangeLogger` relies on `context.timestamp()` which is likely to be incorrect when caching is enabled
","[2016-11-04 11:47:54][Damian Guy][issue:summary][KAFKA-4379:13018043]
The StoreChangeLogger currently keeps a cache of dirty and removed keys and will batch the changelog records such that we don't send a record for each update. However, with KIP-63 this is unnecessary as the batching and de-duping is done by the caching layer. Further, the StoreChangeLogger relies on context.timestamp() which is likely to be incorrect when caching is enabled"
Systemds,SATD Repayment,"[2017-04-01 14:47:44][Matthias Boehm][code-comment][648c628505f04e75e6ece03ec4805a9641bbff88]
nrow(X) -> literal(nrow(X)), ncol(X) -> literal(ncol(X)), if respective dims known
(this rewrite aims to remove unnecessary data dependencies to X which trigger computation
even if the intermediate is otherwise not required, e.g., when part of a fused operator)
","[2017-04-01 14:47:44][Matthias Boehm][commit][648c628505f04e75e6ece03ec4805a9641bbff88]
[SYSTEMML-1454] New dynamic rewrites for nrow/ncol literal replacement

This patch adds rewrites to replace unnecessary nrow/ncol operators with
literals in case of known dimensions after size updates during dynamic
recompilation. These unnecessary nrow/ncol operations have data
dependencies to their inputs which trigger computation even if the
intermediates are otherwise not required, for example, if they are part
of an existing or code generated fused operator."
Arrow,SATD Repayment,"[2020-04-14 15:13:44][Krisztián Szűcs][commit][b0902ab32f26681c9e99a0b61a5ab5d6d03a20df]
ARROW-8444: [Documentation] Fix spelling errors across the codebase

Quickly run `codespell` which found a couple of misspellings.

Closes #6931 from kszucs/spelling

Authored-by: Krisztián Szűcs <szucs.krisztian@gmail.com>
Signed-off-by: Benjamin Kietzman <bengilgit@gmail.com>
","[2020-04-14 12:35:36][Krisztian Szucs][issue:summary][ARROW-8444:13298261]
[Documentation] Fix spelling errors across the codebase"
Systemds,SATD Repayment,"[2014-12-17 02:12:05][MATTHIAS BOEHM][code-comment][d5c11663a25ad4e3756915c21af7cb79a2a97608]
remove unnecessary chain of -(-())
","[2014-12-17 02:12:05][MATTHIAS BOEHM][commit][d5c11663a25ad4e3756915c21af7cb79a2a97608]
55555: SystemML Engine Enhancements - New algebraic simplification rewrites (simplify binary to minus, fuse datagen/minus, remove unnecessary minus)"
Shardingsphere Elasticjob,SATD Duplication,"[2020-10-19 19:29:09][Liang Zhang][code-comment][dc25797275052f4519e7c59331be295bb3ee9d44]
 TODO default value is 3000
","[2020-10-19 19:29:09][Liang Zhang][commit][dc25797275052f4519e7c59331be295bb3ee9d44]
Add todo to default value (#1600)"
Tajo,SATD Repayment,"[2014-08-05 11:58:16][jinossy][commit][0f3412a74bb3c565df1259b19630bc17e1bc69e0]
TAJO-989: Cleanup of child blocks after parent execution block is complete. (jinho)

Closes #103
","[2014-08-03 14:06:55][Jinho Kim][issue:summary][TAJO-989:12731608]
Cleanup of child blocks after parent execution block is complete"
Ignite,SATD Repayment,"[2016-06-17 19:29:33][Pavel Tupitsyn][commit][ead2b1f5aa0637e82b55a8071dd9af911f25f2a3]
IGNITE-3097 .NET: Improve reflective serialization performance

This closes #698
","[2016-05-10 14:50:22][ptupitsyn][pull:summary][698]
IGNITE-3097 .NET: Improve reflective serialization performance"
Arrow,No Relation,"[2020-02-20 14:21:13][wesm][pull:comment][6460:589074911]
I changed the PR title, it seems like (unless I've misunderstood) the issue is about incremental reads using this code path, and our current unit tests only test all-or-nothing reads of row groups. So we should write some unit tests with incremental reads that exhibit the problem
","[2020-01-08 00:22:14][Wes McKinney][issue:comment][ARROW-6895:17010200]
Was this never fixed? I must have gotten sidetracked. Leaving in 0.16.0"
Cloudstack,SATD Repayment,"[2016-05-12 16:49:14][Will Stevens][commit][8c3722d953fc54aed38824265be8bf27f4dd0abf]
Merge pull request #1444 from rafaelweingartner/workAroundPR780

CLOUDSTACK-8800 : Improved the listVirtualMachines API call to include memory utilization information for a VMThis PR introduces the changes proposed in PR #780 with some work to make the code null safe.

During this PR, I have also removed some unused code.

* pr/1444:
  Removed unnecessary check when creating the “userVmResponse” object.
  Fixed issues from CLOUDSTACK-8800 that were introduced in PR 780
  CLOUDSTACK-8800 : Improved the listVirtualMachines API call to include memory utilization information for a VM for xenserver,kvm and for vmware.

Signed-off-by: Will Stevens <williamstevens@gmail.com>
","[2016-03-19 19:43:02][rafaelweingartner][pull:summary][1444]
CLOUDSTACK-8800 : Improved the listVirtualMachines API call to include memory utilization information for a VM"
Flink,SATD Duplication,"[2017-01-10 19:13:19][xhumanoid][pull:summary][3089]
[FLINK-5497] remove duplicated tests
","[2017-01-15 20:11:39][Alexey Diomin][issue:summary][FLINK-5497:13035051]
remove duplicated tests"
Beam,SATD Duplication,"[2018-06-28 16:09:01][chamikaramj][pull:summary][5813]
Some of the error logs that contain BQ load jobs can be extremely large and drop the actual error message. Usually this happens due to 'schema' and/or ''sourceUris' of the job configuration of load jobs being very large. I think these properties are not that useful for debugging so we should consider dropping them from error messages.
","[2018-06-28 15:37:52][Chamikara Madhusanka Jayalath][issue:summary][BEAM-4675:13168900]
Some of the error logs that contain BQ load jobs can be extremely large and drop the actual error message. Usually this happens due to 'schema' and/or ''sourceUris' of the job configuration of load jobs being very large. I think these properties are not that useful for debugging so we should consider dropping them from error messages."
Geode,SATD Repayment,"[2019-12-11 09:26:03][Scott Jewell][commit][82c0a739efaa28e4456f045f3dc3d574325cb109]
GEODE-7567: Improve cleanup logic in create_instance.sh (#4459)

* GEODE-7567: Improve cleanup logic in create_instance.sh

* GEODE-7567: Increase number of retry attempts
","[2019-12-10 21:20:19][Scott Jewell][issue:summary][GEODE-7567:13273707]
Improve create_instance cleanup logic"
Helix,SATD Repayment,"[2020-02-07 12:24:22][Jiajun Wang][commit][39f395937ef86a0cf60687e76dec40c0434a942b]
Refine the WAGED rebalancer to minimize the partial rebalance workload. (#639)

* Refine the WAGED rebalancer to minimize the partial rebalance workload.

Split the cluster module calculation method so that different rebalance logic can have different rebalance scope calculation logic.
Also, refine the WAGED rebalancer logic to reduce duplicate code.
","[2019-11-01 06:22:02][jiajunwang][issue:summary][563]
Improve the WAGED rebalancer calculating speed."
Kafka,No Relation,"[2015-11-02 21:47:40][guozhangwang][pull:comment][388:43687466]
nit: Do we want to return an empty group with NONE error in this case? If we do then the client need to carefully handle the empty group case as you did now.
","[2015-11-20 21:44:41][Jun Rao][issue:comment][KAFKA-2687:15018863]
[~sslavic], thanks for reporting the typo. I fixed that in the 0.9.0 docs."
Accumulo,SATD Repayment,"[2017-03-20 10:47:00][Keith Turner][code-comment][94cdcc4d3f0a8ccf95894f206cb71e6117f4e51d]
*
   * A summarizer that counts the number of times {@code foo} and {@code bar} occur in the row.
","[2017-03-02 00:20:15][keith-turner][pull:comment][224:103824011]
Checking summarizerProps is completely unnecessary here. The function is used in three places.  Only in one of those three places does it actually need to check both."
Lucene Solr,No Relation,"[2019-01-11 14:47:57][Gus Heck][commit][dcc9ffe186eb1873fcebc56382e3be34245b0ecc]
SOLR-13051 improve TRA update processor test
  - remove some timeouts
  - better async mechanism linked to SolrCore lifecycle
  - add some additional tests to be a bit more thorough
","[2019-01-11 20:58:55][David Smiley][issue:comment][SOLR-13051:16740784]
Avoid the CHANGES.txt IMO.  I don't think there's a policy here.  I might be more inclined to if the person who substantively did the change were a contributor, so as to give a bit more recognition, but IMO it's better for CHANGES.txt to be a useful document, and an issue like this is noise that dilutes the usefulness.

BTW thanks for working on this and I like {{SolrCore.runAsync}}"
Lucene Solr,No Relation,"[2015-10-21 21:59:08][Nick Knize][code-comment][d369057766ae8320433de32297527a010c070fbe]
*
     * Computes the maximum shift for the given pointDistanceQuery. This prevents unnecessary depth traversal
     * given the size of the distance query.
","[2015-09-14 21:23:07][Michael McCandless][issue:comment][LUCENE-6780:14744297]
bq. The test was buggy using maxLon where it expected minLon

Duh!  Thanks for fixing :)

I committed the patch w/ some minor code style changes, but added some nocommits, e.g. I'm not sure how {{circleFullInside}} testing helps since it seems to always assert to true in that case.

I'll beast the new test!"
Tomee,SATD Repayment,"[2014-11-17 16:29:13][Romain Manni-Bucau][code-comment][7a8c8aa8d756d429f72060bf78e0b986abe0d0eb]
*
 * IMPORTANT NOTE: when using this event it should be compared to BeforeAppInfoBuilderEvent which is likely better.
 * Main reason to use BeforeStartEjbs is the need of reflection (to do filtering for instance). All other cases shouldn't use it.
","[2014-11-17 15:28:40][Romain Manni-Bucau][issue:summary][TOMEE-1446:12755812]
IMPORTANT NOTE: when using this event it should be compared to BeforeAppInfoBuilderEvent which is likely better. Main reason to use BeforeStartEjbs is the need of reflection (to do filtering for instance). All other cases shouldn't use it. AssemblerAfterApplicationCreated is also a good condicate but this one is launched after timers are started."
Druid,No Relation,"[2017-12-06 08:18:08][Alexander Saydakov][commit][45f91a241e16424e4d3355555801773395b255c7]
numeric quantiles sketch aggregator (#5002)

* numeric quantiles sketch aggregator

* it seems that we need to synchronize all methods, which modify the state

* Seems like a false positive with -Pstrict

* code style fix

* code style fix

* use sketches-core-0.10.3

* moved cache ids to the central place

* better class names

* support large columns

* explained autodetection, added exception

* added comments regarding sketches moving on heap

* support reindexing

* implemented suggestions from jihoonson

* style fix

* use max(k, other.k) for better accuracy

* check for NilColumnValueSelector instead of null

* throw exceptions instead of providing no-op comparators
","[2018-01-30 23:40:05][jon-wei][pull:comment][5002:361772545]
@AlexanderSaydakov can you provide docs for this feature? I'd like to provide a link to them in the 0.12.0 release notes"
Incubator Dolphinscheduler,No Relation,"[2020-09-02 15:59:47][Yichao Yang][code-comment][ac4ed94061e91563268c3bc588c554182d22d277]
*
     * Initialization regularization, solve the problem of pre-compilation performance,
     * avoid the thread safety problem of multi-thread operation
","[2020-09-02 15:59:47][Yichao Yang][commit][ac4ed94061e91563268c3bc588c554182d22d277]
[Improvement][common] Add UnsupportedOperationException for utils construct (#3381)

* [Improvement][common] Add UnsupportedOperationException for utils construct

* Fix checkstyle"
Hbase,SATD Repayment,"[2016-08-01 11:08:56][Enis Soztutar][code-comment][aa0235f98c1dd0f730f5e93dfc64e13a12a36f2a]
*
   * Minimum number of entries in a single index block. Even if we are above the
   * hfile.index.block.max.size we will keep writing to the same block unless we have that many
   * entries. We should have at least a few entries so that we don't have too many levels in the
   * multi-level index. This should be at least 2 to make sure there is no infinite recursion.
","[2016-07-26 19:32:09][Enis Soztutar][issue:comment][HBASE-16288:15394400]
I'm glad that I have written a unit test for this. There is one more case it seems, not just the first key in a block, but we have to make sure that every block in an intermediate level index contains at least 2 keys. Otherwise, the recursion never stops still. The UT creates 100 blocks of such where each key is larger than the max chunk size."
Nifi,No Relation,"[2017-04-06 13:51:08][Bryan Bende][code-comment][556f309df086fefdcc6ca717294eaa91d3a4e113]
 get the temp instance of the Processor so that we know the default property values
","[2017-03-31 17:27:24][mcgilman][pull:comment][1635:290776042]
@bbende The code changes look good. However, I think the implication of the using the `RequiresInstanceClassLoading` annotation with the `cloneDuringInstanceClassLoading` flag on an NAR could lead to some confusing deployments. I think the confusion will come from the fact that the flag on the NAR will only be honored when the entire chain from the component that `RequiresInstanceClassLoading` is also flagged. Rather than trying to identify cases that could be problematic like forgetting the flag in a NAR in the chain or setting the flag on a NAR that contains a service API, should we investigate a way to automatically clone when possible?"
Hbase,SATD Repayment,"[2012-10-29 21:33:15][Michael Stack][code-comment][e7d4f965a1f562cf9ed95e5ccc339192a20e480e]
 run the cleaners, checking for each of the directories + files (both should be deleted and
 need to be checked) in 'otherTable' and the files (which should be retained) in the 'table'
","[2012-10-25 18:45:27][Jesse Yates][issue:comment][HBASE-6707:13484364]
With the recent changes to trunk (HBASE-6949) my earlier addendum (v4-addenum.patch) has become correct since the cleaner the always removes directories now. The extra check is a precaution, but (1) should never be used and (2) doesn't affect correctness even if it somehow does get passed."
Beam,SATD Repayment,"[2019-05-31 17:36:33][Lukasz Cwik][code-comment(deleted)][a9fa019e399746f3aa00ce1ee4f4fde2f47e8a8c]
 TODO(BEAM-6199): Remove these old URNs.
","[2019-05-31 17:36:33][Lukasz Cwik][commit][a9fa019e399746f3aa00ce1ee4f4fde2f47e8a8c]
[BEAM-6199] Remove outdated Combine URNs"
Incubator Doris,SATD Repayment,"[2019-09-03 10:42:16][EmmyMiao87][commit][9f5e5717d4aaf184518d8da93b11c2137489fe6d]
Unify the msg of 'Memory exceed limit' (#1737)

The new msg of limit exceed: ""Memory exceed limit. %msg, Backend:%ip, fragment:%id Used:% , Limit:%. xxx"".
This commit unifies the msg of 'Memory exceed limit' such as check_query_state, RETURN_IF_LIMIT_EXCEEDED and LIMIT_EXCEEDED.
","[2019-09-02 12:09:41][EmmyMiao87][pull:summary][1737]
The new msg of limit exceed: ""Memory exceed limit. %msg, Backend:%ip, fragment:%id Used:% , Limit:%. xxx"".
This commit unifies the msg of 'Memory exceed limit' such as check_query_state, RETURN_IF_LIMIT_EXCEEDED and LIMIT_EXCEEDED."
Cassandra,No Relation,"[2010-02-12 21:55:31][Jonathan Ellis][code-comment][1e6ccecd47f92e895834e11de8f92a54b0903ef1]

   ~ The maximum number of columns in millions to store in memory per
   ~ ColumnFamily before flushing to disk.  This is also a per-memtable
   ~ setting.  Use with MemtableThroughputInMB to tune memory usage.
","[2009-08-21 16:07:30][Jonathan Ellis][issue:comment][CASSANDRA-342:12746042]
We already have a proposal from Jun over in #197 to expose the ring as a string property, and (presumably) load it into a storageservice.  Which would more or less take care of things, although the separation could be cleaner."
Drill,SATD Duplication,"[2017-03-14 22:08:12][paul-rogers][pull:summary][784]
Recent work in Drill has identified a number of cases where code can be
cleaned up: adding missing annotations, etc. These changes don't fit as part of a separate ticket and so are rolled up into a this ""general
hygiene"" PR.
","[2017-03-14 21:24:11][Paul Rogers][issue:summary][DRILL-5355:13056099]
Recent work in Drill has identified a number of cases where code can be cleaned up: adding missing annotations, etc. These changes don't fit as part of a separate ticket and so are rolled up into a this ""general hygiene"" ticket."
Pulsar,No Relation,"[2019-04-22 15:57:19][lipenghui][code-comment][2373ca36fa0d84103c0feed357da1fbb52119d05]
TODO: None key policy
","[2019-04-19 03:03:55][sijie][pull:comment][4079:276891616]
nit: I would suggest you adding more descriptions into the javadoc. It might be worthing using an example to explain how does your algorithm work here."
Nifi,No Relation,"[2016-06-01 18:14:24][mosermw][pull:comment][444:65414058]
@markobean I think the longer description is still valid and should remain in place.
","[2016-03-18 15:26:52][Mark Bean][issue:comment][NIFI-1118:15201629]
The proposed change effectively removes a feature, the Remove Trailing Newlines. The property Remove Trailing Newlines is still present, but the user will be forced to set it to false; there is no functionality behind it. The currently existing bug(s) with this features are not fixed. Rather, the poorly functioning feature is simply not available and therefore the bugs are no longer present."
Drill,SATD Duplication,"[2016-12-06 23:22:51][sohami][pull:summary][679]
DRILL-5098: Improving fault tolerance for connection between client a…
","[2016-12-03 02:05:37][Sorabh Hamirwasia][issue:summary][DRILL-5098:13025279]
Improving fault tolerance for connection between client and foreman node."
Beam,SATD Repayment,"[2020-04-09 10:44:35][Kamil Wasilewski][commit][79b2d87b59819ee55fb8600e8a845c6ba5b98d64]
[BEAM-9085] Fix performance regression in SyntheticSource on Python 3 (#11092)
","[2020-03-10 15:58:24][kamilwu][pull:summary][11092]
[BEAM-9085] Fix performance regression in SyntheticSource on Python 3"
Incubator Pinot,SATD Duplication,"[2020-08-06 12:16:21][Xiaotian (Jackie) Jiang][code-comment][ae2bd2f82f0cd8c19532a0c72944acb7f3d19b61]
 Set min/max value if available
 NOTE: Use getProperty() instead of getString() to avoid variable substitution ('${anotherKey}'), which can cause
       problem for special values such as '$${' where the first '$' is identified as escape character.
 TODO: Use getProperty() for other properties as well to avoid the overhead of variable substitution
","[2020-08-06 18:19:51][Jackie-Jiang][pull:summary][5822]
## Description
In the segment metadata and column metadata, we always store the actual value in the property file and never use variable substitution (`${anotherKey}`). Using variable substitution can cause problem for special values such as `$${` where the first `$` is identified as escape character and removed.
Replace `getString()` with `getProperty()` for column min/max value to avoid variable substitution."
Trafficserver,SATD Repayment,"[2013-01-15 13:42:18][Yunkai Zhang][commit][fc7391096d5b9ea68ea9392e7cd1cea5455f0ba1]
TS-977 RecCore: remove unnecessary IOCORE_* wrapper on RecCore API

Call RecCore API directly is mush better and clear than IOCORE_* wrapper.

Signed-off-by: Yunkai Zhang <qiushu.zyk@taobao.com>
Signed-off-by: Zhao Yongming <ming.zym@gmail.com>
","[2013-01-15 03:17:20][James Peach][issue:comment][TS-977:13553453]
Getting rid of these unnecessary macros is a nice improvement."
Carbondata,SATD Duplication,"[2016-09-20 18:48:27][kumarvishal09][pull:summary][182]
Problem: In case of limit query if limit value is 100 so after consuming 100 records executor service is not getting shutdown, and it may cause memory issue 

Solution: Add executor service in query model need to shutdown the executor after query execution in carbonscan rdd
","[2016-09-20 18:47:50][Kumar Vishal][issue:summary][CARBONDATA-262:13006268]
Problem: In case of limit query if limit value is 100 so after consuming 100 records executor service is not getting shutdown, and it may cause memory issue 

Solution: Add executor service in query model need to shutdown the executor after query execution in carbonscan rdd"
Incubator Mxnet,No Relation,"[2018-02-01 09:39:23][Kellen Sunderland][commit][464086520e749cab950e9e6f7e836c815b6f693b]
Enable CPP unit tests in CI (#9609)

* Enable CPP unit tests in CI.

Enable CPP tests built with GPU and OpenMP support.

* Remove unused LD_LIBRARY_PATH changes

* Make memory tests informational only.

* Package required test binaries

* Update workspace name for cpp uts
","[2018-01-29 17:12:12][larroy][pull:comment][9609:164498531]
Should we run the tests in CPU as well?"
Ignite,No Relation,"[2019-10-14 14:29:59][pavlukhin][pull:comment][6490:334510768]
It is enough to clear caches just from one node, loop is not needed here.
","[2019-12-02 13:07:47][Ivan Pavlukhin][issue:comment][IGNITE-7285:16986040]
[~samaitra], could you please fill in release notes field, create a follow-up documentation ticket and resolve this ticket?"
Myfaces Tobago,SATD Repayment,"[2012-07-24 16:59:57][Udo Schnurpfeil][commit][10ba79b743798d343f0f0c762c6d6b790dda2d49]
TOBAGO-1174: Easier handling of Selenium tests
- cleanup
","[2012-07-13 20:28:38][Udo Schnurpfeil][issue:summary][TOBAGO-1174:12598755]
Easier handling of Selenium tests"
Beam,SATD Repayment,"[2018-04-19 00:18:12][Henning Rohde][code-comment(deleted)][41bbc1638e19c6f824b03727fe8816554c333c82]
 TODO: Window, pane?
","[2018-04-19 00:18:12][Henning Rohde][commit][41bbc1638e19c6f824b03727fe8816554c333c82]
Add WindowInto and window representations

 * Add windowed_wordcount example
 * Expose Window as an optional paramter in DoFns
 * TODO: runtime aspect"
Fluo,SATD Repayment,"[2014-08-07 15:05:08][Mike Walch][commit][0cdf7dba6ed142a2f076155a95624125e32efb32]
Merge pull request #109 from keith-turner/fluo-26

fixes #26 made lock recovery more efficient by caching and batching
","[2014-07-31 22:10:31][keith-turner][pull:summary][109]
fixes #26 made lock recovery more efficient by caching and batching"
Carbondata,No Relation,"[2020-06-03 07:58:14][akashrn5][pull:comment][3770:434379315]
can you add test cases for negative scenarios also, which throws exceptions?
","[2020-05-21 04:27:16][Ajantha Bhat][issue:summary][CARBONDATA-3829:13306365]
Please find the solution document attached."
Incubator Pinot,SATD Duplication,"[2017-03-30 14:02:33][Yungyu Chung][code-comment][6045e8c3cdaa86c2b92bc1d96e055b73da41bf9d]
 select the functionAutotuneConfigDTO in DB
TODO: override existing autotune results by a method ""autotuneConfigDAO.udpate()""
","[2017-03-30 19:32:06][cecilynie][pull:comment][1145:109016511]
This can be a TODO: override existing autotune results by a method ""autotuneConfigDAO.udpate()""  Leave it in the future. :)"
Accumulo,No Relation,"[2014-06-14 00:44:07][Josh Elser][code-comment][a2aabbcbbcb17e2ecccb71e58b531d3135b6ada0]
 We only want to clean up WALs (which is everything but rfiles) and only when
 metadata doesn't have a reference to the given WAL
","[2014-03-27 01:46:00][Josh Elser][issue:comment][ACCUMULO-378:13948742]
Design document that I've been working out that outlines some implementation details."
Airflow,SATD Repayment,"[2016-04-05 13:22:56][jlowin][code-comment][9c6dbf116ef86ecdf95f4095e0015abdb33959bc]
 show Airflow's deprecation warnings
","[2016-04-05 13:22:56][jlowin][commit][9c6dbf116ef86ecdf95f4095e0015abdb33959bc]
Show only Airflow's deprecation warnings

Previous filter was too lenient and showed deprecation warnings from
ALL modules."
Hadoop,SATD Repayment,"[2014-09-08 12:51:56][Colin Patrick Mccabe][commit][cad14aa9168112ef1ceae80b94d9aae3ba293578]
HDFS-6036. Forcibly timeout misbehaving DFSClients that try to do no-checksum reads that extend too long.  (cmccabe)
","[2014-02-28 23:05:37][Colin McCabe][issue:summary][HDFS-6036:12698049]
Forcibly timeout misbehaving DFSClients that try to do no-checksum reads that extend too long"
Incubator Pinot,No Relation,"[2018-02-15 10:43:24][Xiaotian Jiang][code-comment][f6057c77dbb94965518a18f8082b16fcea74e8c6]
 TODO: here we call getBytes() multiple times, could be optimized
","[2018-02-15 10:43:24][Xiaotian Jiang][commit][f6057c77dbb94965518a18f8082b16fcea74e8c6]
Enforce padding character to be '\0' (#2495)

The current code will break if the padding character is not '\0'

1. Remove the config for padding character
2. Simplify the logic of creating string dictionary because the order won't change"
Orc,No Relation,"[2019-12-17 04:41:30][chunyang-wen][pull:comment][461:358593778]
It's better to follow the sequence of header style of existing code.
+ system headers
+ third party headers
+ project headers
","[2016-08-18 09:14:12][Chunyang Wen][issue:comment][ORC-40:15426134]
Is there any plan or any thought about this issue?

In java, search argument is built by traversing the abstract syntax tree which I think is generated by sql parser. But in C++, we use available APIs to read orc files, so there is no such thing (AST). Of course, we can use any method to describe filter conditions that users want. E.g., implementing a simple parser that can parse simple search arguments, >, <, + etc. But it seems that it is not elegant."
Helix,SATD Repayment,"[2017-11-06 16:32:36][Lei Xia][code-comment][d54966557f0817ede7e28ea4af09597de4fcface]
*
 * Verifier that verifies whether the ExternalViews of given resources (or all resources in the cluster)
 * match exactly as its ideal mapping (in idealstate).
","[2017-11-06 16:32:36][Lei Xia][commit][d54966557f0817ede7e28ea4af09597de4fcface]
Add StrictMatchExternalViewVerifier that verifies whether the ExternalViews of given resources (or all resources in the cluster) match exactly as its ideal mapping (in idealstate)."
Trafodion,SATD Repayment,"[2017-10-02 00:13:35][Anoop Sharma][code-comment(deleted)][2eaef5d7a9b3beb1b4f45ab97899c2a4b6b7059e]
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
 warning elimination
","[2017-10-02 00:13:35][Anoop Sharma][commit][2eaef5d7a9b3beb1b4f45ab97899c2a4b6b7059e]
PR-1251 [TRAFOFION-2731] CodeCleanup: Phase4: Removed lagacy/obsolete warning elimination pragmas"
Beam,No Relation,"[2016-11-12 09:11:09][amitsela][pull:comment][1332:260111020]
@staslev and I discussed this and this needs more thinking as the proposed solution here might still be affected by races in case of reusing context repeatedly (for example tests).
Let's discuss in JIRA and PR for review once we have a better solution.
","[2016-11-07 15:50:51][Amit Sela][issue:comment][BEAM-891:15644539]
Just to update: the mentioned failure occurred in build #43 and now we've successfully passed build #78.
Only (1) flake that did occur is related to streaming, which could be (truly) resolved only once triggers are implemented.

I suggest we leave this open while [~staslev] keeps investigating but if nothing comes up we should eventually close this."
Samza,SATD Duplication,"[2019-09-12 23:57:32][Sanil15][pull:summary][1152]
SAMZA-2319: [1/2] Simplify Container Allocation logic
","[2019-09-12 23:46:43][Sanil Jain][issue:summary][SAMZA-2319:13256440]
Simplify Container Allocator Logic"
Kafka,SATD Repayment,"[2020-09-24 02:37:17][Ismael Juma][commit][51957de80606609232d5346a0aa86a945173317d]
MINOR: Use JUnit 5 in raft module (#9331)

I also removed a test class with no tests currently (Jason filed KAFKA-10519 for
filling the test gap).

Reviewers: Jason Gustafson <jason@confluent.io>
","[2020-09-24 00:04:42][ijuma][pull:summary][9331]
I also removed a test class with no tests currently.

### Committer Checklist (excluded from commit message)
- [ ] Verify design and implementation 
- [ ] Verify test coverage and CI build status
- [ ] Verify documentation (including upgrade notes)"
Incubator Pinot,SATD Repayment,"[2020-05-29 14:08:03][Sidd][commit][b40dd992874f9bc38b911870e041a8f6e24c3776]
Faster bit unpacking (Part 1) (#5409)

* Faster bit unpacking

* Add unit tests

* new

* Improved degree of vectorization and more tests

* fix build

* cleanup

* docs

* change file name

* address review comments and add more benchmarks

Co-authored-by: Siddharth Teotia <steotia@steotia-mn1.linkedin.biz>
","[2020-05-18 22:59:26][siddharthteotia][pull:summary][5409]
Faster vectorized bit unpacking (Part 1)"
Druid,SATD Repayment,"[2019-05-15 14:49:50][Gian Merlino][commit][0352f450d738bd5b477709eea83ef449591deaad]
Fix broken links in docs, add broken link checker. (#7658)

Also adds back insert-segment-to-db.md with some docs about why and
when it was removed (in #6911).
","[2019-05-14 21:05:58][gianm][pull:summary][7658]
Fix broken links in docs, add broken link checker."
Hadoop,SATD Duplication,"[2020-10-19 16:38:27][steveloughran][pull:summary][2396]
HADOOP-17313. FileSystem.get to support slow-to-instantiate FS clients.
","[2020-10-19 14:31:24][Steve Loughran][issue:summary][HADOOP-17313:13336082]
FileSystem.get to support slow-to-instantiate FS clients"
Helix,No Relation,"[2014-08-28 10:00:43][Kanak Biscuitwala][code-comment][d8ec1ae7560118363e843283ce2f15f611aea099]
*
     * Clean up the connection to the spectated cluster
","[2014-08-25 23:56:12][Kanak Biscuitwala][issue:comment][HELIX-470:14110005]
Let's use the wiki page since that has the most up-to-date information."
Lucene Solr,No Relation,"[2013-10-24 16:42:14][Alan Woodward][code-comment][e7aec6b5327e5c0e67a11f8bbd821a1b69c38b44]
 Delete one document with commitWithin
","[2011-01-22 15:06:22][Robert Muir][issue:comment][LUCENE-2878:12985126]
bq. It's not that bad of a trap  I has warnings all over it - some people use it out there. I think it's more useful than trapful - if not just as demo code.

In this case maybe contrib?
And if we were careful/re-organized tests a bit, MultiSpansWrapper could be pkg-private."
Druid,SATD Repayment,"[2019-05-17 16:14:47][Jonathan Wei][code-comment][674310991d2fc3af2885df045b4d2f53bec2a164]
 Check for broken links
","[2019-05-14 21:05:58][gianm][pull:summary][7658]
Fix broken links in docs, add broken link checker."
Lucene Solr,No Relation,"[2013-10-24 16:42:14][Alan Woodward][code-comment][e7aec6b5327e5c0e67a11f8bbd821a1b69c38b44]
 TODO if a Term affects multiple fields, we could keep the updates key'd by Term
 so that it maps to all fields it affects, sorted by their docUpto, and traverse
 that Term only once, applying the update to all fields that still need to be
 updated.
","[2012-10-28 15:00:25][Michael McCandless][issue:comment][LUCENE-2878:13485637]
I'm still trying to catch up here (net/net this looks awesome!), but
here's some minor stuff I noticed:

Instead of PostingFeatures.isProximityFeature, can we just use
X.compareTo(PostingsFeatures.POSITIONS) >= 0?  (We do this for
IndexOptions).

Should we move PostingFeatures to its own source instead of hiding it
in Weight.java?

Can we put back single imports (not wildcard, eg ""import
org.apache.lucene.index.*"")?

PostingFeatures is very similar to FieldInfo.IndexOptions (except the
latter does not cover payloads) ... would be nice if we could somehow
combine them ..."
Beam,No Relation,"[2017-10-17 22:22:33][jkff][pull:comment][3729:145272906]
Document this and document the next constant too? (i.e. document how they are used and why the chosen values are reasonable)
","[2017-03-03 22:20:22][Guy Molinari][issue:comment][BEAM-1542:15895141]
I have created a fork called NextDevBoard and have checked in a very primitive version of this.  The checkstyle plugin is failing the build so I'm running -Dcheckstyle.skip=true until I can fix this.   There is much to do including lots and lots of cleanup.   Split bundles must be implemented for the Source but I wanted to get the Sink working first.   There are custom coders for the spanner Mutation and Struct classes."
Hudi,No Relation,"[2020-12-09 15:52:23][wenningd][commit][fce1453fa608fcff5df4d5aca8c88107d4151b09]
[HUDI-1040] Make Hudi support Spark 3 (#2208)

* Fix flaky MOR unit test

* Update Spark APIs to make it be compatible with both spark2 & spark3

* Refactor bulk insert v2 part to make Hudi be able to compile with Spark3

* Add spark3 profile to handle fasterxml & spark version

* Create hudi-spark-common module & refactor hudi-spark related modules

Co-authored-by: Wenning Ding <wenningd@amazon.com>
","[2020-10-30 21:45:31][zhedoubushishi][pull:comment][2208:515396682]
Because ```hudi-spark``` depends on ```hudi-spark2```. I cannot also let ```hudi-spark2``` depends on ```hudi-spark``` tho copying files is not a clean way."
Geode,SATD Repayment,"[2019-07-22 15:31:43][Juan José Ramos][commit][b86837818dcd6901a2249d295bca54c617057aa0]
GEODE-6875: Remove unused & deprecated API usage (#3813)

- Fixed warnings.
- Replaced deprecated API in Http Session.
- Replaced usage of internal API in Http Session.
- Removed unused classes and methods in Http Session.
","[2019-07-18 19:17:33][jujoramos][pull:summary][3813]
GEODE-6875: Remove unused & deprecated API usage"
Systemds,SATD Repayment,"[2015-11-27 20:57:12][Matthias Boehm][code-comment][649dfbfdff2a58b6028360a9118ab19c50491e84]
avoid unnecessary caching of input in order to reduce memory pressure
","[2015-11-27 20:57:12][Matthias Boehm][commit][649dfbfdff2a58b6028360a9118ab19c50491e84]
Improved rdd checkpoint injection (avoid unnecessary input caching)"
Zookeeper,No Relation,"[2016-11-06 06:54:27][hanm][pull:comment][96:86680275]
Agreed, both places are updated to use asserts and removed logging.
","[2016-10-11 12:45:55][Flavio Paiva Junqueira][issue:comment][ZOOKEEPER-2014:15565322]
Thanks for fixing it. I see the point of stability, but I don't think it is much of a concern in this case. You're just building on top of the ZooKeeper, you won't be re-wiring the existing ZooKeeper client code, I think. If I'm right, then it is better to have a single connection to the service rather than two, one for the ZooKeeper object and another for ZooKeeperAdmin. In any case, it might be worth giving it a shot to get a sense of whether it'd cause trouble."
Trafficserver,SATD Repayment,"[2020-11-30 10:45:48][Brian Neradt][commit][8eb68266167d8f8b3fa3a00ca9f6b7889e8ec101]
Add negative caching tests and fixes. (#7361)

This adds test coverage for the negative caching feature and makes some
fixes as a result of the test's findings.
","[2020-11-30 17:32:47][bneradt][pull:summary][7361]
Add negative caching tests and fixes."
Kafka,No Relation,"[2017-08-03 00:57:07][ijuma][pull:comment][3612:131032652]
We can remove the comment above now, right?
","[2017-02-09 17:38:05][Ismael Juma][issue:comment][KAFKA-2507:15859871]
[~mimaison], the benefit of this is relatively small with a high operational cost for people upgrading from 0.8.x. I think I'd remove this at the same time as we remove the old clients (we can then remove all of the Scala request, response and messages code). And given that we got pushback for the deprecation of the old consumer, I think it's unlikely that the old consumer will be removed in 0.11 (more likely the major version after that)."
Cxf,No Relation,"[2015-04-24 12:21:41][Sergey Beryozkin][code-comment][90873c41ab1e632f71a355ef63e67a4b29252ef4]
 TODO Auto-generated method stub
","[2015-04-24 12:21:41][Sergey Beryozkin][commit][90873c41ab1e632f71a355ef63e67a4b29252ef4]
[CXF-6369] Preventing duplicate registrations in ConfigurationImpl"
Systemds,SATD Repayment,"[2013-12-04 11:24:34][MATTHIAS BOEHM][code-comment][e6965ead22f89ef07d44d9289877909ba01cf47b]
 compile body to CP if exec type forced to MR
export only read variables according to live variable analysis
cleanup pinned variables according to live variable analysis
","[2013-12-04 11:24:34][MATTHIAS BOEHM][commit][e6965ead22f89ef07d44d9289877909ba01cf47b]
20974: ParFor construct - Enhanced export and cleanup unpinned variables (live variable awareness)"
Tvm,No Relation,"[2020-03-07 13:30:13][Zhi][code-comment][28ee806dcbd803f4079365dd308a673bd1a89588]
 Inline the functions that have been lifted by the module scope.

 TODO(@zhiics) Note that we need to be careful about the subgraphs with
 global function calls. We should make sure that these callees are also
 inline functions. However, this should be very unlikely for accelerators
 and vendor-provided libraries. So we don't handle for now.
","[2020-03-06 23:39:19][zhiics][pull:comment][4996:389194638]
Let's keep the previous one as it tests the lifting. We can create a separate one to test batch_norm with inline. There are a few other tests for outlining and inlining tests in this file as well. I think this should be enough."
Ozone,SATD Duplication,"[2019-12-11 15:56:35][sodonnel][pull:summary][343]
HDDS-2607 DeadNodeHandler should not remove replica for a dead maintenance node
","[2019-11-21 13:11:55][Stephen O'Donnell][issue:summary][HDDS-2607:13269840]
DeadNodeHandler should not remove replica for a dead maintenance node"
Tinkerpop,SATD Repayment,"[2015-05-14 11:52:47][Marko A. Rodriguez][code-comment(deleted)][05f5114fdceadd5b81efd4e1d6600fd3d1f966eb]
 TODO: Step.teleport(traverser, step)
","[2015-05-14 11:52:47][Marko A. Rodriguez][commit][05f5114fdceadd5b81efd4e1d6600fd3d1f966eb]
lots of TODOs removed and or solved."
Lucene Solr,SATD Repayment,"[2016-04-04 12:51:03][Robert Muir][commit][c1a3e1b8d04ffc94e502b086e0544c0e0494d5a8]
LUCENE-7159: Speed up LatLonPoint point-in-polygon performance
","[2016-04-01 02:56:38][Robert Muir][issue:summary][LUCENE-7159:12955174]
improve spatial point/rect vs. polygon performance"
Hive,SATD Repayment,"[2017-05-16 08:13:28][Peter Vary][commit][1b8ba022c26ef929f35dc12c5c70e1683fa2e373]
HIVE-15726: Reenable indentation checks to checkstyle (Peter Vary via Zoltan Haindrich)

Signed-off-by: Zoltan Haindrich <kirk@rxd.hu>
","[2017-01-25 15:56:14][Peter Vary][issue:summary][HIVE-15726:13037736]
Reenable indentation checks to checkstyle"
Hive,SATD Repayment,"[2015-03-23 06:46:44][Rui Li][commit][f2d73e9341c75abee41a1366d2bd4f786d4a1cda]
HIVE-10006: RSC has memory leak while execute multi queries.[Spark Branch] (Chengxiang via Rui, reviewed by Xuefu)

git-svn-id: https://svn.apache.org/repos/asf/hive/branches/spark@1668521 13f79535-47bb-0310-9956-ffa450edef68
","[2015-03-18 09:41:51][Chengxiang Li][issue:summary][HIVE-10006:12782804]
RSC has memory leak while execute multi queries.[Spark Branch]"
Flink,No Relation,"[2019-02-11 12:01:22][StefanRRichter][pull:comment][7662:255477727]
Hm, this class is separated into sections by the comments that where in the original code. Are you suggesting to remove this separation altogether or maybe just move public methods to the top in their section?
","[2018-09-26 10:03:41][Stefan Richter][issue:summary][FLINK-10431:13187558]
The other half of the current scheduling logic is the management of slot sharing and is located in the SlotPool. We need to extract this logic into our new Scheduler component from the previous step. This leaves us with a simpler SlotPool that mainly cares about obtaining, holding, and releasing slots in interaction with a ResourceManager. The new Scheduler can now identify slot sharing groups and interacts with the SlotPool."
Beam,No Relation,"[2016-09-12 17:40:03][Thomas Groh][code-comment][d056f4661da2cc399cab44c6604eaa61d1dfd178]
*
   * Annotation for the method to use to clean up this instance after processing bundles of
   * elements. No other method will be called after a call to the annotated method is made.
   * The method annotated with this must satisfy the following constraint:
   * <ul>
   *   <li>It must have zero arguments.
   * </ul>
","[2016-09-12 17:40:03][Thomas Groh][commit][d056f4661da2cc399cab44c6604eaa61d1dfd178]
Add DoFn @Setup and @Teardown

Methods annotated with these annotations are used to perform expensive
setup work and clean up a DoFn after another method throws an exception
or the DoFn is discarded."
Superset,No Relation,"[2016-10-11 17:54:40][Bogdan][code-comment][73cd2ea3b17574f8fef1112aa5e5b39f843882f6]
 TODO: support druid datasources.
","[2016-10-07 03:38:05][bkyryliuk][pull:comment][1197:252145871]
@mistercrunch - please take another look. PR is getting bigger :(
There is quite some code duplication, but I can't find an easy way to tackle that in this PR."
Kafka,No Relation,"[2020-01-09 18:20:34][hachikuji][pull:comment][7312:364890245]
I'm ok removing this API in spite of the compatibility concern. It's just that the other constructors are ""standard"" exception constructors and we have no real need to remove them.
","[2019-06-07 13:05:47][Andrew Olson][issue:comment][KAFKA-8421:16858616]
It would be helpful to design and build a stress test harness for exhaustive verification of this, since it seems like quite complex and critical functionality. We could embark on that effort now, and use it to more fully illustrate the weaknesses of the current behavior along with making sure we have adequate logging in place for insight into what's going on deep in the consumer internals."
Hive,SATD Repayment,"[2015-03-23 06:46:44][Rui Li][commit][f2d73e9341c75abee41a1366d2bd4f786d4a1cda]
HIVE-10006: RSC has memory leak while execute multi queries.[Spark Branch] (Chengxiang via Rui, reviewed by Xuefu)

git-svn-id: https://svn.apache.org/repos/asf/hive/branches/spark@1668521 13f79535-47bb-0310-9956-ffa450edef68
","[2015-03-18 09:41:51][Chengxiang Li][issue:summary][HIVE-10006:12782804]
RSC has memory leak while execute multi queries.[Spark Branch]"
Incubator Doris,SATD Repayment,"[2019-05-24 22:02:09][Mingyu Chen][commit][08c8caeacf7efa02d2a365c872c25311c2bbfc43]
Add max cache size to ClientCache in BE (#1202)

Currently, unlimited client cache pool may cause too many connections in FE
","[2019-05-24 09:27:42][morningman][issue:summary][1201]
Too many thrift connection from BE to FE"
Flink,SATD Repayment,"[2017-02-18 19:19:34][Alexey Diomin][commit][53134594644407d0a3cd691b0e93ae09ff6c8102]
[FLINK-5497] [tests] Remove duplicated tests for hash tables

This closes #3089
","[2017-01-15 20:11:39][Alexey Diomin][issue:summary][FLINK-5497:13035051]
remove duplicated tests"
Shardingsphere,SATD Repayment,"[2018-08-02 17:17:50][saaav][code-comment(deleted)][6392ba96aad8ec6eff5a3202acbda0d4bdcfc0af]
 todo Split up into two classes, one use exec() and other use getResult()
","[2018-08-02 17:17:50][saaav][commit][6392ba96aad8ec6eff5a3202acbda0d4bdcfc0af]
todo Split up into two classes, one use exec() and other use getResult()"
Spark,SATD Repayment,"[2015-04-01 18:36:06][Reynold Xin][commit][899ebcb1448126f40be784ce42e69218e9a1ead7]
[SPARK-6578] Small rewrite to make the logic more clear in MessageWithHeader.transferTo.

Author: Reynold Xin <rxin@databricks.com>

Closes #5319 from rxin/SPARK-6578 and squashes the following commits:

7c62a64 [Reynold Xin] Small rewrite to make the logic more clear in transferTo.
","[2015-04-01 23:20:56][rxin][pull:summary][5319]
[SPARK-6578] Small rewrite to make the logic more clear in MessageWithHeader.transferTo."
Fluo,SATD Repayment,"[2014-08-07 15:05:08][Mike Walch][commit][0cdf7dba6ed142a2f076155a95624125e32efb32]
Merge pull request #109 from keith-turner/fluo-26

fixes #26 made lock recovery more efficient by caching and batching
","[2014-07-31 22:10:31][keith-turner][pull:summary][109]
fixes #26 made lock recovery more efficient by caching and batching"
Qpid Dispatch,SATD Repayment,"[2020-12-10 13:25:11][Kenneth Giusti][code-comment][2f6498f95fd313dbc653acdd1e43adb28a358f7a]
 cleanup outstanding requests
","[2020-12-10 13:25:11][Kenneth Giusti][commit][2f6498f95fd313dbc653acdd1e43adb28a358f7a]
DISPATCH-1744: fix cleanup of outstanding requests"
Kafka,SATD Duplication,"[2021-02-17 21:52:48][Ron Dagostino][code-comment][d77759d0fe64094a26a6aeaecebc045be317af6f]
 TODO: The `BatchReader` might need to read from disk if this is
 not a leader. We want to move this IO to the state machine so that
 it does not block Raft replication
","[2021-02-17 23:49:31][cmccabe][pull:comment][10113:780929991]
I think this is mostly ready to go.  I left a few small comments.  Let's resolve the 32-bit / 64-bit raft leader epoch thing elsewhere so we can get this in for 2.8..."
Bookkeeper,SATD Duplication,"[2018-12-08 09:26:49][sijie][pull:summary][1868]
BP-37: Improve configuration management for better documentation
","[2018-12-08 01:48:26][sijie][issue:summary][1867]
BP-37: Improve configuration management for better documentation"
Incubator Pinot,SATD Repayment,"[2018-09-27 18:39:45][Xiaotian Jiang][commit][e5ec0f9cdf60b341fd2373da12420c89367e19a2]
Simplify the parameter for forward index creators (#3208)

Also move method getNumBitsPerValue() into PinotDataBitSet and re-implement it without using double
","[2018-09-21 00:50:00][Jackie-Jiang][pull:summary][3208]
Simplify the parameter for forward index creators"
Hbase,No Relation,"[2019-12-16 02:07:22][Apache9][pull:comment][941:358029239]
Could do this in the future. But the logic will be a bit complicated then.
","[2019-12-16 02:58:03][Allan Yang][issue:comment][HBASE-23326:16996935]
It's a nice approach to put all the procedures in a region.  Is it this region co-located with Master? If so, it is great! Indeed a design doc is needed to understand it."
Incubator Pinot,SATD Repayment,"[2020-05-29 14:08:03][Sidd][commit][b40dd992874f9bc38b911870e041a8f6e24c3776]
Faster bit unpacking (Part 1) (#5409)

* Faster bit unpacking

* Add unit tests

* new

* Improved degree of vectorization and more tests

* fix build

* cleanup

* docs

* change file name

* address review comments and add more benchmarks

Co-authored-by: Siddharth Teotia <steotia@steotia-mn1.linkedin.biz>
","[2020-05-18 22:59:26][siddharthteotia][pull:summary][5409]
Faster vectorized bit unpacking (Part 1)"
Trafficcontrol,No Relation,"[2020-02-17 10:09:41][mattjackson220][code-comment][18fe13ac638557b5532813bce8ab3ad2d964fe49]
 The following two types are not official BCP47, but we support them to
 give access to this otherwise hidden functionality. The name blanked is
 derived from the LDML name blanked and posix reflects the main use of
 the shift-trimmed option.
","[2019-10-16 20:42:25][mattjackson220][pull:comment][3534:335698703]
yes. ill update the docs for those too."
Incubator Doris,SATD Repayment,"[2019-09-19 17:37:02][ZHAO Chun][commit][17e52a4bacec63179525143a8e862e8bf68c9d7b]
Improve LRUCache to get better performance (#1826)

In this CL, I move the entry's deleter out of LRUCache's mutex block,
which can let others access this cache without waiting free cache entry.
","[2019-09-18 12:25:15][imay][pull:summary][1826]
Improve LRUCache to get better performance"
Samza,SATD Repayment,"[2017-08-17 11:16:10][Fred Ji][commit][e21ff714637238e9fe1011a9f4f20699f1e9e471]
SAMZA-1400: disabling flaky test testTwoStreamProcessors in TestZkStreamProcessorSession

In this SAMZA-1400, We are disabling this flaky one in master and will cherry pick for 0.13.1. We have created a ticket SAMZA-1399 for fixing it in later build.

navina sborya Please take a look.

Author: Fred Ji <haifeng.ji@gmail.com>

Reviewers: Xinyu Liu <xinyu@apache.org>

Closes #278 from fredji97/SAMZA1400
","[2017-08-17 17:44:59][fredji97][pull:summary][278]
SAMZA-1400: disabling flaky test testTwoStreamProcessors in TestZkStreamProcessorSession"
Beam,SATD Repayment,"[2019-04-21 06:56:40][Thomas Weise][code-comment][ab8276823959b992332fb9212a40a62a998d2d42]
 fire cleanup timers, they can only execute after the bundle is complete
 as they remove the state that the timer callback may rely on
","[2019-04-20 22:17:03][tweise][pull:comment][8351:485184090]
The state keys need to be encoded as NESTED currently. My attempt to use the ByteString directly caused the checkpoint failure. I reverted that and instead also encode the state key of cleanup timer NESTED. We should look into eliminating the redundant key encoding."
Phoenix,SATD Repayment,"[2019-04-19 20:42:45][Kadir][code-comment][e907249a80748f11c8558f8ce5c8d7b832791c17]
 Run the orphan view tool to clean up orphan views
","[2018-11-16 01:03:03][Kadir OZDEMIR][issue:summary][PHOENIX-5025:13198797]
Tool to clean up orphan views"
Cassandra,No Relation,"[2011-12-06 02:11:50][Jonathan Ellis][code-comment][fe1e7fce60fbe2652a44e535e9bbd9bf04a0ef39]
 Up to a second of unneeded delay is acceptable, relative to the amount of time a typical stream
 takes.
","[2011-12-01 20:39:08][Peter Schuller][issue:comment][CASSANDRA-3494:13161134]
I can submit a patch to make this a tunable, defaulting to something semi-reasonable like 10. Do we however believe there are concurrency issues here? A very very brief sifting of the code looked to me like we're alright."
Incubator Pinot,SATD Repayment,"[2020-05-07 12:06:08][Neha Pawar][commit][bfd263a14d83a1764afbdd587f2a33a0576a31ef]
Remove some unused TimeFieldSpec related methods from Schema (#5347)

Another step towards Issue #2756. As I was making changes to Schema to treat TIME as DATE_TIME, found a subset of changes that can go prior to the bigger change.
Removing 3 methods from the Schema which are related to TimeFieldSpec
1. getIncomingTimeUnit - was unused
2. getOutgoingTimeUnit - was unused
3. getTimeColumnName - was able to remove the 4 usages
","[2020-05-07 00:58:55][npawar][pull:summary][5347]
Remove some unused TimeFieldSpec related methods from Schema"
Helix,SATD Duplication,"[2020-04-23 12:27:36][zhangmeng916][code-comment][fc3dfdc9f7fd0ec2fbdd41846f847e948e651cdd]
 TODO: remove the synchronization here once we move this update into dataCache.
","[2020-03-25 19:30:07][zhangmeng916][pull:comment][851:398115507]
I saw a todo here:
 // TODO: remove the synchronization here once we move this update into dataCache.
    synchronized (_lastSeenInstances) {
I'm not sure whether there's any pending task for this that could also apply here, so I kept it."
Lucene Solr,No Relation,"[2014-07-30 22:16:16][Robert Muir][commit][0368c604cc6bfcabf9c7f1c2afd0dd2e0fbb4a96]
LUCENE-5859: remove dead code: changes no runtime behavior, these are all unused variables

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1614778 13f79535-47bb-0310-9956-ffa450edef68
","[2014-07-30 19:03:56][Robert Muir][issue:comment][LUCENE-5859:14079779]
{quote}
...I am -1 on this newer proposal...

    ... I'm now going down the path of removing Version completely. ...

...since it would effectively eliminate the ability for anyone to confidently upgrade Lucene minor versions, w/o re-indexing all data.
{quote}

This is already the case though. So I suppose you are volunteering to fix StandardAnalyzer on trunk to be backwards compatible with 4.0-4.6? 

We should at least be consistent. Its hilarious it has the Version parameter right now, doing nothing, providing no back compat, and yet there are -1's to clean this stuff up :)

The back compat here is clearly too complex."
Trafficcontrol,No Relation,"[2020-02-17 10:09:41][mattjackson220][code-comment][18fe13ac638557b5532813bce8ab3ad2d964fe49]
 The Waiter should only check the resource state MaxAttempts times
 This is here instead of in the for loop above to prevent delaying
 unnecessary when the waiter will not retry.
","[2020-01-29 18:32:30][ocket8888][pull:comment][3534:372556953]
Can you make this a link to the new cdn.conf section of the TO admin docs?"
Druid,SATD Repayment,"[2013-09-13 13:21:03][cheddar][commit][ef1ac46a7ebe69d916fe840cdc73b3087009f5b9]
Merge pull request #237 from metamx/is-ut

Rework tests in indexing service to be more unit testy
","[2013-09-12 23:39:39][fjy][pull:summary][237]
Rework tests in indexing service to be more unit testy"
Nifi,No Relation,"[2018-01-04 16:51:31][markap14][pull:comment][2371:159700877]
Do we have a specific license for this text? Is it included in the nar's LICENSE/NOTICE file? I'm just totally guessing that this wasn't test data that you made up just to test this? :)
","[2018-01-02 16:50:23][Andy LoPresto][issue:summary][NIFI-4727:13128020]
A frequent community request is to count (lines/words/characters) in arbitrary text. A {{CountTextProcessor}} would provide this functionality natively and with solid performance, rather than abusing the {{SplitText}} or {{ExecuteScript}} processors. 

It should provide the following functionality (simultaneously, given options):

* Line count
* Non-empty line count
* Word count
* Character count

The flowfile content should remain unchanged, and each of the above (if indicated) should be added as an attribute."
Beam,No Relation,"[2016-08-17 15:43:47][bchambers][code-comment][89367cfb19ae86d66441970277177512961d3b6a]
*
     * Generates code to invoke the target method. When this is called the delegate field will be on
     * top of the stack. This should add any necessary arguments to the stack and then perform the
     * method invocation.
","[2016-08-16 03:52:04][bjchambers][pull:comment][812:239994578]
A bunch of nits. I scanned the tests and things seem in order. Are there any of the old tests that you know you removed (it didn't look like it).

Assuming not, once the nits are addressed this LGTM.

I'd like to see these moved into a package related to the reflection -- it would allow us to use package visibility to connect the pieces while using public to control what is visible to the runner/SDK. That can happen in this PR (which introduces the multiple reflection related classes) or a followup."
Geode,SATD Repayment,"[2019-07-22 15:31:43][Juan José Ramos][commit][b86837818dcd6901a2249d295bca54c617057aa0]
GEODE-6875: Remove unused & deprecated API usage (#3813)

- Fixed warnings.
- Replaced deprecated API in Http Session.
- Replaced usage of internal API in Http Session.
- Removed unused classes and methods in Http Session.
","[2019-07-18 19:17:33][jujoramos][pull:summary][3813]
GEODE-6875: Remove unused & deprecated API usage"
Druid,No Relation,"[2016-06-14 19:48:49][gianm][pull:comment][2998:67043285]
I didn't do it that way because I thought many queries wouldn't need to spill at all. So I thought it would be better to keep the data in memory un-sorted at first, then sort the data immediately before writing to disk if necessary, rather than incur the overhead of keeping the map always-sorted on disk for every query.

And yeah, even if we do keep the map always-sorted on disk, as you pointed out the dictionary does need to be written and cleared too (to avoid unbounded heap usage for the dictionary). That would take some time. I think we do want to keep the dictionary in-heap for performance reasons (avoid too much serde of java.lang.String).
","[2016-05-19 17:36:35][gianm][issue:comment][2987:220397452]
I was thinking they would be fixed size just like the processing buffers (probably the same size to keep things simple). If a merge buffer isn't big enough to do the merging work, the query could either fail or it could write to temp files on disk (query's choice). If however much disk space we allow the queries to use is ALSO not enough then the query fails."
Accumulo,SATD Repayment,"[2015-02-13 20:19:10][Christopher Tubbs][commit][b889bb0923073346c6fbf85da3d43add6af3edbd]
ACCUMULO-3586 Clean up build warnings
","[2015-02-14 01:52:33][Christopher Tubbs][issue:comment][ACCUMULO-3586:14321132]
Applied patch to clean up lots of build warnings and generally stabilize the build output from maven plugin activity during the build."
Thrift,SATD Duplication,"[2016-02-13 11:04:14][kazuki-ma][pull:summary][858]
THRIFT-3627 fix missing basic code style consistency of JavaScript.
","[2016-02-13 10:35:55][Kazuki Matsuda][issue:summary][THRIFT-3627:12939019]
Missing basic code style consistency of JavaScript."
Beam,No Relation,"[2017-10-20 23:44:26][robertwb][pull:comment][4020:146087303]
No reason to have 2, changed to 1. 

Basically, this should periodically check for exceptions, and periodically release the lock in case the data for another thread came in.

However, this code isn't at all the easiest to follow. Changed to do the demultiplexing in the reader loop and use events to block. (In addition to being simpler, this should better extend itself to being able to return future-like objects for side inputs and state in the future.)
","[2018-05-08 16:59:52][Luke Cwik][issue:comment][BEAM-2927:16467691]
pull/5302 has current progress.

The remaining issue is to clean up some legacy usages of side inputs via a non portable way to get tests to pass. Also to put in the side input optimization."
Hadoop,No Relation,"[2019-03-12 18:54:59][Ajay Yadav][code-comment][15b6e38ddf2e88ce7813f5346ba6712ad501af80]
 According to AWS sigv4 documentation, authorization header should be
 in following format.
 Authorization: algorithm Credential=access key ID/credential scope,
 SignedHeaders=SignedHeaders, Signature=signature
","[2019-03-06 05:00:54][hadoop-yetus][pull:comment][561:262792326]
whitespace:tabs in line"
Arrow,SATD Duplication,"[2019-02-01 22:29:00][kou][pull:summary][3543]
ARROW-4455: [Plasma] Suppress class-memaccess warnings
","[2019-02-01 22:28:42][Kouhei Sutou][issue:summary][ARROW-4455:13213416]
[Plasma] g++ 8 reports class-memaccess warnings"
Arrow,No Relation,"[2021-01-06 14:32:07][Benjamin Kietzman][code-comment][57376d28cf433bed95f19fa44c1e90a780ba54e8]
 literal(3) may be safely cast to float32, so binding this expr casts that literal:
","[2020-12-17 18:13:20][pitrou][pull:comment][8894:545299428]
Of course, this may be deferred to a later JIRA. But should add a TODO and open the JIRA at least."
Trafficserver,SATD Repayment,"[2013-04-19 17:17:53][Leif Hedstrom][code-comment(deleted)][c88d6153e0850a5c5f633ae8afd7947773b65d99]
 UNUSED FILE *f
","[2013-04-19 17:17:53][Leif Hedstrom][commit][c88d6153e0850a5c5f633ae8afd7947773b65d99]
TS-1820 Cleanup the comments some, and eliminate a few unused parameters where it was obvious"
Myfaces Tobago,SATD Repayment,"[2012-07-24 16:59:57][Udo Schnurpfeil][commit][10ba79b743798d343f0f0c762c6d6b790dda2d49]
TOBAGO-1174: Easier handling of Selenium tests
- cleanup
","[2012-07-13 20:28:38][Udo Schnurpfeil][issue:summary][TOBAGO-1174:12598755]
Easier handling of Selenium tests"
Geode,SATD Repayment,"[2016-05-23 07:55:04][Jinmei Liao][code-comment(deleted)][bbc402723b28bac92c31bda070118ec778dbcba5]
for DATA resource, when we construct the lock to guard the operations, there should always be a 3rd part (regionName),
 if no regionName is specified, we need to add ""NULL"" to it.
 this means, for general data operations, or operations that we can't put a regionName on yet, like backup diskstore, query data, create regions
 it will require DATA:READ/WRITE:NULL role
","[2016-05-23 07:55:04][Jinmei Liao][commit][bbc402723b28bac92c31bda070118ec778dbcba5]
GEODE-17: change default regionName to * instead of null.

* operations with no regionName specified in its permission string will need a higher level of role than the operations with regionName specified. This makes more sense than null."
Airflow,No Relation,"[2018-03-23 09:18:48][Joy Gao][code-comment][05e1861e24de42f9a2c649cd93041c5c744504e1]
TODO: by definition, the discrete bar should not have multiple groups, will modify/remove later
","[2018-02-28 17:47:55][ashb][pull:comment][3015:369322703]
I get similar logs using Postgres. Those ""registering class"" at info (even assuming we fix the errors) are too chatty - we might need to tweak the log levels for FAB to so that we don't create 100s of log lines form the webserver every time we reload the workers.

OR: Do we still need the automatic worker cycling that we do? Do either of you know it that added to work around a specific bug/problem that might not be needed any more?"
Ignite,SATD Repayment,"[2016-06-17 19:29:33][Pavel Tupitsyn][commit][ead2b1f5aa0637e82b55a8071dd9af911f25f2a3]
IGNITE-3097 .NET: Improve reflective serialization performance

This closes #698
","[2016-05-10 14:50:22][ptupitsyn][pull:summary][698]
IGNITE-3097 .NET: Improve reflective serialization performance"
Geode Native,No Relation,"[2019-01-04 16:37:27][Jacob Barrett][commit][a816ac99cbbac557629686cb2542fdc74d464338]
GEODE-6241: Makes .NET integration tests more consistent with C++ (#428)

- Changes Gfsh wrapper:
 - to be more stateless.
 - use more explicit 1:1 mappings to actaual GFSH tool.
- Changes Cluster to keep more state previously held by Gfsh.
- Add support for XUnit's test output facility.
- Corrects async writes to test output after test ends.
","[2019-01-04 02:54:51][moleske][pull:comment][428:245190268]
Just want to say I like this section, much easier to read"
Hudi,No Relation,"[2020-04-04 00:07:34][vinoth chandar][code-comment][eaf6cc2d90bf27c0d9414a4ea18dbd1b61f58e50]
*
   * Executes the Cleaner plan stored in the instant metadata.
","[2020-04-04 00:07:34][vinoth chandar][commit][eaf6cc2d90bf27c0d9414a4ea18dbd1b61f58e50]
[HUDI-756] Organize Cleaning Action execution into a single package in hudi-client (#1485)

- Introduced a thin abstraction ActionExecutor, that all actions will implement
- Pulled cleaning code from table, writeclient into a single package
- CleanHelper is now CleanPlanner, HoodieCleanClient is no longer around
- Minor refactor of HoodieTable factory method
- HoodieTable.create() methods with and without metaclient passed in
- HoodieTable constructor now does not do a redundant instantiation
- Fixed existing unit tests to work at the HoodieWriteClient level"
Nifi Minifi Cpp,No Relation,"[2017-02-22 15:47:02][Andrew Christianson][code-comment][a9485aeb05defe3e54b179c3b5dcc1735486abcd]
 A malloc() may have failed within the call to sqlite3_value_text16()
    ** above. If this is the case, then the db->mallocFailed flag needs to
    ** be cleared before returning. Do this directly, instead of via
    ** sqlite3ApiExit(), to avoid setting the database handle error message.
","[2017-02-16 12:33:23][achristianson][pull:comment][43:101507876]
@phrocker Mainly, creating a shared ProcessContext and SessionFactory which will be used in this thread as well as the threads created in the loop below. I wanted these objects to be cleaned up once they go out of scope in all threads. The raw pointers are only used to integrate with the existing Processor pointer that is passed-in, as well as passing raw pointers to the constructors of the new shared objects. I wanted to minimize function/constructor changes that might have impacts elsewhere in the code base. If we want to move more to having managed pointers across the code base, then some of this can be cleaned up."
Hadoop,No Relation,"[2018-04-02 19:58:09][Anu Engineer][code-comment][b78c94f44c454f35eeadb34d48fea649ea491de5]
 Although AnyOf isn't defined for one argument, AnyOfResult1 is defined
 to simplify the implementation.
","[2018-01-26 18:53:15][Owen O'Malley][issue:comment][HDFS-7240:16341429]
I think that the major contribution of this work is pulling out the block management layer and the naming should reflect that.

I'd propose that:
 * Ozone should be the object store
 * The block layer should have a different name such as Hadoop Storage Layer (HSL)."
Flink,No Relation,"[2019-07-26 13:26:18][twalthr][pull:comment][9212:307740877]
There is the overhead of discovering a planner and executor. The test could also be based on the `Planner` only with a mocking catalog. We should always reduce the dependencies of tests to a minimum because otherwise we need to change many tests if we perform changes to the API class. This test must not use the API but can go at least one level deeper.
","[2019-07-19 14:19:03][Danny Chen][issue:summary][FLINK-13338:13246012]
Now the TableConfig has only interface to config the SqlParser config which is very broad and hard to use for user, we should at least supply an interface to config the sql conformance."
Hive,SATD Repayment,"[2016-04-01 14:38:14][Rui Li][commit][03b81bc9c40b6de4f238f6b7660488e711b869c4]
HIVE-12650: Improve error messages for Hive on Spark in case the cluster has no resources available (Rui reviewed by Xuefu)
","[2016-03-25 02:54:45][Rui Li][issue:comment][HIVE-12650:15211335]
I think the difficult part is that we really don't know the possible reasons. Anyway all we get is a timeout, it could be due to network issue, exceptions, or the RSC is just busy.

Another possible refinement is that we can make the behavior more consistent. Like I said, there're now 2 paths that can lead to timeout/failure and user will see different error messages. How about remove the timeout at {{RemoteHiveSparkClient#createRemoteClient#getExecutorCount}}? I mean after certain amount of time, we can give up the pre-warm and eventually fail the job at job monitor."
Netbeans,No Relation,"[2020-09-12 18:50:19][Matthias Bläsing][code-comment][ed95b776fbb029693f171a79692ba8a0b80b3f8e]
 /home/matthias/src/netbeans/ide/css.lib/src/org/netbeans/modules/css/lib/Css3.g:1110:56: ( ws )?
","[2020-09-12 18:50:19][Matthias Bläsing][commit][ed95b776fbb029693f171a79692ba8a0b80b3f8e]
Merge pull request #2299 from matthiasblaesing/css-improvements

Improve the handling of CSS files"
Tinkerpop,No Relation,"[2014-06-23 17:28:10][Marko A. Rodriguez][code-comment][729256fd026bfaf0773a8aec02f3825f3cf3e332]
TODO: Dangerous that the underlying TinkerGraph Vertex can have edges written to it.
","[2014-06-23 17:28:10][Marko A. Rodriguez][commit][729256fd026bfaf0773a8aec02f3825f3cf3e332]
reworked the directory structure of GiraphGremlin output. much cleaner and doesnt require Hadoop FileFilters (thank god).Other random tweaky tweakies."
Druid,SATD Repayment,"[2017-10-10 21:52:42][Jihoon Son][code-comment][56fb11ce0bf60836010e91c15456c4d844282d84]
*
   * This class can be used by multiple threads, so this function should be thread-safe to avoid extra
   * script compilation.
","[2017-10-02 16:48:46][gianm][pull:comment][4871:142193379]
Is this going to be thread-safe (albeit with some possible extra work if multiple threads don't see the `compiledScript` variable update)? AggregatorFactorys definitely do need to be thread-safe as they are used from multiple threads during query processing."
Camel,No Relation,"[2020-02-11 13:23:32][zregvart][pull:comment][3564:377630130]
Perhaps we could add a comment here.
```suggestion
// We moved the examples to the `camel-examples` repository,
// this made sure that the examples were copied to the
// correct place for the documentation, according to the
// Antora directory structure. For now the examples are
// copied over from `camel-examples` manually.
//exports.examples = examples;
```
","[2019-08-07 07:29:02][Claus Ibsen][issue:summary][CAMEL-13830:13249265]
I think it may be quicker and easier for new users to try our examples if we put them in a separate repo, so there is less source code. The git repo for Camel is very big, and it takes a longer time to checkout, and users may get lost in the source code.

If we have a camel-examples git repo with just examples we can refer people to this."
Groovy,SATD Repayment,"[2019-02-20 00:12:17][Daniel Sun][code-comment][3f26dc7b60cc50144a5982d6e70a6a7586594c46]
 GROOVY-8995: Improve the performance of creating list
 answer.addAll(Arrays.asList(values));
","[2019-02-16 18:56:12][danielsun1106][pull:summary][880]
GROOVY-8995: Improve the performance of creating list"
Incubator Weex,No Relation,"[2017-12-28 11:27:26][Hanks][code-comment][8c6690d593dc0608c6dddb69f98ffa3e825a13a9]
*
	 * Translates the list format produced by css-loader into something
	 * easier to manipulate.
","[2017-12-22 07:52:13][Hanks10100][pull:summary][955]
Remove source codes of .we examples, then rebuild the examples, replace the generated bundles in ios and android."
Cxf,SATD Repayment,"[2017-12-15 12:47:02][Daniel Kulp][commit][97cde56cd73cb03ffb259f01446080fa7748ab8b]
[CXF-7591] Allow getResponseContext().clear() to clear out everything to reduce memory usage
","[2017-12-15 11:21:07][Luca Boncompagni][issue:summary][CXF-7591:13125184]
memory leak in ClientImpl"
Geode,SATD Duplication,"[2018-09-06 21:54:09][dschneider-pivotal][pull:summary][2431]
GEODE-5574: unit test coverage for RegionMapDestroy
","[2018-08-13 18:15:06][Darrel Schneider][issue:summary][GEODE-5574:13178661]
improve RegionMapDestroy unit test coverage"
Camel,No Relation,"[2008-03-26 05:10:04][Claus Ibsen][commit][eec3534c950c80af56e3fa18445e87ea632985d2]
This is a combined patch for CAMEL-394 and CAMEL-395

plus:
- refactored camel-mina
- writing data using mina session.write will now wait for the operation to complete and check if the operation is a success. This is important to handle as we want the operation to complete before continuing our code.
- improved and polished some unit tests
- polished pom to use readable ident
- mvn exec:java to see the CAMEL-395 in action from java main
- better error reporting for mistyped uri configuration
- fixed a few IDEA hints

git-svn-id: https://svn.apache.org/repos/asf/activemq/camel/trunk@641152 13f79535-47bb-0310-9956-ffa450edef68
","[2008-03-24 15:34:34][Claus Ibsen][issue:comment][CAMEL-394:12946581]
TODO: add wiki documentation for logger=true | logger=false option. Default is false.

This option turns Apache MINA logger on/off. It logs using slf4j at INFO level so it gets quite verbose, so its nice to turn it off."
Beam,SATD Repayment,"[2019-08-23 15:31:57][Robert Bradshaw][commit][f085cb500730cf0c67c467ac55f92b3c59f52b39]
Merge pull request #9352 Fix and rename assertUnhashableCountEqual.

Rename assertArrayCountEqual to assertUnhashableCountEqual and fix typo
","[2019-08-15 19:09:24][ostrokach][pull:summary][9352]
Rename assertArrayCountEqual to assertUnhashableCountEqual and fix typo"
Arrow,SATD Repayment,"[2020-01-02 07:24:58][Kazuaki Ishizaki][commit][cec93999fdef8fe9c83e78ec9f9cc53f9341d71c]
ARROW-7482: [C++] Fix typos

This PR fixes typos in files under `cpp/src/arrow` directory

Closes #6110 from kiszk/ARROW-7482 and squashes the following commits:

b5dc3f012 <Kazuaki Ishizaki> fix lint errors
bb39903f4 <Kazuaki Ishizaki> address review comment
b291f2e01 <Kazuaki Ishizaki> fix lint errors
224796723 <Kazuaki Ishizaki> fix typo

Authored-by: Kazuaki Ishizaki <ishizaki@jp.ibm.com>
Signed-off-by: Sutou Kouhei <kou@clear-code.com>
","[2019-12-31 17:49:14][Kazuaki Ishizaki][issue:summary][ARROW-7482:13277039]
[C++] Fix typos"
Ignite,SATD Repayment,"[2018-05-03 16:23:40][tledkov-gridgain][code-comment][83b5c0e0ae493247dc9ba0db0e1014f6c38821aa]
*
 * Tests leaks on node restart with enabled persistence.
","[2018-05-03 16:23:40][tledkov-gridgain][commit][83b5c0e0ae493247dc9ba0db0e1014f6c38821aa]
IGNITE-8347 Test of Memory leaks on restart Ignite node with enabled persistence at ThreadLocal. - Fixes #3889.

Signed-off-by: dpavlov <dpavlov@apache.org>"
Flink,SATD Repayment,"[2020-05-16 16:32:18][Stephan Ewen][code-comment][939625f2c84bdce6872548d3df672f492e33a704]
* The factory for the source reader. This is a workaround, because currently the SourceReader
	 * must be lazily initialized, which is mainly because the metrics groups that the reader relies on is
	 * lazily initialized.
","[2020-05-16 16:32:18][Stephan Ewen][commit][939625f2c84bdce6872548d3df672f492e33a704]
[FLINK-17699][DataStream API] Initalize SourceOperator more eagerly and reduce scope or collaborators.

This reduces the scope of necessary mocking in the tests and of special-casing in the setup logic.

  - This removes the dependency on Source and replaces it with a reader factory
  - This let's the SourceOperator register itself at the OperatorEventDispatcher"
Drill,No Relation,"[2017-06-20 17:01:01][Boaz Ben-Zvi][code-comment][c16e5f8072f3e5d18157767143f9ccc7669c4380]
 if too little memory - behave like the old code -- no memory limit for hash aggregate
 10_000_000_000L
","[2017-05-31 00:10:53][Ben-Zvi][pull:comment][822:119245285]
Yes, but only when %100 sure; else if there's a chance for a SchemaChange -- Better use UnsupportedOperationException ...  
  Code change done !!"
Reef,No Relation,"[2016-05-12 15:03:27][Andrew Chung][code-comment][8b483a53cc738d0739849c32e417b2a3970b8dd6]
 TODO[JIRA REEF-1385]: Check the MessageTaskSourceID on the Driver side.
","[2016-05-12 15:03:27][Andrew Chung][commit][8b483a53cc738d0739849c32e417b2a3970b8dd6]
[REEF-863] Test ActiveContext.SendMessage()

This addressed the issue by
  * Adding a context message portion to the driver-evaluator messaging test.
  * Fixing typos dealing with ContextMessages.
  * Fixing ContextMessageClr2Java where it calls the wrong interop method in Java.
  * Improve understandability of the messaging test.

JIRA:
  [REEF-863](https://issues.apache.org/jira/browse/REEF-863)

This closes #986"
Geode,SATD Duplication,"[2017-05-03 03:04:22][davinash][pull:summary][488]
GEODE-254: Removed deprecated Region.keys and Region.entries
","[2015-08-21 18:04:01][Darrel Schneider][issue:summary][GEODE-254:12857926]
Remove the deprecated Region.keys and Region.entries. Any calls can be simply changed to Region.keySet and Region.entrySet so this should be an easy change.
A large number of tests call the deprecated methods."
Druid,SATD Repayment,"[2013-09-13 13:21:03][cheddar][commit][ef1ac46a7ebe69d916fe840cdc73b3087009f5b9]
Merge pull request #237 from metamx/is-ut

Rework tests in indexing service to be more unit testy
","[2013-09-12 23:39:39][fjy][pull:summary][237]
Rework tests in indexing service to be more unit testy"
Hadoop,SATD Repayment,"[2016-07-14 14:40:58][Akira Ajisaka][commit][5537c6b23430285ebee33c6d9b69d3ec1e9b17b1]
HADOOP-13351. TestDFSClientSocketSize buffer size tests are flaky. Contributed by Aaron Fabbri and Mingliang Liu.
","[2016-07-07 22:56:35][Aaron Fabbri][issue:summary][HADOOP-13351:12987633]
TestDFSClientSocketSize buffer size tests are flaky"
Jena,No Relation,"[2016-09-15 13:34:33][Andy Seaborne][code-comment][52d17aba8a8980ede2056f6b959294b8975fe142]
 ""Temporary"" hack. Graph ought to implement sync and casade it down.
","[2016-09-15 13:34:33][Andy Seaborne][commit][52d17aba8a8980ede2056f6b959294b8975fe142]
Clean up."
Calcite,SATD Repayment,"[2016-08-29 16:14:10][Jesus Camacho Rodriguez][commit][e872959797de16ef856d76526da484e094ef0a10]
[CALCITE-1220] Further extend simplify for reducing expressions

Extends work done in [CALCITE-1116].

Close apache/calcite#270
","[2016-08-24 12:10:01][jcamachor][pull:summary][270]
[CALCITE-1220] Extend simplify for reducing expressions II"
Netbeans,No Relation,"[2019-06-26 13:46:13][Gaurav Gupta][code-comment][b4f79ef8ac06dda14f8a1a4c087faae1704fefac]
 This would probably be a runtime exception due to a bug, but we
 must trap it here so it doesn't cause trouble upstream.
 We handle it the same as above for now.
 !PW FIXME should we notify here, or just log?
","[2019-06-26 13:46:13][Gaurav Gupta][commit][b4f79ef8ac06dda14f8a1a4c087faae1704fefac]
NP-20 Payara Server tools integration in Apache NetBeans IDE (#1290)

* NP-20 Payara server tools integration in Apache NetBeans IDE

* NP-20 fix typo

* NP-20 Polish enterprise/payara.common layer.xml

* NP-20 Fix Rat failure

* NP-20 update the resources license info

* NP-20 add payara server icon license info

* NP-20 modules/endorsed fileset for PayaraV5_192"
Tajo,No Relation,"[2012-01-20 21:00:43][Hyunsik Choi][code-comment][cb6710c1433137159a1d8ee2dd9b83ac0982d5b3]
 TODO - to be implemented
","[2014-08-04 02:12:40][jihoonson][pull:comment][101:15738646]
This is an unused imports.
Please remove it."
Calcite,No Relation,"[2017-09-08 16:04:00][vlsi][pull:comment][503:137828394]
@zhumayun , @jcamacho, this seems to support just one schema level.
In other words, if table is located in a subschema, then table is not found.

In my case, tables are located in `schema.subschema..table`, and this code is unable to find the table.

I'm not very familiar with SqlValidator code, however the proper way to resolve tables seems to be `scope.resolveTable`

If ""findTable"" is a proper approach at all.
","[2017-05-31 13:03:05][Slim Bouguerra][issue:comment][CALCITE-1787:16031114]
[~zhumayun] in my opinion it is better to have something working correctly within one commit/bug_id. This makes code easier to read/maintain and use."
Lucene Solr,SATD Duplication,"[2011-01-05 20:47:08][Simon Willnauer][code-comment][36b17aab62c7a3d254fa976dfee3093af501f889]
 TODO: eable this assert once SolrIndexReader and friends are refactored to use ReaderContext
 We can't assert this here since SolrIndexReader will fail in some contexts - once solr is consistent we should be fine here
 Lucene instead passes all tests even with this assert!
 assert context.isTopLevel: ""IndexSearcher's ReaderContext must be topLevel for reader"" + context.reader;
","[2011-01-05 23:02:49][Yonik Seeley][issue:comment][LUCENE-2831:12978023]
Regarding this assert in IndexSearcher:
    // TODO: eable this assert once SolrIndexReader and friends are refactored to use ReaderContext
    // We can't assert this here since SolrIndexReader will fail in some contexts - once solr is consistent we should be fine here
    // assert context.isTopLevel: ""IndexSearcher's ReaderContext must be topLevel for reader"" + context.reader;

This is a bug in ReaderUtil.build() that when passed a segment reader, it sets isTopLevel to false.
You got bit by those extra booleans ;-) 

When I hacked ReaderContext to just set isTopLevel to parent==null, all the solr tests passed w/ the assertion enabled."
Gobblin,SATD Duplication,"[2017-02-12 09:52:02][Hung Tran][code-comment][ee3137f83d5793197f9ba8d0d630b36d2f3a24d3]
 #HELIX-0.6.7-WORKAROUND
 working around helix 0.6.7 job delete issue with custom taskDriver
","[2017-02-12 09:52:02][Hung Tran][commit][ee3137f83d5793197f9ba8d0d630b36d2f3a24d3]
Helix upgrade to 0.6.7. (#1613)

* Helix upgrade to 0.6.7.
* Add #HELIX-0.6.7-WORKAROUND to comments for workarounds.
* Remove helix-core-0.6.6-SNAPSHOT.jar

Created customized Helix TaskDriver, MessagingService, and CriteriaEvaluator classes to workaround bug, missing functionality, and behavior changes.
Issues that we had to workaround.
1. Messaging service does not allow sending messages to instances
2. Deletion of job is not allowed on a running queue
3. Cannot stop a queue
4. Shutdown message is not defined
5. Creation of queue fails with generic exception if queue already exists"
Beam,SATD Duplication,"[2018-07-25 18:25:58][Mark Liu][code-comment][31fea5d86444fe879afba43cf199e7cb7a7a5e73]
 TODO(BEAM-5025): Disable this test in streaming temporarily.
 Remove sickbay-streaming tag after it's fixed.
","[2018-07-25 18:25:58][Mark Liu][commit][31fea5d86444fe879afba43cf199e7cb7a7a5e73]
[BEAM-4859] Enable Python VR tests in streaming in postcommit task (#6053)

* [BEAM-4859] Enable Python VR tests in streaming in Jenkins postcommit
* Increase integration test timeout since streaming takes longer time
* Disable test_read_metrics in streaming due to BEAM-3544
* Disable test_multi_valued_singleton_side_input in streaming due to BEAM-5025"
Hadoop,No Relation,"[2018-04-02 19:58:09][Anu Engineer][code-comment][b78c94f44c454f35eeadb34d48fea649ea491de5]
 GTEST_HAS_TYPED_TEST || GTEST_HAS_TYPED_TEST_P
","[2017-12-07 20:03:41][Andrew Wang][issue:comment][HDFS-7240:16282441]
Hi Sanjay,

Thanks for writing up that summary. It's clear there's still disagreement on the merge. How should we proceed on reaching consensus? On the last call you suggested making a document, or we could do another call."
Hawq,SATD Repayment,"[2018-03-14 18:23:19][interma][commit][a1acf9638b9834424718349aa8c75f21a614f1fe]
HAWQ-1594. Memory leak in standby master (gpsyncagent process)
","[2018-03-14 03:09:49][Hongxu Ma][issue:summary][HAWQ-1594:13144918]
In a high workload scenario, the gpsyncagent process of standby master consumes memory continuously until restart it.

There are some Memory leak happened."
Shardingsphere,SATD Repayment,"[2020-09-21 19:17:14][kimmking][commit][730571ef49fe2beae5a312cfcd8ebbdc332c59f6]
fix exception checkstyle (#7535)
","[2020-09-21 11:16:41][kimmking][pull:summary][7535]
fix exception checkstyle"
Reef,SATD Repayment,"[2015-06-30 17:50:30][Mariia Mykhailova][commit][d3cf5d598522911cd306d135cdb95ce4b5725921]
[REEF-432]: Fix violations of JavadocPackage checkstyle

This addressed the issue by adding missing package-info.java files with
Javadoc ""TODO: Document.""

JIRA:
  [REEF-432](https://issues.apache.org/jira/browse/REEF-432)

Pull Request:
  This closes #265
","[2015-07-01 00:22:08][tcNickolas][pull:summary][265]
This addressed the issue by
- Adding missing package-info.java files with Javadoc ""TODO: Document.""

JIRA: [REEF-432](https://issues.apache.org/jira/browse/REEF-432)"
Lucene Solr,No Relation,"[2013-01-18 18:30:54][Alan Woodward][code-comment][ae98268935ae3a45c972137a1fe2c8b1e9e8d4b8]
 TODO: maybe allow re-analysis for tiny fields? currently we require offsets,
 but if the analyzer is really fast and the field is tiny, this might really be
 unnecessary.
","[2012-10-29 14:56:07][Robert Muir][issue:comment][LUCENE-2878:13486067]
I don't like the general style of things like Collector.postingsFeatures()

From the naming, you cant tell this is a ""getter"". In general I think methods like this should be getPostingsFeatures() ?"
Drill,No Relation,"[2016-08-23 22:33:54][jinfengni][pull:comment][575:75964268]
Maybe we log a JIRA for this TODO, so that we keep track of this issue? Seems it makes sense to either use the list of entries, or fileSet, but not both.
","[2016-08-19 19:34:06][Aman Sinha][issue:summary][DRILL-4857:12998575]
After DRILL-4530, we see the (expected) performance improvements in planning time with metadata cache for cases where partition pruning got applied.  However, in cases where it did not get applied and for sufficiently large number of files (tested with up to 400K files),  there's performance regression.  Part of this was addressed by DRILL-4846.   This JIRA is to track some remaining fixes to address the regression."
Hadoop,No Relation,"[2012-04-11 17:09:54][Siddharth Seth][code-comment][cfafd8c29dc3679e503c6155bcbf26f377b0ea8f]
 Add the staging directory cleaner before the history server but after
 the container allocator so the staging directory is cleaned after
 the history has been flushed but before unregistering with the RM.
","[2012-04-10 18:51:45][Robert Joseph Evans][issue:comment][MAPREDUCE-4099:13250955]
I like the patch.  +1 

I just have one small comment.  We are not logging the IOException that caused the staging dir to not be deleted, I can add it in when I check it in though."
Accumulo,No Relation,"[2014-11-24 18:06:40][Josh Elser][commit][f5e5d2d336e5be04317ffaa02f33462c805f1911]
ACCUMULO-3167 Port over more tests to AccumuloClusterIT

Make sure tests don't destructively change the configuration.
Use table names which start with the test class name and method
so the base class can clean them up automagically.
","[2014-11-19 04:45:04][Josh Elser][issue:comment][ACCUMULO-3167:14217414]
Attaching reviewboard. Initial patch that switches a number of ITs over to being able to run against a standalone cluster or miniaccumulo cluster with no test code changes."
Nifi Minifi Cpp,No Relation,"[2020-01-20 15:03:46][Daniel Bakai][commit][7d18dc8501ffa884f642d7f5836a12983c6719b1]
MINIFICPP-1088 - clean up minifiexe and MINIFI_HOME logic

Signed-off-by: Arpad Boda <aboda@apache.org>

This closes #709
","[2020-01-16 15:42:17][szaszm][pull:comment][709:367490826]
I believe the logic to fix class names doesn't belong here but rather in a function that's used to query class names."
Hive,SATD Repayment,"[2018-05-15 14:26:00][Prasanth Jayachandran][commit][4b418a4aeacf21bf84e01d03815124fa8b7cb79a]
HIVE-19560: Retry test runner and retry rule for flaky tests (Prasanth Jayachandran reviewed by Jesus Camacho Rodriguez)
","[2018-05-15 20:19:29][Prasanth Jayachandran][issue:summary][HIVE-19560:13159520]
Retry test runner and retry rule for flaky tests"
Lucene Solr,No Relation,"[2019-11-26 00:18:33][dsmiley][pull:comment][1037:350488231]
At least we should acknowledge in a comment that this is expensive :-/
At least I could imagine a user solving this by subclassing FuzzyQuery to override toAutomaton and using a cache.
","[2019-11-25 09:54:45][Alan Woodward][issue:summary][LUCENE-9062:13270408]
Currently, QueryVisitor only allows queries to report that they consume a fixed set of terms.  For multi-term queries, however, they don't know which terms in an index they're going to match until rewrite time.  Current users of this API get round this by using instanceof checks in a `visitLeaf()` method, but this is clunky and does not adapt well to user-defined queries.

We should extend QueryVisitor so that queries can report that they consume a class of terms matching an automaton, in addition to individual terms."
Kafka,No Relation,"[2019-04-15 20:12:33][vvcephei][pull:comment][6536:275525990]
When I wrote the tests the first time around, I overlooked a simpler application to test suppression. Switching to this simpler application made it possible to directly test for the bug (duplicated suppress output).
","[2019-04-01 21:43:19][John Roesler][issue:comment][KAFKA-7895:16807217]
Quick update: The main source of the duplicates seems to be this odd situation where the suppression buffer is sometimes sending its records to the wrong changelog partition. This results in duplicates because those changelog partitions are handled independently, so the message sent to the wrong partition will be emitted in addition to the ones sent to the right partition. It's still not clear why some records are being logged to the wrong partition.

When I fully understand why this is happening, I should also be able to explain why none of the existing tests have caught this condition, when it's so easy to reproduce with your application."
Cloudstack,SATD Repayment,"[2011-01-18 16:17:04][Alex Huang][code-comment(deleted)][28137b805b0265023f5332192b9c959bbc13151d]
 FIXME: Cleanup.
","[2011-01-18 16:17:04][Alex Huang][commit][28137b805b0265023f5332192b9c959bbc13151d]
more cleanup work"
Tvm,No Relation,"[2020-07-14 17:16:22][Chenfan][code-comment][456c58dea0f76237401674e7f09989130eada214]
 Create the initial schedule
 TODO(jcf94): Currently we only checked single output dag for TVM Auto-scheduler,
 update this after testing with multiple outputs.
","[2020-06-30 19:12:54][comaniac][pull:comment][5962:447919856]
Better to use `disable=broad-except` to make it more clear."
Attic Apex Malhar,No Relation,"[2013-11-25 21:41:55][Andy Perlitch][code-comment][72d651f99a70d728921e2b4c8df9b6bfcea3e9c4]
 Speed-up: Sizzle("".CLASS"")
","[2016-08-08 22:20:13][otterc][pull:comment][324:73966670]
It seems `bucketId`, `prefix` are unused. Also please add getter/setter for batchsize."
Brooklyn Server,SATD Repayment,"[2014-05-26 22:09:30][Aled Sage][code-comment][7e18144ade9e86271354260ced9d6c97bebc9108]
 problem: but let's ensure that classpath is sane to give better errors in common IDE bogus case;
 and avoid repeated logging
","[2014-05-26 22:09:30][Aled Sage][commit][7e18144ade9e86271354260ced9d6c97bebc9108]
Avoid repeated logging: BasicLocationRegistry"
Parquet Mr,No Relation,"[2020-02-20 13:35:26][gszadovszky][pull:comment][757:382000764]
You may speed up the hashing by having a `ByteBuffer` cache created at class level. You may create a 64bit long buffer and set the ordering once. Then, you can `clear` the buffer before putting a value in it then flip before invoking `hashByteBuffer`.
In the other hand I can see the functions `hashLong` and `hashInt` in `LongHashFunction`. Maybe it worth to update the `HashFunction` interface so you can call these directly. I am not sure which options is the best or which one performs better.
","[2015-03-31 20:22:46][Ryan Blue][issue:comment][PARQUET-41:14389323]
Thanks [~prateekrungta]! Looks like I need to go read ""Less Hashing, Same Performance: Building a Better Bloom Filter"" by Kirsch et. al. now."
Nifi,No Relation,"[2016-02-02 17:02:21][markap14][pull:comment][200:51598556]
Typo in the variable name here - ROUNTING instead of ROUTING
","[2016-02-03 01:53:10][Joe Witt][issue:comment][NIFI-865:15129591]
Yes.  The LICENSE and NOTICE provided in the nar (nifi-amqp-nar/src/main/resources/META-INF/) itself is a great step.  However, the LICENSE should be unmodified plain old apache license.  The added language at the bottom is unnecessary and should be avoided (removed).  Specifically remove lines 204-212.

The NOTICE file provided is great but lines 13-16 should also be placed into the nifi-assembly/NOTICE as well.

Those two changes and you should be in good shape licensing wise if indeed that is the only dep (no transitive stuff).

Thanks
Joe"
Hadoop,SATD Repayment,"[2010-02-22 22:28:29][Devaraj Das][code-comment][c5622e5d4df0ec83ffedb46f1d4cfdeed9e43539]
 
       Further SaslException should be ignored during cleanup and
       original exception should be re-thrown.
","[2010-02-16 23:50:42][Kan Zhang][issue:comment][HADOOP-6543:12834553]
Add a new patch that ignores the previous findbugs warning, since further SaslExceptions should be ignored during cleanup and the original exception should be re-thrown."
Hbase,SATD Duplication,"[2019-05-13 03:01:34][apurtell][pull:comment][225:491660228]
The rubocop result is silly. I left the formatting the same as I found it. Somehow it was not valid before? But if someone feels this is legitimate, I can just drop the change to admin.rb, it is just a trivial thing. 

The unit test failure looks unrelated, perhaps environmental.
","[2019-05-13 03:02:44][Andrew Kyle Purtell][issue:comment][HBASE-22377:16838227]
Copying my comments from the PR

The rubocop result is silly. I left the formatting the same as I found it. Somehow it was not valid before? But if someone feels this is legitimate, I can just drop the change to admin.rb, it is just a trivial thing.

The unit test failure looks unrelated, perhaps environmental.

This looks ready to go to me."
Drill,No Relation,"[2017-12-11 20:19:02][paul-rogers][pull:comment][1045:156187558]
Github is very confused by this double rename. I presume the new file just has the same contents, but a new name? Used an online diff checker to compare the two interfaces. Turns out there are important differences. Comments below.
","[2017-09-27 18:54:13][Timothy Farkas][issue:comment][DRILL-5730:16183086]
[~Paul.Rogers] All the tests are passing for me using JDK 8 with DRILL-5752 . I observed that various race conditions surfaced when switching to JDK 8 at first, but I have been slowly fixing the flakey tests throughout my commits, and it looks like the issue is resolve (for me atleast) with DRILL-5752. After that change is merged please try running the tests with JDK 8 again."
Hbase,SATD Repayment,"[2017-12-15 16:16:34][Peter Somogyi][commit][f9f869f60a334982b739420a614b5d44adf26af0]
HBASE-19497 Fix findbugs and error-prone warnings in hbase-common (branch-2)
Signed-off-by: Apekshit Sharma <appy@apache.org>
","[2017-12-12 10:00:37][Peter Somogyi][issue:summary][HBASE-19497:13124327]
Fix findbugs and error-prone warnings in hbase-common (branch-2)"
Carbondata,SATD Duplication,"[2016-12-30 16:44:43][jackylk][pull:summary][484]
[CARBONDATA-571][CARBONDATA-572] Clean up code for carbon spark integration
","[2016-12-27 17:19:02][Jacky Li][issue:summary][CARBONDATA-571:13030734]
clean up code for carbon-spark module"
Trafficcontrol,No Relation,"[2020-02-17 10:09:41][mattjackson220][code-comment][18fe13ac638557b5532813bce8ab3ad2d964fe49]
 ErrCodePackedPolicyTooLargeException for service response error code
 ""PackedPolicyTooLarge"".

 The request was rejected because the policy document was too large. The error
 message describes how big the policy document is, in packed form, as a percentage
 of what the API allows.
","[2020-02-12 15:09:23][ocket8888][pull:comment][3534:378311239]
I'd feel bad asking you to change this yet again, and this gets the point across, so feel free to ignore this, but you didn't need to specify the form yourself, you can just link to the RFC. Which is easy to do with the built-in `rfc` role:
```rst
:expiration: The expiration date of the certificate for the :term:`Delivery Service` in :rfc:`3339` format
```"
Zookeeper,SATD Duplication,"[2019-04-12 19:23:27][eolivelli][pull:summary][909]
ZOOKEEPER-3362 Create a simple checkstyle file
","[2019-04-12 19:17:18][Enrico Olivelli][issue:summary][ZOOKEEPER-3362:13227782]
Create a basic checkstyle file, in order to cover the minimal check on @author tags.

This is needed in order to drop old ANT based precommit job (see ZOOKEEPER-3351)

We will not remove legacy checkstyle configuration file in zookeeper-server/src/test/resources/checkstyle.xml because it is referred by ANT build.xml files (even if we are not actually using that target).

This task won't add a complete checkstyle configuration with usual checks because it would imply almost a change at every .java in the codebase."
Flink,SATD Repayment,"[2019-08-07 16:49:45][Konstantin Knauf][code-comment][f695a76b10b0cb5f074bbb874fe374cd11e6eff3]
disabling Operator chaining to make it easier to follow the Job in the WebUI
","[2019-07-24 16:20:56][fhueske][pull:comment][9192:306902320]
disable operator chaining to make the job easier to follow in the web frontend?"
Trafficserver,No Relation,"[2013-07-18 17:32:21][Alan M. Carroll][code-comment][941784b2a1ff3bcaf8a9a78337dbf121d6a21cf6]
* Lifecycle callback.

      The function @a cb is called after cache initialization has
      finished and the cache is ready or has failed.

      @internal If we need more lifecycle callbacks, this should be
      generalized ala the standard hooks style, with a type enum used
      to specific the callback type and passed to the callback
      function.
","[2012-09-24 16:43:13][Leif Hedstrom][issue:comment][TS-1487:13461901]
As for Yongming's comment: remember that this is done by design. I'm definitely for making it possible to startup without requiring the cache to be made available, but it needs to be optional. The idea with the current design is that in a single server (or small number of servers) setup, it's better to proxy than to refuse connections until the cache is up."
Reef,SATD Repayment,"[2015-10-14 11:56:22][Dongjoon Hyun][commit][8b7189bd764cea5421d4810fd5b024b935e3e67c]
[REEF-839] Fix typos in REEF.NET

This fixes many typos in C# files.

JIRA:
  [REEF-839](https://issues.apache.org/jira/browse/REEF-839)

Pull Request:
  This closes #561
","[2015-10-13 00:48:55][Dongjoon Hyun][issue:summary][REEF-839:12904402]
Fix typos in REEF.NET"
Helix,No Relation,"[2020-02-07 12:24:22][Jiajun Wang][code-comment][71948ec8fdb97c2b62fd41b0d944b653b46ae01c]
 Note that the calculation used the baseline as the input only. This is for minimizing unnecessary partition movement.
","[2019-09-27 19:17:00][jiajunwang][pull:comment][456:329216138]
I tried your suggestion. In short, I partially agree with you, but I think the current implementation is safer.

Major concern is that the change will make the idea state calculation logic separated. More specifically, the current code ensures the preference lists in the IdealState is calculated by the computeBestPossibleStates() only. And the later operation won't change the preference lists anymore. If we break this assumption, although there won't be any immediate issue, the future devs may be confused where they can get the finalized preference lists."
Cassandra,No Relation,"[2012-03-27 22:43:00][Pavel Yaskevich][code-comment][731af1a4323314dc31020deec9fd04b97a79519c]
 to escape duplicating error message
","[2012-03-27 19:25:49][Pavel Yaskevich][issue:comment][CASSANDRA-4087:13239850]
It's not really necessary because default value to ""key_cache_size_in_mb"" is set in the Config class to ""auto"" so there is not chance it would be NPE."
Jena,SATD Duplication,"[2015-01-12 01:19:14][Stian Soiland-Reyes][code-comment][8a6b2823456ddf4802ca8d9ca97a7f05ff73ce2e]
 TODO: Move to jena-parent?
","[2015-01-12 01:19:14][Stian Soiland-Reyes][commit][8a6b2823456ddf4802ca8d9ca97a7f05ff73ce2e]
ver.* properties as in jena-parent

TODO: Move these properties to jena-parent?"
Beam,No Relation,"[2019-08-06 14:28:47][Chamikara Jayalath][code-comment][9678149872de2799ea1643f834f2bec88d346af8]
 TODO: add verification for the file written by external transform
  after fixing BEAM-7612
","[2019-02-15 21:00:20][Chamikara Madhusanka Jayalath][issue:summary][BEAM-6683:13216078]
Add an integration test suite for cross-language transforms for Flink runner"
Beam,No Relation,"[2016-12-02 15:42:33][Eugene Kirpichov][commit][96455768568616141a95833380f37c478a989397]
Makes DoFnTester use new DoFn internally.

There were 2 remaining users of DoFnTester.of(OldDoFn):
- SplittableParDo.ProcessElements: this is fixed in
  https://github.com/apache/incubator-beam/pull/1261
- GroupAlsoByWindowsProperties: this one is harder.
  Various GABWDoFn's use OldDoFn.windowingInternals,
  and we can't pass that through a new DoFn.
  So instead I removed usage of DoFnTester from
  GroupAlsoByWindowsProperties in favor of a tiny
  hand-coded solution.

So after #1261 DoFnTester.of(OldDoFn) can be deleted.
","[2016-11-30 21:42:22][tgroh][pull:comment][1261:90334967]
This might be worth factoring out of this PR into a cleanup PR, just for simplicity."
Calcite,SATD Duplication,"[2016-03-01 12:29:56][jcamachor][pull:summary][202]
[CALCITE-1116] Extend simplify for reducing expressions
","[2016-03-01 12:28:01][Jesus Camacho Rodriguez][issue:summary][CALCITE-1116:12945816]
Extend simplify for reducing expressions"
Gobblin,SATD Repayment,"[2019-07-19 14:12:00][sv2000][commit][51edd5d82f4246db24b05de0f9e45f86bc7a7af2]
[GOBBLIN-816] Implement a workaround to abort Helix TaskDriver#getWorkflows() after a timeout[]

Closes #2680 from sv2000/getWorkflowsWorkaround
","[2019-06-28 20:18:07][sv2000][pull:summary][2680]
GOBBLIN-816: Implement a workaround to abort Helix TaskDriver#getWork…"
Tajo,SATD Duplication,"[2015-03-31 04:47:56][jinossy][pull:summary][484]
TAJO-1482: Cleanup the legacy cluster mode.
","[2015-03-31 02:30:52][Jinho Kim][issue:summary][TAJO-1482:12786904]
Cleanup the legacy cluster mode"
Thrift,SATD Duplication,"[2015-09-28 12:26:19][nsuke][pull:summary][629]
THRIFT-3360 Improve cross test servers and clients further
","[2015-09-27 14:47:29][Nobuaki Sukegawa][issue:summary][THRIFT-3360:12896659]
Improve cross test servers and clients further"
Arrow,No Relation,"[2019-11-26 01:05:52][wesm][pull:comment][5892:350499606]
I'd be in favor of changing the names to be more clear and where relevant, conforming to the specification
","[2019-09-18 17:53:49][Antoine Pitrou][issue:comment][ARROW-6157:16932715]
Hmm. Perhaps that validation can be moved to a separate method :-)
Then we'll have to make sure that all tests call the thorough validation method, rather than the light one."
Druid,No Relation,"[2018-12-21 12:49:24][Joshua Sun][code-comment][7c7997e8a1183a7bffad731ca94e8b4c381e8665]
 not yet supported, will be implemented in the future
","[2018-11-30 01:15:18][dclim][pull:comment][6431:237717742]
Typo in method name: parition -> partition"
Drill,SATD Repayment,"[2017-02-24 19:01:41][Kunal Khatua][commit][8614bae5e881dadeb556206c1e2129e9b816a50c]
DRILL-5195: Publish Operator and MajorFragment Stats in Profile page

Improved UI
1. Introduction of Tooltips
2. Share of each operator as a percentages of the major fragment and of the query
  - This would help identify the most CPU intensive operators within a fragment and across the query
3. Rows emitted by each operator
4. For a running query, changes to 'last update' and 'last progress' now shows the elapsed time since.

closes #756
","[2017-02-22 20:37:01][kkhatua][pull:summary][756]
Improved UI
1. Introduction of Tooltips
2. Share of each operator as a percentages of the major fragment and of the query
  - This would help identify the most CPU intensive operators within a fragment and across the query
3. Rows emitted by each operator
4. For a running query, changes to 'last update' and 'last progress' now shows the elapsed time since."
Geode,SATD Repayment,"[2015-07-14 12:25:42][Dan Smith][commit][9fa9ced08f1851f97d2d2407f1519dcc3cac06e0]
GEODE-74: Making the satisfy redundancy phase of rebalance parallel

Tasks submitted to background threads to trigger redundancy
satisfaction. After the satisfy redundancy phase is done we wait for the
tasks to finish.

The number of buckets that can be recovering in parallel is controlled
by the system property gemfire.MAX_PARALLEL_BUCKET_RECOVERIES, currently
set to 8.

If a redundancy recovery/rebalance is restarted due to a membership
change, wait for any in progress operations to complete before fetching
new information from all of the members.
","[2015-07-01 18:54:35][Dan Smith][issue:summary][GEODE-74:12842076]
Recover redundancy in parallel"
Ozone,SATD Duplication,"[2020-11-03 23:25:56][errose28][pull:summary][1553]
HDDS-4431. Improve output message for key/bucket list command.
","[2020-11-03 23:00:53][Ethan Rose][issue:summary][HDDS-4431:13338737]
Improve output message for key/bucket list command"
Camel,SATD Repayment,"[2020-10-02 10:49:16][Claus Ibsen][commit][7bfaccb2415df09ebfeda810359c6ac52e04d2da]
CAMEL-15605: Languages should be singleton for better performance.
","[2020-10-01 07:13:27][Claus Ibsen][issue:summary][CAMEL-15605:13330299]
camel-core - Languages should be singleton for better performance"
Arrow,No Relation,"[2019-11-26 09:38:25][pitrou][pull:comment][5892:350629784]
Yes. I think this is simpler than having to lazily-initialize it.
","[2019-09-18 16:34:47][Wes McKinney][issue:comment][ARROW-6157:16932632]
Not obvious to me either. It seems like there is a dual need

* Checking very basic validity preconditions
* Actual data validation (boundschecking, checking monotonicity in the case of variable offsets, etc.)

AFAICT we haven't really implemented much in the way of the latter. I think it'd be useful to have this in C++ but separate from the current {{Array::Validate}} I guess, and something that users can opt in to if they need to sanitize inputs"
Druid,No Relation,"[2018-01-23 00:37:59][Roman Leventov][commit][f99c27e9e0d41a30a5a0b8029573311b528d1771]
Fix bugs in ImmutableRTree; Merge bytebuffer-collections module into druid-processing (#5275)

* Fix bugs in ImmutableRTree; optimize ImmmutableRTreeObjectStrategy.writeTo(); Merge bytebuffer-collections module into druid-processing

* Remove unused declaration

* Fix another bug
","[2018-01-09 22:22:59][leventov][issue:comment][4312:356433882]
@himanshug I don't think there could be any debate about this, it wasn't implemented before just because nobody had time for this"
Spark,SATD Duplication,"[2019-03-13 08:03:46][Yuming Wang][code-comment][dccf6615c34c9347e937838742dec88456843f13]
 The same profiles used for building are used to run Checkstyle by SBT as well because
 the previous build looks reused for Checkstyle and affecting Checkstyle. See SPARK-27130.
","[2019-03-12 10:31:09][HyukjinKwon][pull:comment][24065:264611108]
and .. let's also leave a comment saying, ""The same profiles used for building are used to run Checkstyle by SBT as well because the previous build looks reused for Checkstyle and affecting Checkstyle. See SPARK-27130."""
Tajo,SATD Repayment,"[2014-08-05 11:58:16][jinossy][commit][0f3412a74bb3c565df1259b19630bc17e1bc69e0]
TAJO-989: Cleanup of child blocks after parent execution block is complete. (jinho)

Closes #103
","[2014-08-03 14:06:55][Jinho Kim][issue:summary][TAJO-989:12731608]
Cleanup of child blocks after parent execution block is complete"
Incubator Mxnet,No Relation,"[2018-01-31 13:31:41][Da Zheng][code-comment][2cc2aa2272881326c8a50c6204aedd71e1821c3f]
 The memory is allocated from the temporary memory space in the
 operator. It'll only become invalid after we exit from the operator.
","[2017-12-11 22:27:09][zheng-da][pull:comment][8302:156218843]
probably not. I'll remove the class."
Cloudstack,No Relation,"[2020-01-30 19:52:28][Sid Kattoju][commit][6baa598033fa3f78b5b0144275de8c1404f67f29]
Clean up inactive iscsi sessions when VMs get moved due to crashes (#3819)
","[2020-01-28 08:45:33][svenvogel][pull:comment][3819:579139719]
@rhtyd can we run tests please? unfortunately you can only test the code formally or using a solidfire. we and the @syed and @skattoju4 tested it."
Druid,No Relation,"[2019-04-19 16:37:14][leventov][pull:comment][7477:277031411]
Then there should be a Javadoc comment on the method mentioning that. Otherwise, readers of this class may this question and will go re-check if Druid still supports Java 7.
","[2019-06-18 05:24:15][itanoss][issue:comment][5589:502952070]
Now  it is failed to launch druid with the tutorial under JDK 11:
```bash
apache-druid-0.14.2-incubating$ bin/supervise -c quickstart/tutorial/conf/tutorial-cluster.conf
Please upgrade to Java 8 or better! Your current version is 11.0.2
```"
Lucene Solr,No Relation,"[2007-02-21 20:01:36][Michael McCandless][code-comment][4541271b9dc666c0473aebf5d1f9e4b476c10f7b]
*
 * This exception is thrown when Lucene detects
 * an inconsistency in the index.
","[2007-02-16 22:58:27][Chris M. Hostetter][issue:comment][LUCENE-793:12473847]
> Since these really are cases of severe index corruption I thought it
> best to throw CorruptIndexException instead? 

no disagreement, i'm just not clear on why ""CorruptIndexException"" (which is a completley new Exception type created by your patch correct?) should be a subclass of IOException instead of IllegalStateException."
Superset,No Relation,"[2021-01-26 09:29:49][simchaNielsen][commit][4d04565c9af477d10b01a1d9156a63af38f381e0]
feat(native-filters): apply scoping of native filters to dashboard (#12716)

* feat: scoping native filters in dashboard

* test: add tests / fix reducer

* test: fix tests

* chore: merge with master

* fix: fix undefined cases

* fix: fix code according cypress

* refactor: fix mocks according CRs

* chore: re run pipeline
","[2021-01-25 07:56:40][villebro][pull:comment][12716:563520165]
nit:
```suggestion
import { getActiveNativeFilters } from 'src/dashboard/util/activeDashboardNativeFilters';
```"
Cloudstack,No Relation,"[2016-05-20 08:33:07][Will Stevens][code-comment][82b702dc9ae4db2d87ea213c49e168a430872ca4]
XXX: not sure if this the right thing to do here. We can always fallback to the ""copy from sec storage""
","[2016-04-08 20:16:23][jburwell][pull:comment][1403:59082995]
This appears to be the default implementation from the IDE.  I realize that it predates this patch, but should method do more?  If not, can we strike the IDE generated comment to avoid future confusion?"
Incubator Brooklyn,No Relation,"[2015-11-02 16:42:45][Alex Heneveld][code-comment][48e4fe3ca0b5a00fbdec10bceec9f21edee25ded]
 TODO rename as BrooklynObjectSignature or BrooklynObjectMetadata;
 or (perhaps better and easier to retire deprecated usage, if that is required?)
 introduce new mechanism for storing accessing this information
","[2015-10-30 03:00:38][ahgittin][pull:summary][993]
Introduce a type registry as a simplified catalog"
Incubator Brooklyn,No Relation,"[2013-01-28 12:49:08][Aled Sage][code-comment][6477174b272ae9e192f377730a001087f9350ace]
 Wait for it to reach size 2, and confirm take expected time
 TODO This is time sensitive, and sometimes fails in CI with size=1 if we wait for currentSize==2 (presumably GC kicking in?)
      Therefore do strong assertion of currentSize==2 later, so can write out times if it goes wrong.
","[2013-01-28 12:49:08][Aled Sage][commit][6477174b272ae9e192f377730a001087f9350ace]
Fix AutoScalerPolicy

- We didn't have tearDown, so for ""repeated"" test with invocationCount=100
  we were presumably having 100 app+policies running, with lots
  of threads etc
- Also tidied up some of the assertion code to improve messages"
Hbase,SATD Repayment,"[2014-10-31 17:12:21][Nick Dimiduk][commit][f5d6314c87b0375fd455980b0c18b650a466d840]
HBASE-12335 IntegrationTestRegionReplicaPerf is flaky
","[2014-10-24 02:21:03][Nick Dimiduk][issue:summary][HBASE-12335:12750254]
IntegrationTestRegionReplicaPerf is flaky"
Lucene Solr,No Relation,"[2011-05-22 21:45:19][Steven Rowe][code-comment][674feedec605b578ad8509be8b860681846fd33a]

 TODO: if we want to support more than one value-filler or a value-filler in conjunction with
 the DocValues, then members like ""scorer"" should be per ValueFiller instance.
 Or we can say that the user should just instantiate multiple DocValues.
","[2011-06-20 12:37:22][Robert Muir][issue:comment][SOLR-2452:13051953]
ok, i was just curious, sounds like something that could possibly be dealt with later.

I think i said it before too, I find it confusing the way these directories all depend upon each other today and how each one is not its own 'subproject' of the build (that basically acts like a contrib or module itself and states its dependencies). So I would *really* like to see this fixed.

However, I think I would recommend thinking about when you want to make the change: it will make merging code up to this branch nearly impossible... is it holding back other changes or is this a final step?"
Hbase,SATD Repayment,"[2017-12-15 16:16:34][Peter Somogyi][commit][f9f869f60a334982b739420a614b5d44adf26af0]
HBASE-19497 Fix findbugs and error-prone warnings in hbase-common (branch-2)
Signed-off-by: Apekshit Sharma <appy@apache.org>
","[2017-12-12 10:00:37][Peter Somogyi][issue:summary][HBASE-19497:13124327]
Fix findbugs and error-prone warnings in hbase-common (branch-2)"
Incubator Heron,SATD Repayment,"[2017-01-21 10:47:05][Mark Li][code-comment][dee26e80bdb8c140bdc0fdf948b8672fa3ae9650]
 SUPPRESS CHECKSTYLE RegexpSinglelineJava
 Exit with status code 200 to indicate dry-run response is sent out
","[2016-12-21 17:55:23][billonahill][pull:comment][1629:93487032]
Instead of hard coding 200 here can we have this be a constant somewhere with it's meaning implied in the name?

RESP_CODE_FOO=100
RESP_CODE_DRY_RUN=200"
Trafficserver,SATD Duplication,"[2015-07-08 12:37:26][Leif Hedstrom][code-comment][61bf5c4fc35814a6db97b6098dd2deaa06157e3a]
 This is currently eliminated, since it breaks things in odd ways (see TS-3710)
","[2015-07-08 17:39:49][Leif Hedstrom][issue:comment][TS-3687:14619021]
We're reverting this, since it breaks things in odd ways (see TS-3710). Moving this out to 6.1.0 as well."
Lucene Solr,No Relation,"[2015-03-31 05:22:40][Ryan Ernst][code-comment][05cf3fde0d909a492df8e82c119c4b632defc709]
*
         * We use this place holder object to pull the UninvertedField construction out of the sync
         * so that if many fields are accessed in a short time, the UninvertedField can be
         * built for these fields in parallel rather than sequentially.
","[2015-02-20 19:18:42][Robert Muir][issue:comment][LUCENE-6271:14329386]
I agree, Terms.hasPositions(), Terms.hasFreqs(), Terms.hasPayloads(), Terms.hasOffsets() should be used for these checks up-front.

For the backwards behavior, in 5.x we could use an internal flag to make this work. We still need to improve the flags anyway (e.g. to not overlap, and for the new ones to be a little simpler). This is probably good to do first, I sitll have the issue open for it."
Hawq,SATD Repayment,"[2016-07-14 14:55:30][YI JIN][commit][ef3325f2ba1c6ac6782c4540b97942f6fc68a898]
HAWQ-894. Add feature test for polymorphism with new test framework
","[2016-07-06 04:29:40][Wen Lin][issue:summary][HAWQ-894:12987041]
Add feature test for polymorphism with new test framework"
Druid,SATD Repayment,"[2015-09-04 15:06:22][Fangjin Yang][commit][07266d682a4456012f048593e14d702779404588]
Merge pull request #1694 from metamx/namespaceExtractionCacheManagerTestImprovements

Better timing and locking in NamespaceExtractionCacheManagerExecutorsTest
","[2015-09-01 19:35:37][drcrallen][pull:summary][1694]
Better timing and locking in NamespaceExtractionCacheManagerExecutorsTest"
Netbeans,SATD Repayment,"[2019-11-13 14:15:15][Svatopluk Dedic][commit][7ec83916cca2bd87c2b72e66bd88c0462e1c50e4]
Merge pull request #1578 from sdedic/bugfix/serviceProcessorAnnotation

NETBEANS-3250: Fix warnings from annotation processors.
","[2019-10-18 10:23:30][Svatopluk Dedic][issue:summary][NETBEANS-3250:13263063]
Most of the processors declare *@SupportedSourceVersion(RELEASE_7)* or even earlier, which produces warnings if the project uses greater source level.

The warnings are harmess, but annoying."
Camel,SATD Repayment,"[2014-05-27 18:26:06][Akitoshi Yoshida][commit][de56e0bddfaa007e6c224ed5a7e5abb085a95cc6]
CAMEL-7468: Make xmlTokenizer more xml-aware so that it can handle more flexible structures
","[2014-05-27 14:22:24][Akitoshi Yoshida][issue:summary][CAMEL-7468:12716817]
Make xmlTokenizer more xml-aware so that it can handle more flexible structures"
Hbase,No Relation,"[2019-08-12 15:57:21][johnhomsea][code-comment][009851d680e1bb58791715d5d3ad0387b5efbc72]
*
   * This function is the alias of regionDefinitelyOnTheRegionServerException,
   * whose name is confusing in the function findException().
","[2019-08-09 02:27:35][Joseph295][pull:comment][436:312309821]
> Make this private? And can we reuse the regionDefinitelyOnTheRegionServerException so we can write less instance of here? And MultiActionResultTooLarge is not included in regionDefinitelyOnTheRegionServerException? 

Here the isSpecialException is equivalent with regionDefinitelyOnTheRegionServerException, the two more exceptions in isSpecialException  are RegionMovedException and  RegionOpeningException. Both of them are subclasses of NotServingRegionException, which is there."
Tinkerpop,SATD Repayment,"[2017-06-09 10:58:57][Stephen Mallette][commit][1a1ba58333d1ebae69d1e5e4d14e01255bb5bb40]
TINKERPOP-1563 Removed deprecated getInstance() methods
","[2016-11-22 11:37:32][Stephen Mallette][issue:summary][TINKERPOP-1563:13022478]
Remove deprecated getInstance() methods"
Commons Lang,SATD Duplication,"[2017-06-08 08:14:32][Benedikt Ritter][code-comment][8ec7e02e753267c2470f76d9ed729e3ca7dfec6e]
 Temporary fix for LANG-1338, remove this after this has implemented in parent pom
","[2017-06-08 08:14:32][Benedikt Ritter][commit][8ec7e02e753267c2470f76d9ed729e3ca7dfec6e]
LANG-1338: Add Automatic-Module-Name MANIFEST entry for Java 9
compatibility.

This change duplicates adds some maven-jar-plugin configuration pom.
After we have implemented a solution for this in parent pom, this
confgiruation should be removed."
Airflow,SATD Repayment,"[2015-11-05 22:46:18][Bolke de Bruin][code-comment][67400063d9dcf7a89b80b27896d5410e3fee70f3]
models.User = User  # hack!
del User
","[2015-11-05 22:46:18][Bolke de Bruin][commit][67400063d9dcf7a89b80b27896d5410e3fee70f3]
Remove hack for User"
Camel,SATD Duplication,"[2020-09-18 08:43:45][Claus Ibsen][code-comment][119fcebf6f7b32989c1a7bb7cc9a57dd40a3496e]
 we get the api description via the method signature (not ideal but that's the way of the old parser API)
","[2020-09-01 12:51:11][Claus Ibsen][issue:comment][CAMEL-15478:17188428]
api component generator of enums generate them with UPPERCASE(""human name here"") kind.
So it would be good for the json metadata tooling to handle this, so it can use the ""human names"" as its enums in the generated schema instead of the ugly uppercased.

As workaround we have sometimes manually added enums=""aaa,bbb,ccc"" in the source code. But lets make the tooling smarter. See the api components such as twillio

*DONE*"
Hbase,No Relation,"[2017-06-20 01:06:47][Kahlil Oppenheimer][commit][5224064d4d1370aef1ef5ba16078014ab5c593f1]
HBASE-18164 Fast locality computation in balancer

-Added new LocalityCostFunction and LocalityCandidateGenerator that
cache localities of every region/rack combination and mappings of every
region to its most local server and to its most local rack.

-Made LocalityCostFunction incremental so that it only computes locality
based on most recent region moves/swaps, rather than recomputing the
locality of every region in the cluster at every iteration of the
balancer

-Changed locality cost function to reflect the ratio of:
(Current locality) / (Best locality possible given current cluster)

Signed-off-by: Sean Busbey <busbey@apache.org>
Signed-off-by: Chia-Ping Tsai <chia7712@gmail.com>
","[2017-06-12 20:33:55][Sean Busbey][issue:comment][HBASE-18164:16047032]
I reran the QA build to see if some of those failures are maybe flakys"
Arrow,SATD Duplication,"[2017-12-14 02:58:48][seibs][pull:summary][1422]
ARROW-764: [C++] Improves performance of CopyBitmap and adds benchmarks
","[2017-04-03 22:04:01][Wes McKinney][issue:summary][ARROW-764:13061271]
[C++] Improve performance of CopyBitmap, add benchmarks"
Camel,No Relation,"[2020-05-18 13:08:55][Claus Ibsen][commit][f721dec6291e358f694b90d0e78292329aa4e9e8]
CAMEL-15045: Allow to configure route startup logging level. For example if you have 100+ routes it may be annoying with a log per route.
","[2020-05-11 12:12:40][Claus Ibsen][issue:summary][CAMEL-15045:13304102]
Lets allow to configure how much to log and at which logging level. You may want to be verbose on DEBUG level during development, and tone it down for INFO for production."
Hadoop,SATD Duplication,"[2020-07-20 17:09:05][iwasakims][pull:summary][2155]
HADOOP-17138. Fix spotbugs warnings surfaced after upgrade to 4.0.6.
","[2020-07-17 11:04:45][Masatake Iwasaki][issue:summary][HADOOP-17138:13317389]
Fix spotbugs warnings surfaced after upgrade to 4.0.6"
Kafka,SATD Repayment,"[2017-10-04 18:55:46][Ismael Juma][commit][2a1b39ef1b65a4de4f3813bc749458f9fd6a1e38]
MINOR: Simplify log cleaner and fix compiler warnings

- Simplify LogCleaner.cleanSegments and add comment regarding thread
unsafe usage of `LogSegment.append`. This was a result of investigating
KAFKA-4972.
- Fix compiler warnings (in some cases use the fully qualified name as a
workaround for deprecation warnings in import statements).

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Rajini Sivaram <rajinisivaram@googlemail.com>

Closes #4016 from ijuma/simplify-log-cleaner-and-fix-warnings
","[2017-10-04 14:25:44][ijuma][pull:summary][4016]
MINOR: Simplify log cleaner and fix compiler warnings"
Hudi,SATD Repayment,"[2020-08-25 12:40:10][Satish Kotha][code-comment][492ddcbb06e107618ae71fa369ba07af47a036fb]
*
 * TimelineUtils provides a common way to query incremental meta-data changes for a hoodie table.
 *
 * This is useful in multiple places including:
 * 1) HiveSync - this can be used to query partitions that changed since previous sync.
 * 2) Incremental reads - InputFormats can use this API to query
","[2020-08-14 00:14:07][satish][issue:summary][HUDI-1191:13322633]
Create incremental client abstraction to query modified partitions for a timeline.

This can be reused in HiveSync and InputFormats. We also need this as an API for other usecases"
Flink,SATD Repayment,"[2020-03-24 10:44:34][Andrey Zagrebin][commit][813f590f9d92d154ec286377dfc12401aeae1b04]
[FLINK-16225] Improve metaspace out-of-memory error handling thrown in user code

Improve error message, explaining the possible reasons and ways to resolve.
In case of metaspace OOM error, try a graceful TM shutdown.

This closes #11408.
","[2020-03-18 09:28:43][azagrebin][pull:comment][11408:394208538]
I agree, improving the error message of exception should also help here to report more details to the receiver.
It would be nice to figure out a way to handle direct OOM errors from Netty threads in general because Netty also can allocate direct memory. Same for Netty threads in Akka RPC framework. These tasks can be follow-ups."
Incubator Pinot,No Relation,"[2017-08-09 11:44:20][Xiaotian Jiang][commit][ff0a131645f3b32cc955d8eea8ac4aa14bef1a64]
Enhance AggregationGroupByTrimmingService to support trimming on non-comparable intermediate result (#1767)

Currently the following aggregation functions have non-comparable intermediate result:
DistinctCount, DistinctCountHLL, FastHLL, Percentile, PercentileEst
Current trimming service does not work on them, which might cause huge amount of data serialized and transfered to brokers

Implemented a TreeMap based class to support trimming on non-comparable intermediate result
Added a helper Sorter interface and two implementations: ComparableSorter and NonComparableSorter
Also enhanced the test to cover the new code
","[2017-08-09 15:32:38][Jackie-Jiang][pull:comment][1767:132220512]
It's not about overhead. I will try to make them an interface, but that basically means refactoring most of the code... Still, as a private helper class, I don't think that's necessary."
Nifi,No Relation,"[2015-10-25 00:49:58][ricky][commit][f2c4f2d2a15f23edd8933f6dbd10210de1700de3]
[PATCH] NIFI-997 Periodically attempt a kerberos relogin in AbstractHadoopProcessor

 - attempt a relogin based on an interval specified in the processor configuration
 - use hadoop's UserGroupInformation.checkTGTAndReloginFromKeytab to determine if a relogin is necessary based on the ticket and do so if needed
 - improve code readability with HdfsResources object in AbstractHadoopProcessor

Reviewed and Amended by Tony Kurc (tkurc@apache.org). This closes #97
","[2015-10-23 13:48:18][rickysaltzer][pull:comment][97:150578022]
I agree with you on the tuple within a tuple, it is pretty confusing. I'll work on getting these moved into its own class. You're right, error handling is a bit tricky in this area of the code in order to avoid breaking API changes. I did the division by 1000 since the threshold is in seconds, but I could change that. Precision isn't a big deal here since the renewal isn't millisecond (or even second) time sensitive."
Incubator Doris,SATD Repayment,"[2019-09-03 10:42:16][EmmyMiao87][commit][9f5e5717d4aaf184518d8da93b11c2137489fe6d]
Unify the msg of 'Memory exceed limit' (#1737)

The new msg of limit exceed: ""Memory exceed limit. %msg, Backend:%ip, fragment:%id Used:% , Limit:%. xxx"".
This commit unifies the msg of 'Memory exceed limit' such as check_query_state, RETURN_IF_LIMIT_EXCEEDED and LIMIT_EXCEEDED.
","[2019-09-02 12:09:41][EmmyMiao87][pull:summary][1737]
The new msg of limit exceed: ""Memory exceed limit. %msg, Backend:%ip, fragment:%id Used:% , Limit:%. xxx"".
This commit unifies the msg of 'Memory exceed limit' such as check_query_state, RETURN_IF_LIMIT_EXCEEDED and LIMIT_EXCEEDED."
Trafficcontrol,No Relation,"[2019-10-14 07:45:32][ocket8888][code-comment][f2aeec7a92d8e88ec2df7114e8ad5e1ef2d63b98]
 Source has an unknown purpose. I believe this is supposed to name the ""plugin"" that provided
 the data - kept for compatibility with the Perl version(s) of the ""Traffic Stats endpoints"".
 Deprecated: this'll be removed or reworked to make more sense in the future
","[2019-09-26 17:26:35][mhoppa][pull:comment][3758:328735327]
nit but I wonder if you could create a map of duration to seconds and then just index into that instead of using this switch statement could potential do the same for the above function"
Flink,SATD Duplication,"[2014-03-18 22:17:55][Fabian Hueske][code-comment][2c00032ffe8472dbe6d42da3b546424978751b6e]
 TODO: Runtime support required. Each right tuple may be returned only once.
 	     Special exec strategy (runtime + optimizer) based on hash join required. 
 		 Either no duplicates of left side in HT or right tuples removed from HT after first match.
  default join functions
","[2014-03-18 22:17:55][Fabian Hueske][commit][2c00032ffe8472dbe6d42da3b546424978751b6e]
Small step towards semi join. Added semi join functions.
TODO: Special exec strategy (runtime + optimizer) based on hash join required.
      Either no duplicates of filtering side in HT or filtered tuples removed from HT after first match."
Cloudstack,SATD Repayment,"[2013-12-16 18:53:35][Murali Reddy][code-comment][c6c299523151345bbc3c97614c8ac995676e229b]
 Nics with reservation strategy 'Start' should go through release phase in the Nic life cycle.
 Ensure that release is performed before Nic is to be removed to avoid resource leaks.
","[2013-12-16 18:53:35][Murali Reddy][commit][c6c299523151345bbc3c97614c8ac995676e229b]
CLOUDSTACK-4616: When system Vms fail to start when host is down , link
local Ip addresses do not get released resulting in all the link local
Ip addresses being consumed eventually.

fix ensure Nics with reservation strategy 'Start' should go through
release phase in the Nic life cycle so that release is performed before
Nic is removed to avoid resource leaks."
Arrow,No Relation,"[2019-09-09 11:06:06][tianchen][code-comment][e9f35a82fb71577be911822f5b6b0a3815e5ac33]
 using github.com/google/error-prone-javac is required when running on JDK 8
","[2019-08-23 04:53:53][Micah Kornfield][issue:summary][ARROW-6331:13252578]
[Using https://github.com/google/error-prone|https://github.com/google/error-prone] seems like it would be a good idea to automatically catch more errors."
Nifi,No Relation,"[2016-02-02 16:39:30][markap14][pull:comment][200:51594383]
I do agree that it is less code - however, the code is certainly more complex. I will favor code that is more verbose but simpler over code that is concise but complex any day.
","[2016-02-03 01:10:01][Joe Witt][issue:comment][NIFI-865:15129508]
Just looked at 199.patch....   I see copy and paste flume stuff and copy and paste license and notice stuff.  Then I see no real license notice info.  Was I looking at the wrong thing?"
Tvm,SATD Repayment,"[2019-05-27 09:33:13][Sergei Grechanik][commit][8814adab8ab082c8bc232635dd591c6bcdc9ea84]
[ARITH] Improve div/mod in rewrite simplifier (#3149)

* [ARITH] Improve div/mod in rewrite simplifier

* Fix lint error

* Fuller file name in src/arithmetic/modular_set.h

Co-Authored-By: Wei Chen <ipondering.weic@gmail.com>

* Generalize some rules

* Replace gcd factoring with specialized rules

* Mark rules that don't work for non-truncated division

* More tests
","[2019-05-08 14:04:59][sgrechanik-h][pull:summary][3149]
[ARITH] Improve div/mod in rewrite simplifier"
Camel,SATD Repayment,"[2016-01-05 17:38:53][Claus Ibsen][commit][df701cc3776833c98a3e2b53f86dfd8f01eabe4b]
CAMEL-9482: Removed option which has been deprecated for a very long time
","[2016-01-05 16:36:32][Claus Ibsen][issue:summary][CAMEL-9482:12927308]
Remove some old options that has been deprecated forever"
Geode,SATD Duplication,"[2017-01-09 12:06:28][Kirk Lund][code-comment][c30addc26224a2a0897096caa8ae1c410b2e4a04]
 GEODE-2286: need to rewrite with Awaitility and longer timeouts
","[2017-01-09 20:05:27][Kirk Lund][issue:comment][GEODE-2286:15812709]
Need to rewrite this test with Awaitility and longer timeouts."
Incubator Weex,SATD Repayment,"[2017-12-22 15:40:06][Hanks][code-comment(deleted)][8668b0f9ee4c42407c69240542b80dda4729848f]
 Remove old value.
","[2017-12-22 15:40:06][Hanks][commit][8668b0f9ee4c42407c69240542b80dda4729848f]
- [example] remove legacy .we examples

Remove source codes of .we examples, then rebuild the examples, replace the generated bundles in ios and android."
Samza,SATD Repayment,"[2019-06-06 13:33:35][Cameron Lee][commit][38e642d330acc6d08ab1f82580bb712f88ce7b7e]
SAMZA-2197: [Scala cleanup] Convert TaskConfig to Java  (#1039)

* SAMZA-2197: [Scala cleanup] Convert TaskConfig to Java
* moving constants to TaskConfigJava
* renaming TaskConfigJava to TaskConfig and modifying visibility on some constants
* update private method access in TestJobCoordinator
* clean up unused methods in TaskConfig
* update javadocs, use Java Optional, move some defaults to TaskConfig
* post-merge fixes
* test and import fixes
* fix javadoc, clean up if-else check, fix format
","[2019-05-18 00:46:56][cameronlee314][pull:summary][1039]
SAMZA-2197: [Scala cleanup] Convert TaskConfig to Java"
Hadoop,SATD Duplication,"[2019-05-28 17:51:09][xiaoyuyao][pull:summary][866]
HDDS-1604. ContainerReader#initializeUsedBytes leaks DB reference. Co…
","[2019-05-28 17:33:59][Xiaoyu Yao][issue:summary][HDDS-1604:13236055]
ContainerReader#initializeUsedBytes leaks DB reference"
Reef,SATD Repayment,"[2016-09-08 11:51:24][Mariia Mykhailova][commit][fba47fa2cfb605dc7d664ef796e31d87ca9af4ce]
[REEF-1559] Remove unused methods of Exceptions

This change removes methods of Exceptions class which are unused
or used in a single place.

JIRA:
  [REEF-1559](https://issues.apache.org/jira/browse/REEF-1559)

Pull request:
  This closes #1116
","[2016-09-08 17:23:33][tcNickolas][pull:summary][1116]
[REEF-1559] Remove unused methods of Exceptions"
Calcite,No Relation,"[2020-09-04 09:58:49][Julian Hyde][code-comment][850f0f4a04fc2399b8fd1c1fed532cd8e1e39514]
 The conditions in one filter are simplified.
","[2020-09-04 09:58:49][Julian Hyde][commit][850f0f4a04fc2399b8fd1c1fed532cd8e1e39514]
[CALCITE-4173] Add internal SEARCH operator and Sarg literal that represents a set of values or ranges

Obsolete use of IN in RexCall; in Druid, replace some uses
with DRUID_IN operator.

Create Sarg instances during RexSimplify of AND, OR. Also
during simplify, strengthen Sarg.containsNull from true to
false if predicates prove that NULL values are impossible.

In JDBC adapter we handle SEARCH natively, but in Geode,
MongoDB and Spark adapters, expand SEARCH before translating
to target query language. Later, it may be better to handle
SEARCH explicitly. For instance, it will be easier to recognize
expressions that can be translated to Geode's 'IN SET'
construct.

Close apache/calcite#2124"
Beam,SATD Repayment,"[2018-06-18 07:42:09][Kenneth Knowles][code-comment][38e691fb0fb666867f30bf300277e32a6ae6e271]
*
   * Tests that we didn't typo an annotation, that all things we claim to test are real operators.
","[2018-06-18 07:42:09][Kenneth Knowles][commit][38e691fb0fb666867f30bf300277e32a6ae6e271]
Add test that all supported operators are tested"
Incubator Pinot,SATD Repayment,"[2020-05-29 14:08:03][Sidd][commit][b40dd992874f9bc38b911870e041a8f6e24c3776]
Faster bit unpacking (Part 1) (#5409)

* Faster bit unpacking

* Add unit tests

* new

* Improved degree of vectorization and more tests

* fix build

* cleanup

* docs

* change file name

* address review comments and add more benchmarks

Co-authored-by: Siddharth Teotia <steotia@steotia-mn1.linkedin.biz>
","[2020-05-18 22:59:26][siddharthteotia][pull:summary][5409]
Faster vectorized bit unpacking (Part 1)"
Zookeeper,SATD Repayment,"[2018-09-28 14:38:24][Fangmin Lyu][code-comment][fdde8b006458f7b989c894af0eac7e124d271a1e]
*
     * HashSet is used to optimize the iterating, if there is a single 
     * element in this BitHashSet, but the bit is very large, without 
     * HashSet we need to go through all the words before return that 
     * element, which is not efficient.
","[2018-09-23 04:06:03][lvfangmin][pull:comment][590:219687878]
BitSet.get is O(1), check cache doesn't may actually more expensive. 

HashSet is used to optimize the iterating, for example, if there is a single element in this BitHashSet, but the bit is very large, without HashSet we need to go through all the words before return that element, which is not efficient."
Arrow,No Relation,"[2018-02-08 16:21:54][pitrou][pull:comment][1576:364164874]
This required a bit more churn than I expected (especially to get the Cython example and test to work). I think this is ready for review now.
","[2018-02-08 13:28:49][Uwe Korn][issue:comment][ARROW-1021:16356935]
{quote}So, IIUC, 3rd party Cython code is expected to use only the symbols defined as {{cdef public}} in {{lib.pxd}}?
{quote}
Yes.
{quote}Does that reflect the intended idiom for calling into that API?
{quote}
Also yes but until now I have only used that API with {{boost::python}} and {{pybind11}}. I will add that afterwards to the documentation."
Carbondata,SATD Repayment,"[2018-10-19 16:37:27][xubo245][commit][f810389faf5ddf938b40e2c9a7be35d4a12d901e]
[CARBONDATA-3002] Fix some spell error and remove the data after test case finished running

1.fix spell error -- change retrive to retrieve
2.remove the data after test case finished by deleting table and database
3.change dummy table with UUID, avoid error when there are multiple carbonreader

This closes #2811
","[2018-10-11 10:07:14][Bo Xu][issue:summary][CARBONDATA-3002:13190860]
Fix some spell error and remove the data after test case finished running

retrive"
Phoenix,No Relation,"[2014-07-08 21:28:04][Gabriel Reid][code-comment][61c948b73f27c8d563561f5d3ef779742646a450]
 TODO It doesn't seem right to do this selection here, but it's not currently clear
 where a better place is to do it
 For a HashJoin the scan can't be restarted where it left off, so we don't use
 a ChunkedResultIterator
","[2014-07-16 12:48:46][Wei Xue][issue:comment][PHOENIX-539:14063439]
Just a bit of overhead with joins, since the join for the next row will already have been performed before returning to the client. But I guess in real use, the batch size is usually not that small so that the join overhead can be ignored."
Calcite,SATD Repayment,"[2018-08-29 16:50:23][pengzhiwei][code-comment][90f49be639b9a569e3dc4d8369c08e2db64ea301]
 ""f"" is a strong operator, so ""f(operand) IS NULL"" simplifies to
 ""operand IS NULL""
","[2018-08-29 16:50:23][pengzhiwei][commit][90f49be639b9a569e3dc4d8369c08e2db64ea301]
[CALCITE-2469] RexSimplify should optimize '(NOT x) IS NULL' to 'x IS NULL' (pengzhiwei)

Previously it optimized '(NOT x) IS NULL' to 'x IS NOT NULL', which is
wrong.

Generalize the above, to simplify 'f(x) IS NULL' to 'x IS NULL' for any
operator 'f' that is known to be strong. (Julian Hyde)

Close apache/calcite#796"
Hadoop,SATD Duplication,"[2019-09-12 20:45:56][nandakumar131][pull:summary][1435]
After #1423 hdds/ozone no more relies on hadoop parent pom, so we have to use separate checkstyle.xml and suppressions.xml in hdds/ozone projects for checkstyle validation.
","[2019-09-12 15:44:45][Nanda kumar][issue:summary][HDDS-2119:13256386]
After HDDS-2106 hdds/ozone no more relies on hadoop parent pom, so we have to use separate checkstyle.xml and suppressions.xml in hdds/ozone projects for checkstyle validation."
Accumulo,No Relation,"[2015-03-10 16:16:53][Eric C. Newton][code-comment][4635de8671a62f0a412da775db05519f6831daaa]
 locking is confusing, but probably correct
","[2015-03-04 15:30:49][Eric C. Newton][issue:summary][ACCUMULO-3638:12779415]
AccumuloIT always prints this warning when the ""timeout.factor"" is not set."
Lucene Solr,SATD Duplication,"[2009-09-11 13:50:16][Grant Ingersoll][code-comment][70fe60013412e1c99fae638ade23a9d6cf508592]
 XXX note: this should be false, but for now we return true for any field,
 XXX if at least one field uses the reversing
","[2009-09-10 14:18:35][Grant Ingersoll][issue:comment][SOLR-1321:12753631]
Added ASL headers.

I don't understand, in the Test, the comment:
{quote}
// XXX note: this should be false, but for now we return true for any field,
    // XXX if at least one field uses the reversing
    assertTrue(parserThree.getAllowLeadingWildcard());
{quote}

Seems like this needs to be fixed before committing."
Tvm,No Relation,"[2018-09-19 15:55:12][Jared Roesch][code-comment][51fe00fb9015f2f80cfcd3ac0085115b303bf3e3]
 TODO(@jroesch): Restore this code when we finish kind checker.
 if (!check_kind(ret)) {
 std::stringstream ss;
 ss << ""Invalid Kinds in substituted type!"";
 ss << t << std::endl;
 ss << ret << std::endl;
 throw SubstitutionError(ss.str());
 }
","[2018-09-18 16:47:04][tqchen][pull:comment][1672:218509765]
need to document the convention for vargs in the TypeRelation struct"
Bookkeeper,No Relation,"[2017-10-03 12:31:59][Yiming Zang][code-comment][2bbecd7da52824c991e1a28573ccf8c8515ea5dd]
 We need to make sure index file is created, otherwise the test case can be flaky
","[2017-12-21 06:53:09][ivankelly][pull:comment][513:158207157]
So the deadlock is within the same thread? I was under the impression that if you hold a readlock on a thread, you can upgrade it to the writelock without releasing the readlock, but the documentation is telling that this isn't the case. But ok, this isn't the sort of deadlock which involves many interacting threads, so it should be simple enough to fix. This does need to be fixed though. Even if the sequence of events in unlikely, it breaks our guarantees, and once you have exceptions to guarantees, you have no guarantees at all."
Incubator Doris,No Relation,"[2019-09-03 13:52:16][Dayue Gao][code-comment][f76dad289e2823e8a4c92932ffed5d59e02a1b6a]
 `use_cache` is ignored because beta rowset doesn't support fd cache now
 DCHECK(is_inited()) << ""should init() rowset "" << unique_id() << "" before load()"";
 TODO remove the following if block when rowset is guaranteed to be initialized
","[2019-09-02 06:00:38][imay][pull:comment][1718:319814625]
I see all your logs are ERROR level which I think is too high.
I think even there is some error, it only affect only a query, all system can work as usual. And I think the log should not depend on the implementation of the function."
Kylin,SATD Repayment,"[2015-10-13 14:26:52][Li Yang][code-comment][118860ce400454963e48c8383c827f22a6f3e7a9]
 log the stack trace of bad query thread for further analysis
","[2015-10-13 14:26:52][Li Yang][commit][118860ce400454963e48c8383c827f22a6f3e7a9]
minor, log stack trace of bad query thread for further analysis"
Calcite,SATD Duplication,"[2018-11-28 03:52:39][jcamachor][pull:summary][944]
[CALCITE-2713] JDBC adapter may generate casts on PostgreSQL for VARC…
","[2018-11-28 03:22:30][Jesus Camacho Rodriguez][issue:summary][CALCITE-2713:13201004]
JDBC adapter may generate casts on PostgreSQL for VARCHAR type exceeding max length"
Incubator Mxnet,No Relation,"[2016-12-29 01:37:46][Eric Junyuan Xie][commit][e59cb57c3e984c40a0039111ff2c6a91a1877428]
[NNVM] Imperative Invoke (#3208)

* [Engine] Deduplicate Variable Util

* [NNVM] NNVM Imperative Invoke

* [NNVM] Imperative improve speed

* fix

* fix
","[2016-09-02 18:31:18][tqchen][pull:comment][3208:244453711]
We need to measure the time spending on FCompute, I think we can likely get most of the vector space into a threadlocal workspace and avoid most of the space allocations.

I hope we can get < 1ms overhead on this"
Airflow,SATD Repayment,"[2019-06-28 17:01:48][Xiaodong][commit][b30f0fa9f2ef0cf0b00b0cbc047e3e01318becc6]
[AIRFLOW-3935] answer a TODO in airflow/executors/local_executor.py (#4752)

To answer why 'raise e' was commented:
1. This try-except is inside method execute_work() & there are other operations
   after the try-except and after invoking this method.
   Raising exception here will prevent all following steps from taking place.
2. The exception itself is already marked properly by labelling state to be FAILED,
   and the exception is printed out using self.log.error().
","[2019-02-21 14:15:31][XD-DENG][pull:summary][4752]
[AIRFLOW-3935] answer a TODO in airflow/executors/local_executor.py"
Arrow,SATD Duplication,"[2019-12-31 17:55:04][kiszk][pull:summary][6110]
ARROW-7482: [C++] Fix typos
","[2019-12-31 17:49:14][Kazuaki Ishizaki][issue:summary][ARROW-7482:13277039]
[C++] Fix typos"
Hbase,SATD Duplication,"[2019-09-04 07:24:45][chenxu14][pull:summary][581]
When switching pread to stream read, new HFileReaderImpl will be create, but the two different readers do not share informations with each other. maybe we can divide HFileReaderImpl into two different class, such as HFilePreadReader and HFileStreamReader. When constructing HFileStreamReader, it will copy some stuffs (fileInfo, index, etc) from an already existing Reader, and no need to do prefetch operations.
","[2019-08-21 10:47:50][chenxu][issue:summary][HBASE-22888:13252102]
When switching pread to stream read, new HFileReaderImpl will be create, but the two different readers do not share informations with each other. maybe we can divide HFileReaderImpl into two different class, such as HFilePreadReader and HFileStreamReader. When constructing HFileStreamReader, it will copy some stuffs (fileInfo, index, etc) from an already existing Reader, and no need to do prefetch operations."
Arrow,No Relation,"[2019-06-06 02:28:51][Yurui Zhou][code-comment][ec6879b76413c8b28cb810b28fb6e729bfdcbfef]
 Initialize the module id starting value to a number greater than zero
 to allow for easier debugging of uninitialized java variables.
","[2019-05-21 03:33:56][emkornfield][pull:comment][4348:285839406]
i don't know if it is a good idea to hard-code default here."
Beam,No Relation,"[2017-10-31 23:04:32][jkff][pull:comment][3729:148150102]
Rename this one to be more clear as well?
","[2017-03-03 22:20:22][Guy Molinari][issue:comment][BEAM-1542:15895141]
I have created a fork called NextDevBoard and have checked in a very primitive version of this.  The checkstyle plugin is failing the build so I'm running -Dcheckstyle.skip=true until I can fix this.   There is much to do including lots and lots of cleanup.   Split bundles must be implemented for the Source but I wanted to get the Sink working first.   There are custom coders for the spanner Mutation and Struct classes."
Hadoop,No Relation,"[2016-02-02 11:23:00][Colin Patrick Mccabe][commit][dd9ebf6eedfd4ff8b3486eae2a446de6b0c7fa8a]
HDFS-9260. Improve the performance and GC friendliness of NameNode startup and full block reports (Staffan Friberg via cmccabe)
","[2016-01-28 22:24:57][Staffan Friberg][issue:comment][HDFS-9260:15122433]
Thanks for the comments

Patch 15 (and 16) should address all your comments.

I did not change the protected to private as there are some direct access in the two subclasses."
Reef,SATD Repayment,"[2015-05-24 08:32:42][Yingda Chen][commit][5d5771456bae780b4f0781cf6a2e0d75addc5694]
[REEF-277] Remove unused code paths in the C# Driver

This removes traces of a planned, but never executed, full Driver implementation
in C#.

JIRA:
  [REEF-277](https://issues.apache.org/jira/browse/REEF-277)

Pull Request:
  This closes #192
","[2015-05-23 17:57:02][yingdachen][pull:summary][192]
# [REEF-277]: Remove unused code paths in the C# Driver
# This addressed the issue by
# \* Remove unused code paths in the C# Driver
# JIRA: [REEF-277](https://issues.apache.org/jira/browse/REEF-277)"
Iceberg,No Relation,"[2020-04-08 20:20:44][cmathiesen][commit][634e14972f25666b22af9cdab1718eef2831e9e4]
Add Java code examples and update site docs (#678)
","[2019-12-18 20:16:39][rdblue][pull:comment][678:567195712]
Thanks for all of the work on this, @cmathiesen! It looks helpful, although I'd like to make a few changes to make sure it uses best practices."
Incubator Brooklyn,No Relation,"[2013-08-23 10:07:11][Alex Heneveld][code-comment][60e77a7e6ad5bd01adb12cea8da383fef31da04a]
 FIXME change name, due to confusion with brooklyn.location.LocationSpec
","[2013-08-23 10:07:11][Alex Heneveld][commit][60e77a7e6ad5bd01adb12cea8da383fef31da04a]
extend common commands so it can download to stdout; also update some of the Location usages to use specs, simplify that with LocalhostMachineProvisioningLocation.spec(), and create new test for new way of provisioning locations; and finally, restructure SshTasks to be a bit more intuitive"
Hadoop,SATD Duplication,"[2014-08-14 16:08:53][Jason Darrell Lowe][code-comment][3755f527a82dfe593f89d259af528c4a4f155462]
 Files cannot be atomically replaced, therefore we write a temporary
 update file, remove the original token file, then rename the update
 file to the token file. During recovery either the token file will be
 used or if that is missing and an update file is present then the
 update file is used.
","[2014-07-29 21:51:30][Jason Darrell Lowe][issue:comment][MAPREDUCE-6010:14078450]
The previous unit tests didn't catch the update failure because the rename doesn't fail on the local filesystem but does on HDFS.

Attaching a patch that fixes update by removing the destination token file before trying to rename the temporary file to the final token file.  Crashing after the delete but before the rename is handled during recovery since it checks for a temporary update file without a corresponding token file and will use the temporary update file.

Patch also adds an HDFS unit test and a unit test to cover the crash-during-update scenario."
Kafka,No Relation,"[2017-04-26 14:08:57][dguy][pull:comment][2301:113461163]
nit: personal preference so feel free to ignore. But i'd ditch the `else` in this case. I don't think it adds anything
","[2017-08-17 16:40:32][Guozhang Wang][issue:comment][KAFKA-3856:16130788]
Leaving this JIRA open until we have the doc changes in the upgrade guide."
Jena,SATD Repayment,"[2019-03-13 09:14:30][Andy Seaborne][commit][01eec4c45600acef8f2bdac00f984578a9a24452]
Merge pull request #540 from afs/code-clean

JENA-1680: Code formatting jena-dboe-*
","[2019-03-11 12:58:11][Andy Seaborne][issue:summary][JENA-1680:13220839]
The git history is useful in finding when bugs appeared and the lineage 
of a feature. That's the main reason a mass reformatting of code for 
white space or style has a significant impact - it obscures the history 
and some history is very long.

Packages jena-db/jena-dboe-* packages, and maybe jena-db/jena-tdb2, are 
sufficiently new and their history short that it would not be too 
disruptive.

The proposed cleaning is:
* trailing whitespace.
* replace ""space semi-colon"" with ""semi-colon"".
* convert to staggered opening braces
* turn double or more blank lines to single.

See also: [email on dev@|https://lists.apache.org/thread.html/7aff88e1dc22bfb39467fc862e63ca1b88839dc8c69e9dec6ad078bd@%3Cdev.jena.apache.org%3E]."
Systemds,SATD Duplication,"[2020-08-08 20:51:55][Matthias Boehm][code-comment][a4f992ed86d92cff95b160dab0c852b5434bed25]
TODO should remain federated matrix (no need for agg)
","[2020-08-08 20:51:55][Matthias Boehm][commit][a4f992ed86d92cff95b160dab0c852b5434bed25]
[SYSTEMDS-2600] Rework federated runtime backend (framework, ops)

This patch makes a major rework of the exiting federated runtime backend
and operations in order to simplify the joint development of all
remaining federated operations.

The new design has only four command types: read, put, get, exec_inst,
which allows to read federated matrices, put and get variables, and
execute arbitrary instructions over these variables. With this approach,
we can reuse the existing symbol table and CP/Spark instructions and
only need to handle their orchestration and global compensations.
Furthermore, the new design adds several primitives like broadcast,
broadcastSliced, aggregations, and rbind/cbind and more convenient data
structures.

Finally, this patch also includes minor reworks of the execution
context, and reblock rewrite to allow for specific characteristics of
federated execution."
Druid,No Relation,"[2019-07-29 17:06:33][Jonathan Wei][commit][640b7afc1cee911a27de7bf938dda24a85ba1510]
Add CliIndexer process type and initial task runner implementation (#8107)

* Add CliIndexer process type and initial task runner implementation

* Fix HttpRemoteTaskRunnerTest

* Remove batch sanity check on PeonAppenderatorsManager

* Fix paralle index tests

* PR comments

* Adjust Jersey resource logging

* Additional cleanup

* Fix SystemSchemaTest

* Add comment to LocalDataSegmentPusherTest absolute path test

* More PR comments

* Use Server annotated with RemoteChatHandler

* More PR comments

* Checkstyle

* PR comments

* Add task shutdown to stopGracefully

* Small cleanup

* Compile fix

* Address PR comments

* Adjust TaskReportFileWriter and fix nits

* Remove unnecessary closer

* More PR comments

* Minor adjustments

* PR comments

* ThreadingTaskRunner: cancel  task run future not shutdownFuture and remove thread from workitem
","[2019-07-23 07:07:51][clintropolis][pull:comment][8107:306158040]
nit: could you add javadoc links to things like `Appenderator` and other types? I find them handy for easily navigating to things in intellij when I'm reading about how stuff works"
Geode,SATD Repayment,"[2015-07-14 12:25:42][Dan Smith][commit][9fa9ced08f1851f97d2d2407f1519dcc3cac06e0]
GEODE-74: Making the satisfy redundancy phase of rebalance parallel

Tasks submitted to background threads to trigger redundancy
satisfaction. After the satisfy redundancy phase is done we wait for the
tasks to finish.

The number of buckets that can be recovering in parallel is controlled
by the system property gemfire.MAX_PARALLEL_BUCKET_RECOVERIES, currently
set to 8.

If a redundancy recovery/rebalance is restarted due to a membership
change, wait for any in progress operations to complete before fetching
new information from all of the members.
","[2015-07-01 18:54:35][Dan Smith][issue:summary][GEODE-74:12842076]
Recover redundancy in parallel"
Attic Apex Core,SATD Duplication,"[2015-05-12 15:31:49][David Yan][code-comment][e3bfbabbbec64a38ba74cb6dd3b41aa31594b85d]
 hack to ignore JVM warning when loading hadoop native library in stdout and there is no way to disable this warning in JVM
","[2015-05-12 15:31:49][David Yan][commit][e3bfbabbbec64a38ba74cb6dd3b41aa31594b85d]
hack to skip JVM warning when doing CLIProxy"
Trafficserver,No Relation,"[2011-05-13 20:34:34][Leif Hedstrom][code-comment][a5140410ca75846ee6766739cdbdbe75bbd3e56e]
 TODO: I don't think this method is used anywhere, so perhaps get rid of it ?
","[2011-05-13 20:02:12][Leif Hedstrom][issue:summary][TS-776:12507172]
Found a few areas where we can simplify the code, and make it faster at the same time."
Incubator Pinot,SATD Repayment,"[2018-03-11 18:26:14][Subbu Subramaniam][commit][da16c679272bd5b09721d4edc0910dd3a5bb8734]
Issue-2583: Step 1 to support generic streams (#2606)

* Issue-2583: Step 1 to support generic streams

- Create a new package com.linkedin.pinot.core.realtime.stream in pinot-core.
- Move KafkaStreamMetadata to com.linkedin.pinot.core.realtime.stream, renaming it to StreamMetadata
- Get rid of (unused) StreamMetadata
- Move (and rename) classes to be kafka-agnostic (which they are for most parts)
- Add TODO in a couple of places where classes are kafka-specific

* Moved StreamMetadata to different package as suggested in review comment
","[2018-03-09 02:07:06][mcvsubbu][pull:summary][2606]
- Create a new package com.linkedin.pinot.core.realtime.stream in pinot-core.
- Move KafkaStreamMetadata to com.linkedin.pinot.core.realtime.stream, renaming it to StreamMetadata
- Get rid of (unused) StreamMetadata
- Move (and rename) classes to be kafka-agnostic (which they are for most parts)
- Add TODO in a couple of places where classes are kafka-specific"
Incubator Mxnet,No Relation,"[2018-04-04 22:50:56][ashokei][pull:comment][10317:179306524]
got it, thanks! we noticed the same performance issue for smaller networks too (eg: mnist) . Lower OMP_NUM_THREADS (eg: 4 -vs- 36) was giving better performance.
","[2018-04-02 21:03:08][Da Zheng][issue:summary][MXNET-264:13149587]
The current MKLDNN integration still has a lot of overhead for calling MKLDNN functions and the overhead comes from many places. This PR is to reduce the overheads."
Samza,SATD Repayment,"[2017-12-18 16:45:06][Prateek Maheshwari][commit][ea2b6fa915473e2f120a4860c32cd09b4516c283]
SAMZA-1538: Disabled Flaky Tests in TestStreamProcessor

Author: Prateek Maheshwari <pmaheshw@linkedin.com>

Reviewers: Shanthoosh Venkataraman <svenkata@linkedin.com>

Closes #389 from prateekm/disable-flaky-test
","[2017-12-15 19:45:52][prateekm][pull:summary][389]
SAMZA-1538: Disabled Flaky Tests in TestStreamProcessor"
Hbase,SATD Repayment,"[2018-06-14 20:27:04][Sean Busbey][code-comment][b4f463a5cd37fdbcb519effb6153ae06a70c9b7b]
 If we change checkstyle configs, run checkstyle
","[2018-06-14 17:38:55][Sean Busbey][issue:summary][HBASE-20733:13166158]
right now we only do checkstyle tests when java files are altered. we should also run if our checkstyle configs in {{hbase-checkstyle}} are altered."
Flink,No Relation,"[2015-10-07 15:10:55][uce][pull:comment][1153:41402299]
Resolved. I don't think that this a case we have to monitor atm. Removed the TODO.
","[2015-07-14 15:39:37][Ufuk Celebi][issue:comment][FLINK-2354:14626504]
State handle resource clean up needs extra consideration with multiple job manager instances relying on it."
Zookeeper,SATD Duplication,"[2020-10-21 02:50:41][hanm][pull:summary][1511]
ZOOKEEPER-3981: Flaky test MultipleAddressTest::testGetValidAddressWithNotValid
","[2020-10-21 02:49:44][Michael Han][issue:summary][ZOOKEEPER-3981:13336395]
Flaky test MultipleAddressTest::testGetValidAddressWithNotValid"
Nifi,SATD Repayment,"[2019-10-14 11:32:47][Mark Payne][commit][9dd0dda6880ca473b230e5325920834abc213627]
NIFI-6772: Improved the information that is emitted about Garbage Collection when a Diagnostics Dump is performed

This closes #3809
","[2019-10-11 18:08:28][markap14][pull:summary][3809]
NIFI-6772: Improved the information that is emitted about Garbage Col…"
Hadoop,No Relation,"[2018-03-22 14:52:32][Anu Engineer][code-comment][78d94acdced8e04252d0288b495d41371b1fb7b4]
 We cannot call numeric_limits::max() as it conflicts with the
 max() macro on Windows.
","[2017-11-06 17:28:08][Michael Stack][issue:comment][HDFS-7240:16240584]
The posted document needs author, date, and ref to this issue. Can it be made a google doc so can comment inline rather than here?

I skipped to the end, ""So​ ​why​ ​put​ ​the​ ​Ozone​ ​in​ ​HDFS​ ​and​ ​not​ ​keep​ ​it​ ​a​ ​separate​ ​project"". There is no argument here on why Ozone needs to be part of Apache Hadoop. As per [~shv] above, Ozone as separate project does not preclude its being brought in instead as a dependency nor does it dictate the shape of deploy (Bullet #3 is an aspiration, not an argument)."
Hbase,SATD Repayment,"[2019-05-01 01:25:53][Jan Hentschel][code-comment(deleted)][2c7fdb39ce0ad8b5468bd221673b3bfa5e69fcda]
*
   * This is not used any more and does nothing. Use reverse scan instead.
   * @deprecated since 2.0.0 and will be removed in 3.0.0
","[2019-05-01 01:25:53][Jan Hentschel][commit][2c7fdb39ce0ad8b5468bd221673b3bfa5e69fcda]
HBASE-22277 Removed deprecated methods from Get"
Usergrid,No Relation,"[2014-03-31 12:32:47][Rod Simpson][code-comment(deleted)][d5b6c97e35f2aba5caa59ce4a462e5739837fe29]
 Concatenating expressions makes it hard to reason about whether some combination of
 concatenated values are unsafe to use and could easily lead to XSS.  By requiring that a
 single expression be used for iframe[src], object[src], etc., we ensure that the value
 that's used is assigned or constructed by some JS code somewhere that is more testable or
 make it obvious that you bound the value to some user controlled value.  This helps reduce
 the load when auditing for XSS issues.
","[2014-11-04 09:24:36][apps4u][pull:comment][88:61612993]
let me know if It needs more examples I'll still got notification examples to add I just need to create the notification manifest file first I'll try to add that tomorrow."
Calcite,SATD Repayment,"[2019-02-27 10:04:26][Vladimir Sitnikov][commit][ebafff1ede5921901b322872693bf1dbdf09fc8d]
[CALCITE-2878] Avoid use of new RuntimeException(e) in tests

new RuntimeException(e) adds very little info in tests, and it makes stacktraces harder to read.
So it makes sense to just sneaky-throw in those cases, especially for test purposes.
","[2019-02-27 07:03:47][Vladimir Sitnikov][issue:summary][CALCITE-2878:13218272]
{{new RuntimeException(e)}} adds very little info in tests, and it makes stacktraces harder to read.
So it makes sense to just sneaky-throw in those cases, especially for test purposes"
Druid,SATD Duplication,"[2017-07-20 10:14:14][Slim][code-comment][71e7a4c054a055b4b38c323f82eef85226906500]
 no resources to cleanup
","[2017-07-20 17:25:17][gianm][pull:comment][4491:316773709]
Broken in the sense that if you have double columns, SQL stuff won't work right. The UTs are passing since they don't test double columns. But there's code like this:

```java
  public static StringComparator getStringComparatorForSqlTypeName(SqlTypeName sqlTypeName)
  {
    final ValueType valueType = getValueTypeForSqlTypeName(sqlTypeName);
    if (valueType == ValueType.LONG || valueType == ValueType.FLOAT) {
      return StringComparators.NUMERIC;
    } else {
      return StringComparators.LEXICOGRAPHIC;
    }
  }
```

Which needs to get cleaned up since it would lead to wrong results. Probably also this kind of code should be changed to throw an error on unrecognized ValueTypes, in case we add new ones in the future, since errors are better than wrong results."
Arrow,No Relation,"[2016-02-11 00:21:32][Wes McKinney][commit][d35efe214bbd05cfabce42d226e87b725a90d9e9]
PARQUET-497: Decouple serialized file internals from the ParquetFileReader public API

This depends on PARQUET-501. A bit of a refactoring bloodbath, but extremely important to split out these details so that we can instrument the file reader public APIs with test fixtures for unit testing purposes.

Author: Wes McKinney <wes@cloudera.com>

Closes #47 from wesm/PARQUET-497 and squashes the following commits:

aa152ad [Wes McKinney] Decouple Parquet file format details and Thrift metadata from the ParquetFileReader and RowGroupReader public APIs.

Change-Id: Ifc84ba4520517a304f373110cff6a5a43f505d2d
","[2016-02-03 17:59:28][Aliaksei Sandryhaila][issue:comment][PARQUET-497:15130777]
[~wesmckinn] What do you have in mind? ParquetFileReader currently uses FileLike, which does not have to be a file (but it has to have the structure of a whole file, with metadata, data, etc. in the right places)."
Incubator Mxnet,No Relation,"[2019-02-14 11:55:43][Sandeep Krishnamurthy][commit][dad33b51b4a3a05f9bb94f781628494a409e80e4]
Performance improvement in Normalize GPU Kernel (#14139)

* New CPU kernel for normalize

* New GPU kernel for Normalize

* Add launch bounds and increase threads to 32*32

* do not hardcode number of threads

* Try fix windows build failure

* make channels as int to fix windows build issues with omp

* Simplify cuda kernels with 1 D thread block

* Minor refactoring

* Revert thread dim for ToTensor operator
","[2019-02-13 00:05:33][zhreshold][pull:comment][14139:256199591]
nit: I am not a fan of such huge switch block simply for assigning mean and std values"
Flink,SATD Duplication,"[2019-07-24 05:27:18][danny0405][pull:summary][9212]
[FLINK-13338][table-api] Sql conformance is hard to config in TableConfig
","[2019-07-19 14:19:03][Danny Chen][issue:summary][FLINK-13338:13246012]
Sql conformance is hard to config in TableConfig"
Druid,SATD Repayment,"[2014-07-17 21:28:12][fjy][commit][64307766073a16a673d938cbf00ec86c188caf49]
Merge pull request #641 from metamx/cleanup-ingest

some minor cleanups to ingest firehose
","[2014-07-17 20:06:09][fjy][pull:summary][641]
some minor cleanups to ingest firehose"
Hadoop,No Relation,"[2014-01-03 07:26:52][Tsz-wo Sze][code-comment][498f9674ffff414af3d9284cd189b47db444f2de]
*
 * Implementation of CheckpointID used in MR. It contains a reference to an
 * underlying FileSsytem based checkpoint, and various metadata about the
 * cost of checkpoints and other counters. This is sent by the task to the AM
 * to be stored and provided to the next execution of the same task.
","[2014-02-22 22:00:46][Tsz-wo Sze][issue:comment][HDFS-5535:13909553]
> ... RollingUpgrade is a little big change, so does that enough only run unit tests to test it? or you'd already did some manual testing on the dev cluster?

Yes, we will post a test plan which includes manual tests.

> Does this patch based on trunk? I can do some verification on my testing cluster.

The patch does apply to trunk.  It would be great if you could help testing it.  Thank you in advance!"
Incubator Brooklyn,No Relation,"[2012-10-03 04:32:14][ahgittin][code-comment][fdfbfd9dd05860f0f14353a06eebbe08595659dc]
 align user (brooklyn standard) and userName (jclouds standard) fields
 TODO don't default to root --> default later to what jclouds says
","[2012-10-03 04:32:14][ahgittin][commit][fdfbfd9dd05860f0f14353a06eebbe08595659dc]
Merge pull request #332 from ahgittin/feature/jclouds-login-user

jclouds clear loginUser separation and somewhat clearer code; see common-usage.md for full description"
Hadoop,SATD Repayment,"[2017-07-13 10:30:15][Wangda Tan][commit][945c0958bb8df3dd9d5f1467f1216d2e6b0ee3d8]
YARN-6775. CapacityScheduler: Improvements to assignContainers, avoid unnecessary canAssignToUser/Queue calls. (Nathan Roberts via wangda)

Change-Id: I84ccd54200ccbaae23018ef320028e42b4c3509a
","[2017-07-07 16:42:16][Nathan Roberts][issue:summary][YARN-6775:13085555]
There are several things in assignContainers() that are done multiple times even though the result cannot change (canAssignToUser, canAssignToQueue). Add some local caching to take advantage of this fact.

Will post patch shortly. Patch includes a simple throughput test that demonstrates when we have users at their user-limit, the number of NodeUpdateSchedulerEvents we can process can be improved from 13K/sec to 50K/sec."
Arrow,No Relation,"[2020-08-17 18:00:03][bkietz][pull:comment][7819:471664878]
Hmmm, this is a consequence of cpp11 defining the `as_*` conversions in terms of a free function. For now, please add a comment explaining the `#include`'s location. I'll look into a fix for cpp11
","[2020-07-22 15:47:46][Uwe Korn][issue:comment][ARROW-9405:17162900]
Also a nice thing is that seems to be non-GPL which makes the legal state of the R binding in the Apache Foundation world less brittle."
Hadoop,No Relation,"[2016-11-25 22:10:23][Harsh J][commit][07825f2b49384dbec92bfae87ea661cef9ffab49]
HADOOP-1381. The distance between sync blocks in SequenceFiles should be configurable rather than hard coded to 2000 bytes. Contributed by Harsh J.
","[2011-09-03 08:43:05][Harsh J][issue:comment][HADOOP-1381:13096610]
- Fixed the 100 MB mistake. It was supposed to be 100 KB, over multiplied :-)
- Fixed the boxed integer issue. Derived from IntegerOption.
- Removed constructor's internal ports to new API. It was done for unification, yes, unrelated. This new patch directly adds defaults to other constructors, which was unnecessary with the unification approach."
Kafka,No Relation,"[2018-08-31 13:13:42][John Roesler][commit][d57fe1b053546966e6a867d84ee24dd256bb071a]
MINOR: single Jackson serde for PageViewTypedDemo (#5590)

Previously, we depicted creating a Jackson serde for every pojo class, which becomes a burden in practice. There are many ways to avoid this and just have a single serde, so we've decided to model this design choice instead.

Reviewers: Viktor Somogyi <viktorsomogyi@gmail.com>, Bill Bejeck <bill@confluent.io>, Guozhang Wang <wangguoz@gmail.com>
","[2018-08-30 23:01:07][guozhangwang][pull:comment][5590:214205602]
Is this necessary? We do not include sample data production / consumption intentionally across all examples because we document in the tutorials to start these examples as pure streams app only."
Lucene Solr,No Relation,"[2012-08-13 13:52:46][Simon Willnauer][code-comment][23784c63d413ef32e70b207515456f477ef7d3a3]
 ÷ 0041 ÷ 3031 ÷	#  ÷ [0.2] LATIN CAPITAL LETTER A (ALetter) ÷ [999.0] VERTICAL KANA REPEAT MARK (Katakana) ÷ [0.3]
","[2013-02-07 09:49:42][Simon Willnauer][issue:comment][LUCENE-2878:13573353]
Alan, I don't think you can cut over to DocsEnum or DocsAndPositionsEnum. DocsAndPosEnum has a significant problem that doesn't allow efficient PosIterator impl underneath it. It defines that DocsAndPosEnum#nextPosition should be called at max DocsEnum#freq() times which is fine on a low level but bogus for lazy pos iterators since we don't know ahead of time how many intervals we might have. I think we first need to fix this problem before we can go and do this refactoring, makes sense? PhraseQuery does only know his freq currently because it's greedy and pulls all intervals at once."
Drill,SATD Duplication,"[2016-01-05 20:22:38][adeneche][pull:summary][317]
Drill 4236: ExternalSort should use the new allocator functionality to better manage it's memory usage
","[2015-12-30 19:45:01][Abdel Hakim Deneche][issue:summary][DRILL-4236:12924940]
ExternalSort should use the new allocator functionality to better manage it's memory usage"
Hadoop,No Relation,"[2012-08-22 22:11:39][Siddharth Seth][code-comment][01fa1138a35c29da06d9b1d3e7c7c89079e864a2]
 TODO Informing the scheduler is only required if the event came in
 after the scheduler was asked to launch the task. Likely in a subclass.
","[2012-02-29 21:11:46][Ted Yu][issue:comment][MAPREDUCE-3902:13219552]
{code}
+  private void makeContainerReuseDecision() {
+    targetMapContainers = 
+        conf.getInt(MRJobConfig.MR_AM_CONTAINER_REUSE_MAX_CONTAINERS, 
+            numMapTasks);
+  }
{code}
Maybe more logic is going to be added to the above method ?
{code}
+  //        Key->Resource Capability
+  //        Value->ResourceRequest
+  protected final Map<Priority, Map<String, ResourceRequest>>
   remoteRequestsTable =
-      new TreeMap<Priority, Map<String, Map<Resource, ResourceRequest>>>();
+      new HashMap<Priority, Map<String, ResourceRequest>>();
{code}
The comment above doesn't seem to match the Map structure."
Reef,SATD Duplication,"[2015-09-29 22:27:40][tcNickolas][pull:summary][530]
[REEF-528] Add missing Javadoc comments/triage TODO notes in Java code: reef-runtime-local
","[2015-07-29 19:46:09][Mariia Mykhailova][issue:summary][REEF-528:12850037]
Add missing Javadoc comments/triage TODO notes in Java code: reef-runtime-local"
Tinkerpop,SATD Duplication,"[2014-09-22 13:02:30][Stephen Mallette][code-comment][7f2775ab379f0deff0f238af7df314ece7d8f8ff]
 todo: is there a way to get the feature down here so we can just test it directly?
","[2014-09-22 13:02:30][Stephen Mallette][commit][7f2775ab379f0deff0f238af7df314ece7d8f8ff]
Catch UnsupportedOperationException when iterating properties on VertexProperty. #161

Would be better to feature check this.  Trying to do too much for M2 release is looming, but should look into a nicer way than exception catching."
Incubator Pinot,No Relation,"[2019-05-21 20:44:27][Xiaotian (Jackie) Jiang][code-comment][8a0b8ce75474cf4d116a639a61cf107f3375647e]
 TODO: remove the deprecated config keys in the new release
","[2019-05-20 21:21:32][Jackie-Jiang][pull:comment][4222:285773257]
IMO we should not keep unused constants in the code base, it's better to put them in the release log."
Drill,SATD Repayment,"[2015-01-06 15:31:26][norrislee][commit][4304b25e8246970163966e5790231d7ffdbd308f]
DRILL-1498 Drill Client to handle spurious results and handshake messages
","[2014-10-06 16:46:09][Norris Lee][issue:summary][DRILL-1498:12746183]
Drill Client to handle handshake messages in handleRead and to ignore spurious results"
Hadoop,No Relation,"[2011-11-22 11:24:34][Amar Kamat][code-comment][3f09c787810bee568ae5f28306d3fc7ca715ebe2]
TODO Note that the sorter will be instantiated 2 times as follows
       1. During the sort/spill in the map phase
       2. During the merge in the sort phase
 We need the handle to the matcher thread only in (2).
 This logic can be relaxed to run only in (2).
","[2011-09-14 13:08:49][Amar Kamat][issue:summary][MAPREDUCE-3008:12523049]
CPU emulation in Gridmix fails to meet the expected target if the map has no data to sort/spill/merge. There are 2 major reasons for this:
1. The map task end immediately ends soon after the map task. The map progress is 67% while the map phase ends. 
2. Currently, the sort (comparator) doesnt emulate CPU. If the map is short lived, the CPU emulation thread (spawned from the map task in cleanup) doesn't get a chance to emulate."
Lucene Solr,No Relation,"[2019-11-27 16:28:19][Alan Woodward][commit][bed694ec8811c67b8ba4b4c8943e60eda281850a]
LUCENE-9062: QueryVisitor.consumeTermsMatching (#1037)

This commit adds a consumeTermsMatching() method to QueryVisitor, allowing
queries that match against a class of terms to report this back to the visitor. It also
changes highlighting code to use this new method, replacing the current implementation
via instanceof checks.
","[2019-11-25 23:47:29][dsmiley][pull:comment][1037:350480740]
I really like this.  
Obviously this method and public classes etc. will need javadoc but you'll get to that."
Hive,No Relation,"[2013-03-12 17:45:10][Ashutosh Chauhan][code-comment][d27fdcbccd347c2f25b417f8b4b2509630c69df2]
 = ""07A9615F837F7D0A952B595DD3020972"";
 = {0x07,0xA9,0x61,0x5F,0x83,0x7F,0x7D,0x0A,0x95,0x2B,0x59,0x5D,0xD3,0x02,0x09,0x72};
","[2012-11-22 06:51:01][Namit Jain][issue:comment][HIVE-2935:13502613]
I haven't looked at the patch either, and I agree with Ashutosh, that additive portions (like beeline) can be checked in.
However, would it be possible for you to break this patch, and extract the changes that you have made to the current hive code.
That presents a huge risk, and should be reviewed very carefully.

Or, you can take the other approach, which is to check in the new additive isolated components first (which will not be used), and
then have the code which touches the current hive code in a patch.

If someone is not using the hive server, what are the changes that this patch brings in ? That definitely needs to be reviewed very thoroughly."
Tvm,SATD Repayment,"[2019-01-11 10:21:24][Sergei Grechanik][code-comment][547a0913f69c29deb89b38098880d76fbc563f49]
 Note that here we assume that the identity element is indeed identity. Without this
 assumption we would have to perform a single iteration of the loop, i.e. use
 `(*r->combiner.get())(r->combiner->identity_element, r->source)[r->value_index]`
 instead of `r->source[r->value_index]`. The former may be more difficult to simplify.
","[2018-12-17 15:59:30][sgrechanik-h][pull:comment][2284:242205647]
Without this assumption we would have to unroll a single iteration of reduction, i.e. instead of `r->source[r->value_index]` we would write `(*r->combiner.get())(r->combiner->identity_element, r->source)[r->value_index]`. The latter is more difficult to simplify, for example, for `max` the smallest representable number is used as the identity, and the simplifier doesn't seem to know that it is an identity. I'll add something along the lines to the comment."
Lucene Solr,No Relation,"[2014-01-15 19:06:49][Mark Robert Miller][code-comment][a9a9eb48d3beed6b64807e87bcb9e228b08d4821]
 to test uniq fields
","[2013-09-10 23:39:31][Mark Miller][issue:comment][SOLR-1301:13763715]
Here is another patch. No major changes. I've confirmed it has ivy.xml in it.

I made some minor tweaks to fix issues 'precommit' brought up, but it's currently failing on 3 javadoc warnings due to some new hadoop test dependencies:

{noformat}
  [javadoc] /ssd/workspace3/lucene-solr-5x-mr/solr/contrib/solr-mr/lib/hadoop-mapreduce-client-jobclient-2.0.5-alpha-tests.jar(org/apache/hadoop/mapreduce/TestLocalRunner.class): warning: Cannot find annotation method 'timeout()' in type 'Test': class file for org.junit.Test not found
  [javadoc] /ssd/workspace3/lucene-solr-5x-mr/solr/contrib/solr-mr/lib/hadoop-common-2.0.5-alpha-tests.jar(org/apache/hadoop/util/TestClassUtil.class): warning: Cannot find annotation method 'timeout()' in type 'Test'
  [javadoc] /ssd/workspace3/lucene-solr-5x-mr/solr/contrib/solr-mr/lib/hadoop-common-2.0.5-alpha-tests.jar(org/apache/hadoop/io/TestSortedMapWritable.class): warning: Cannot find annotation method 'timeout()' in type 'Test'
{noformat}"
Myfaces Tobago,SATD Repayment,"[2014-03-03 09:53:52][Udo Schnurpfeil][commit][f484375ad421ab4dd7a7a148f7ddbb9324be771f]
TOBAGO-1373: Better JavaScript logging: using browser console and fill browser gaps.
","[2014-03-03 08:33:29][Udo Schnurpfeil][issue:summary][TOBAGO-1373:12698374]
Better JavaScript logging: using browser console and fill browser gaps."
Carbondata,SATD Duplication,"[2018-04-22 05:03:56][ravipesala][pull:summary][2206]
[CARBONDATA-2376] Improve Lucene datamap performance by eliminating blockid while writing and reading index.
","[2018-04-22 05:10:05][Ravindra Pesala][issue:summary][CARBONDATA-2376:13154290]
Improve Lucene datamap performance by eliminating blockid while writing and reading index."
Hbase,SATD Repayment,"[2016-10-21 15:50:39][Ramkrishna][commit][0ae211eb399e5524196d89af8eac1941c8b61b60]
HBASE-16414 Improve performance for RPC encryption with Apache Common
Crypto (Colin Ma)
","[2016-08-15 06:50:39][Colin][issue:summary][HBASE-16414:12997239]
Hbase RPC encryption is enabled by setting “hbase.rpc.protection” to ""privacy"". With the token authentication, it utilized DIGEST-MD5 mechanisms for secure authentication and data protection. For DIGEST-MD5, it uses DES, 3DES or RC4 to do encryption and it is very slow, especially for Scan. This will become the bottleneck of the RPC throughput.
Apache Commons Crypto is a cryptographic library optimized with AES-NI. It provides Java API for both cipher level and Java stream level. Developers can use it to implement high performance AES encryption/decryption with the minimum code and effort. Compare with the current implementation of org.apache.hadoop.hbase.io.crypto.aes.AES, Crypto supports both JCE Cipher and OpenSSL Cipher which is better performance than JCE Cipher. User can configure the cipher type and the default is JCE Cipher."
Drill,SATD Repayment,"[2019-02-08 11:13:22][Paul Rogers][commit][304293a46e66ba27b6b38bbc2fef63743f78d598]
DRILL-7024: Refactor ColumnWriter to simplify type-conversion shim

DRILL-7006 added a type conversion ""shim"" within the row set framework. Basically, we insert a ""shim"" column writer that takes data in one form (String, say), and does reader-specific conversions to a target format (INT, say).

The code works fine, but the shim class ends up needing to override a bunch of methods which it then passes along to the base writer. This PR refactors the code so that the conversion shim is simpler.

closes #1633
","[2019-02-02 03:47:17][Paul Rogers][issue:summary][DRILL-7024:13213450]
Refactor ColumnWriter to simplify type-conversion shim"
Kafka,SATD Duplication,"[2019-10-28 13:38:31][ijuma][pull:summary][7604]
KAFKA-9110: Improve efficiency of disk reads when TLS is enabled
","[2019-10-29 14:41:41][Ismael Juma][issue:summary][KAFKA-9110:13265059]
Improve efficiency of disk reads when TLS is enabled"
Superset,SATD Duplication,"[2019-02-25 16:14:56][Christine Chambers][code-comment][73cdb37f7e88c075e8a143860499b80cf43ba98d]
 This method transforms any BigNumber object in the given payload to its
 64-bit float representation. It is a temporary fix so charts receive
 floats instead of BigNumber instances in their props to properly render.
","[2019-02-25 16:14:56][Christine Chambers][commit][73cdb37f7e88c075e8a143860499b80cf43ba98d]
Fix rendering regression from the introduction of bignumber (#6937)

In superset-ui 0.8.0, we used bignumber.js to transform numbers in chartProps' payload from plain 64-bit floats to BigNumber instances. This causes a number of charts to render incorrectly when comparison functions in the rendering algorithms operate on BigNumber objects instead of floats. This PR uses the preTransformProps step in SuperChart to transform BigNumber instances back to floats so charts can render properly."
Hbase,No Relation,"[2016-04-27 10:41:47][stack][code-comment][6b78409eb259e263354cdd95b6970168219b1464]
 Allocate enough space to fit the next block's header too; saves a seek next time through.
 onDiskBlock is whole block + header + checksums then extra hdrSize to read next header;
 onDiskSizeWithHeader is header, body, and any checksums if present.
 TODO: Make this ByteBuffer-based. Will make it easier to go to HDFS with BBPool (offheap).
","[2016-03-22 05:33:20][Michael Stack][issue:comment][HBASE-15477:15205835]
bq. ....when we have some scans that involves scanning from contiguous blocks.

... and some blocks come from cache and some from HDFS... yeah, we keep the next-blocks length around and save it in cache so we avoid the need to seek the next block header before we can read the next block body.

Yeah, we retain this 'optimization' after all. It is not removed. It is documented on how it provides benefit (Just don't know how much)."
Hadoop,No Relation,"[2011-08-17 22:08:08][Arun Murthy][code-comment][2da287b31209011f27555734c0378ec4cff0e9a3]
 TODO: Reuse FS for user?
","[2011-03-17 17:48:43][Arun Murthy][issue:comment][MAPREDUCE-279:13008030]
Updated patch, adding missing license headers for some files."
Fluo,No Relation,"[2017-12-11 20:08:21][jkosh44][pull:comment][975:350842729]
No problem, happy to help. I think my next step is going through the code and seeing how we can use thenCompose to make the code cleaner like jwonders suggested.
","[2017-12-14 15:10:17][jwonders][issue:comment][978:351738004]
@jkosh44 I'm interested in looking at it.  I probably can't get to it until this weekend rthough.

Hopefully the `AsyncCommitResult` doesn't need to pass much intermediate information between steps.  There is probably a balance between doing everything in-line with `thenCompose(...)` and keeping some of the current structure to make the short-circuiting cleaner and allow for capturing data in the surrounding scope.  The direction I would approach this from was starting with the same structure, introducing `thenCompose(...)` and then trying to refactor to achieve the understandability @keith-turner is looking for."
Lucene Solr,No Relation,"[2012-07-24 12:58:13][Uwe Schindler][commit][6e966079b12caeee1ac8467c7f09e4db00307a5f]
LUCENE-2510: Fix generics and remove Häckidy-Hick-Hack (its not needed here, as names should be unique; we dont have the preflex codec special case)

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/branches/lucene2510@1365026 13f79535-47bb-0310-9956-ffa450edef68
","[2012-05-04 17:40:30][Ryan McKinley][issue:comment][LUCENE-2510:13268565]
The only reason solrj has that dependency is for the deprecated interface:
{code:java}
public interface ResourceLoader extends org.apache.lucene.analysis.util.ResourceLoader 
{code}

I vote we just drop ResourceLoader from the solrj client API at 4.0 rather then 5.0

alternatively, we could put the deprecated interface in solr-core, but that makes a mess of OSGI bundles (i think)"
Druid,SATD Repayment,"[2016-01-19 14:25:48][Himanshu][code-comment][fe841fd96174301dfbf2d49d293ba04764a1acf4]

           Both contains(segment) and remove(segment) can be moved inside the synchronized block. However, in that case,
           each time when addSegment() is called, it has to wait for the lock in order to make progress, which will make
           things slow. Given that in most cases segmentsToDelete.contains(segment) returns false, it will save a lot of
           cost of acquiring lock by doing the ""contains"" check outside the synchronized block.
","[2016-01-05 21:51:50][guobingkun][pull:comment][2118:48901225]
@nishantmonu51 Yeah, contains and remove can definitely be moved inside the synchronized block. However, in that case, each time when `addSegment()` is called, it has to wait for the lock in order to make progress, which will make things slow. Given that in most cases `segmentsToDelete.contains(segment)` returns false, it will save a lot of cost of acquiring lock by doing the ""contains"" check outside the synchronized block."
Cloudstack,SATD Repayment,"[2014-06-12 13:33:21][Brian Federle][code-comment][cd17061916eaf4f93f8dced4bf097035574976d3]
 Cleanup old tab content
","[2014-06-12 13:33:21][Brian Federle][commit][cd17061916eaf4f93f8dced4bf097035574976d3]
Detail view: Cleanup old tab content on change

Add event handler on tab change to remove all old tab content. This prevents
potential conflicts with referencing widget data caused by old content laying
around."
Tvm,SATD Repayment,"[2018-11-19 12:35:15][eqy][commit][7761416f00aed73e93bf919036625fc3f7941cbf]
[WIP] [RPC] clean up uploaded modules (#2121)

 [RPC] clean up uploaded modules
","[2018-11-15 23:32:55][eqy][pull:summary][2121]
 [RPC] clean up uploaded modules"
Calcite,No Relation,"[2020-08-31 17:29:13][julianhyde][pull:comment][2124:480278359]
The line was nowhere near 100 characters. It was a checkstyle bug. Simplest thing is to keep the files ascii.
","[2020-08-31 18:21:49][Julian Hyde][issue:comment][CALCITE-4173:17187930]
[~rubenql], Short answer is no. This change does not give you what you want, or make it any easier to implement."
Arrow,SATD Duplication,"[2019-06-29 00:29:17][trxcllnt][pull:summary][4746]
ARROW-5741: [JS] Make numeric vector from functions consistent with TypedArray.from
","[2019-06-26 15:07:12][Brian Hulette][issue:summary][ARROW-5741:13241731]
[JS] Make numeric vector from functions consistent with TypedArray.from"
Ignite,SATD Duplication,"[2020-11-09 15:00:37][a-polyakov][pull:summary][8441]
IGNITE-13687 Improvement of human-readable format of WAL records (StandaloneWalRecordsIterator)
","[2020-11-09 12:10:28][Alexand Polyakov][issue:summary][IGNITE-13687:13339514]
Improvement of human-readable format of WAL records (StandaloneWalRecordsIterator)"
Arrow,SATD Duplication,"[2019-11-18 13:56:23][fsaintjacques][pull:summary][5857]
ARROW-7148: [C++][Dataset] Major API cleanup
","[2019-11-12 16:25:21][Francois Saint-Jacques][issue:summary][ARROW-7148:13267771]
[C++][Dataset] API cleanup"
Kafka,SATD Duplication,"[2016-04-20 14:09:59][Jason Gustafson][code-comment][c9485b78a6e43747daf1314ae9532839fb7bc810]
 TODO: move connector configuration update handling here to be consistent with
       the semantics of the config backing store
","[2016-03-21 04:36:15][hachikuji][pull:comment][1087:56781916]
This is part of the awkwardness mentioned above. I was reluctant to rewrite StandaloneHerder with the config storage callback semantics. I'll add the TODO for now, but let me know if you'd rather fix it here."
Zookeeper,SATD Duplication,"[2018-09-16 13:02:09][maoling][pull:summary][630]
ZOOKEEPER-2284:LogFormatter and SnapshotFormatter does not handle FileNotFoundException gracefully
","[2015-09-28 18:27:56][Mohammad Arshad][issue:summary][ZOOKEEPER-2284:12901103]
LogFormatter and SnapshotFormatter does not handle FileNotFoundException gracefully"
Incubator Doris,SATD Duplication,"[2020-03-28 09:14:45][frwrdt][code-comment][4a5164ab9d1a4b0ca8e9b8a08f876f22a4a2c500]
 If this property is not set to ""true"", FileSystem instance will be returned from cache
 which is not thread-safe and may cause 'Filesystem closed' exception when it is closed by other thread.
","[2020-03-27 11:09:30][frwrdt][pull:comment][3216:399189773]
If this property is not set to ""true"", FileSystem instance will be returned from cache which is not thread-safe and may cause 'Filesystem closed' exception when it is closed by other thread."
Arrow,SATD Duplication,"[2020-04-07 19:47:55][Krisztián Szűcs][code-comment][e279a7e06e61c14868ca7d71dea795420aea6539]
 ARROW-8213: Opening a dataset with a local incorrect path gives confusing
             error message
","[2020-03-25 15:33:01][Joris Van den Bossche][issue:summary][ARROW-8213:13293851]
[Python][Dataset] Opening a dataset with a local incorrect path gives confusing error message"
Arrow,SATD Repayment,"[2020-04-22 18:04:29][Wes McKinney][commit][7d8c2d32ce9fbc487778e491cb16c7f56dce3067]
ARROW-8512: [C++] Remove unused expression/operator prototype code

None of this code was ever used.

Closes #7013 from wesm/ARROW-8512

Authored-by: Wes McKinney <wesm+git@apache.org>
Signed-off-by: Antoine Pitrou <antoine@python.org>
","[2020-04-22 14:37:54][wesm][pull:summary][7013]
None of this code was ever used."
Lucene Solr,No Relation,"[2010-06-24 09:17:52][Michael McCandless][code-comment][e92a91ed185f0f9be9b136ecade6d5a43f1ae00f]
 coarse -- this overcounts since a given doc can
 have more than one terms:
","[2010-05-11 20:11:33][Michael McCandless][issue:comment][LUCENE-2410:12866305]
Another thing we should fix -- PhraseQuery of a single term should rewrite to TermQuery."
Cassandra,No Relation,"[2014-04-04 15:37:09][belliottsmith][commit][5ebadc11e36749e6479f9aba19406db3aacdaf41]
Ensure safe resource cleanup when replacing SSTables

Patch by belliotsmith; reviewed by Tyler Hobbs for CASSANDRA-6912
","[2014-04-01 22:28:07][Benedict Elliott Smith][issue:comment][CASSANDRA-6912:13957094]
Dagnabit. Good catch - I originally had this bundled up with two other patches, and in separating them I was apparently not as careful as I had thought. The whole of tidy() was scheduled, and I thought I didn't need that after I extracted this (for reasons I won't get into). I'll reintroduce it."
Incubator Mxnet,SATD Repayment,"[2018-01-10 19:13:00][Haibin Lin][commit][a80245d4d1a3005593456f743a34e396b774edbc]
improve memory usage in sparse.dot (#8826)

* improve memory usage in sparse.dot

* rename kernel name. revert changes in embedding op until further benchmark results
","[2017-11-27 07:13:19][eric-haibin-lin][pull:summary][8826]
improve memory usage in sparse.dot"
Hbase,No Relation,"[2017-12-07 14:54:30][anoopsamjohn][code-comment][f8e2323323ef9594d7c898d6d7573966a2fab786]
 TODO We used to set CacheDataInL1 for META table. When we have BucketCache in file mode, now
 the META table data goes to File mode BC only. Test how that affect the system. If too much,
 we have to rethink about adding back the setCacheDataInL1 for META table CFs.
","[2017-12-14 14:10:49][Anoop Sam John][issue:comment][HBASE-19357:16290888]
[~stack] 
Did a perf compare for on heap LRU vs File mode BC for the META only read.  The test just do reads from META table always.  As expected the File is almost half throughput only.  48.5% throughput down.
We do have region locations at connection end cache. So it wont be continuous META read as in this test.  So I feel like we are ok only."
Geode,SATD Repayment,"[2015-07-14 12:25:42][Dan Smith][commit][9fa9ced08f1851f97d2d2407f1519dcc3cac06e0]
GEODE-74: Making the satisfy redundancy phase of rebalance parallel

Tasks submitted to background threads to trigger redundancy
satisfaction. After the satisfy redundancy phase is done we wait for the
tasks to finish.

The number of buckets that can be recovering in parallel is controlled
by the system property gemfire.MAX_PARALLEL_BUCKET_RECOVERIES, currently
set to 8.

If a redundancy recovery/rebalance is restarted due to a membership
change, wait for any in progress operations to complete before fetching
new information from all of the members.
","[2015-07-01 18:54:35][Dan Smith][issue:summary][GEODE-74:12842076]
Recover redundancy in parallel"
Lucene Solr,No Relation,"[2018-12-03 09:07:27][markrmiller][commit][1408f5255fbcde6e843845375349a694f783d247]
SOLR-12801: Disable TimeRoutedAliasUpdateProcessorTest because the feature leaks threads.
","[2018-09-24 16:03:23][Mark Miller][issue:summary][SOLR-12801:13187075]
Fix the tests, remove BadApples and AwaitsFix annotations, improve env for test development."
Lucene Solr,No Relation,"[2014-06-19 16:25:31][Noble Paul][code-comment][42e8c50620a0831e050f75372e17a1d5619d2d6d]
* Create this, passing simplify=true and finite=null, so that we try
   *  to simplify the automaton and determine if it is finite.
","[2014-04-17 21:43:34][Mark Miller][issue:comment][SOLR-5473:13973454]
bq.  I don't see a more appropriate method name for those

I think more appropriate names are something along the lines of Format1 and Format2. There is really no reason to have a single internal/external in the patch as it just adds confusion. And we should also have good javadoc around the format feature and what the differences are between the formats. It should be simple for a new developer to come on and understand what is going on around the format version."
Kafka,No Relation,"[2018-11-15 13:39:18][John Roesler][commit][abc09597db86091c5273348e74be07b63c31a189]
MINOR: Remove redundant SuppressIntegrationTests (#5896)

The removed tests have counterparts covered by SuppressScenarioTest using the TopologyTestDriver.

This will speed up the build and improve stability in the CPU-constrained Jenkins environment.

Reviewers: Bill Bejeck <bill@confluent.io>, Matthias J. Sax <matthias@confluent.io>, Guozhang Wang <wangguoz@gmail.com>
","[2018-11-10 00:15:19][mjsax][pull:comment][5896:437534531]
I personally don't believe that the risk for this particular test is large. It's testing with a single partition and everything is based on event-time.

The only difference I see is, that using `TopologyTestDriver` we flush the `KTable` cache after each records. But this should not impact the test.

Btw: I am wondering, why we don't remove the whole test? The two remaining error scenarios can be tested as unit-test, too, IMHO."
Lucene Solr,No Relation,"[2011-06-10 18:17:44][Steven Rowe][code-comment][c98779dd12cd14c4fd7f6b89c3fde0da14204ad5]

   * TODO: if impls like this are merged we are bound to the amount of memory we
   * can store into a BytesRefHash and therefore how much memory a ByteBlockPool
   * can address. This is currently limited to 2GB. While we could extend that
   * and use 64bit for addressing this still limits us to the existing main
   * memory as all distinct bytes will be loaded up into main memory. We could
   * move the byte[] writing to #finish(int) and store the bytes in sorted
   * order and merge them in a streamed fashion.
","[2011-06-20 12:40:31][Robert Muir][issue:comment][SOLR-2452:13051957]
by the way, obviously since you have been doing all the work here, i don't want you to read this as me questioning/objecting to the change, just trying to maybe help save you some sanity... if you don't mind dealing with the merging I would just say go for it."
Nifi,SATD Duplication,"[2018-07-16 12:41:14][MikeThomsen][pull:summary][2895]
NIFI-5412 Added additional documentation for PutMongo.
","[2018-07-11 15:08:21][Mike Thomsen][issue:summary][NIFI-5412:13171440]
Write additional documentation for PutMongo"
Arrow,No Relation,"[2019-01-02 15:31:02][pitrou][pull:comment][2942:244765908]
I'm curious: do we want to prefix all Gandiva global names at some point? Otherwise they might clash with other names inside the current process? (perhaps it depends on the linkage attributes... but name collisions can lead to obscure problems)
","[2018-11-05 20:53:56][Antoine Pitrou][issue:comment][ARROW-3701:16675746]
LLVM IR is generally not cross-platform, as it will encode platform specificities such as type widths, ABI, etc.
 (see LLVM FAQ at [https://llvm.org/docs/FAQ.html#can-i-compile-c-or-c-code-to-platform-independent-llvm-bitcode])

Perhaps by being extra-careful it's possible to have IR generated for one platform compile and interface correctly on another platform, but it sounds a bit fragile."
Systemds,SATD Repayment,"[2016-05-03 22:55:27][Deron Eriksson][commit][f9d10cfba029a7e2418bc4c0b57b06f2d7495efa]
[SYSTEMML-648] Deprecate castAsScalar

Add castAsScalar deprecation warnings.
Add Expression javadocs.
Remove unused enums from Expression.
Display parse warnings if they occur without parse errors.
Don't chain ParseException in JMLC Connection.

Closes #130.
","[2016-04-27 23:47:47][deroneriksson][pull:summary][130]
Add castAsScalar deprecation warnings.
Add Expression javadocs, rename cast enum values.
Remove unused enums from Expression.
Display parse warnings if they occur without parse errors.
Don't chain ParseException in JMLC Connection."
Hudi,SATD Duplication,"[2019-10-08 18:00:56][leesf][pull:summary][945]
[HUDI-296] Explore use of spotless to auto fix formatting errors
","[2019-10-07 17:52:46][Vinoth Chandar][issue:summary][HUDI-296:13260940]
Explore use of spotless to auto fix formatting errors"
Hbase,No Relation,"[2020-09-19 15:01:05][Bharath Vissapragada][code-comment][9a1d5a02b0040d99273a1e0051816f8928e36ba5]
 clean up.
","[2019-11-22 00:08:06][ndimiduk][pull:comment][830:349379911]
So any znode under `/hbase` shows up or disappears and we re-build the cache? Seems like this would cause a lot of unnecessary ZK chatter. I really wish the meta replica list was under a node of its own."
Pulsar,SATD Repayment,"[2018-12-10 11:09:12][Matteo Merli][code-comment][bddfa2a5a233f17b93cb756b289b40d587321e4c]
*
 * View of a message that exposes the internal direct-memory buffer for more efficient processing.
 *
 * The message needs to be released when the processing is done.
","[2018-12-08 23:00:08][merlimat][pull:summary][3146]
### Motivation

Use ""raw"" message interface when reading messages directly from storage.

The regular `Message` interface exposes only a `byte[]` with the payload and it was meant to be simple. Eg. there is no ref-counting for messages. 

When we are reading from storage directly, we need to take advantage that buffers are coming from direct memory and are already pooled. This will allow to avoid all memory copies and many objects allocation by exposing a lower level message interface, on which the users will need to explicitly call release.

Note: this is a step-gap solution until we have more comprehensive and encapsulated API for direct storage access."
Lucene Solr,No Relation,"[2012-11-23 12:00:32][Alan Woodward][code-comment][930f90fe7aa895acd82aead4fb774dba39430dd6]
 Used to remove duplicate surface forms (but we
 still index the hightest-weight one).  We clear
 this when we see a new analyzed form, so it cannot
 grow unbounded (at most 256 entries):
","[2013-01-20 22:13:28][Alan Woodward][issue:comment][LUCENE-2878:13558405]
So at the moment, IntervalFilterScorer doesn't consume all the intervals on a given document when advancing, it just checks if the document has any matching intervals at all.  Which is great for speed, but bad for scoring - you want to iterate through the intervals on a document to get the within-doc frequency, which can then be passed to the docscorer.  You also need to iterate through everything to deal with payloads.

Is it worth specialising here?  Have two query types (or maybe just a flag on the query), so you can optimize for query speed or for scoring.  SpanScorer always iterates over all spans, by comparison."
Geode,SATD Repayment,"[2020-01-29 13:29:00][mhansonp][commit][11048af21c6e71575af405d23403737a304b8d8d]
GEODE-7600-4: Further cleanup (#4642)

* GEODE-7600-4: Further cleanup
- Cleaning the teardown approach
- Change to wait for event history to be correct.
- Getting rid of a timing issue
- Getting rid of a debug change.
","[2020-01-28 19:40:24][mhansonp][pull:summary][4642]
GEODE-7600-4: Further cleanup"
Cassandra,No Relation,"[2009-06-23 17:48:18][Jonathan Ellis][code-comment][2493c9a5651a72aa4c36ff0f080ee3f6c6978dc8]
 todo can we refactor to take list of sstables?
","[2009-06-09 18:30:53][Jonathan Ellis][issue:summary][CASSANDRA-224:12427482]
All kinds of code needs to know about the inner workings of SSTable to work.  A major cause is passing around SSTable filenames instead of objects.  Thanks to CASSANDRA-208 I feel like I have a good enough understanding of the code here to refactor more than superficially."
Flink,SATD Duplication,"[2019-11-12 11:39:29][wuchong][pull:summary][10160]
[FLINK-14723][table-planner-blink] Improve some code of computed column in planner
","[2019-11-12 11:28:29][Jark Wu][issue:summary][FLINK-14723:13267674]
Improve some code of computed column in planner"
Jena,SATD Duplication,"[2020-09-09 20:02:06][afs][pull:summary][794]
JENA-1960: Clean up Fuseki dispatch
","[2020-09-09 18:34:14][Andy Seaborne][issue:summary][JENA-1960:13326725]
 Clean up Fuseki dispatch"
Hbase,SATD Repayment,"[2013-02-13 18:42:03][Jonathan Hsieh][code-comment][55a44243a93e1138598f17f799ceba3bdb6a6e53]
 If the user has enabled the snapshot, we force the cleaners to be present
 otherwise we still need to check if cleaners are enabled or not and verify
 that there're no snapshot in the .snapshot folder.
","[2012-12-16 12:34:41][Matteo Bertozzi][issue:comment][HBASE-7294:13533372]
Added check at startup to verify if the cleaners are present.

If cleaners are not present, everything is fine unless there're snapshot in the .snapshot folder. Master should not start because otherwise we end up with data loss.

If cleaners are not present in the conf, and there're no snapshot we can still use hbase without the snapshot feature. Any call to snapshot, clone or restore will fail with unsupported exception and the missing cleaner message."
Flink,SATD Duplication,"[2018-05-03 09:26:28][sihuazhou][code-comment][14e7d35f26f51672cb90b63f16f349e6eb846b23]
 TODO: this code assumes that writing a serializer is threadsafe, we should support to
 get a serialized form already at state registration time in the future
","[2018-05-02 11:26:50][StefanRRichter][pull:comment][5934:185465407]
I wonder if this note does not sound a bit to scary, maybe we could just add a todo that this code assumes that writing a serializer is threadsafe and that we could get a serialized form already at state registration time in the future?"
Beam,SATD Repayment,"[2019-09-25 16:13:35][Maximilian Michels][code-comment][948c6fae909685e09d36b23be643182b34c8df25]
 Use a loop here due to the horrible performance of Java Streams:
 https://medium.com/@milan.mimica/slow-like-a-stream-fast-like-a-loop-524f70391182
","[2019-09-24 18:29:03][lukecwik][pull:comment][9374:327769381]
nit: [streams are siginficantly slower than for loops even with JDK 12](https://medium.com/@milan.mimica/slow-like-a-stream-fast-like-a-loop-524f70391182)"
Cxf,No Relation,"[2020-12-07 07:37:53][rmannibucau][pull:comment][721:739732809]
Except ClassGeneratorClassLoader static variables which still look fishy and unexpected - they hide another bug to be concrete like during redeployment of a server with some different config for resource selection - it looks very good for a first mergeable set of changes. I'd just add some doc, maybe some javadoc with a pointer to the doc (if on a wiki/website) to explain how to use it as you did in the test and it is all good for me.
","[2020-10-26 18:50:48][Andriy Redko][issue:comment][CXF-8340:17220930]
Indeed great news, [~dufoli] , would you be open to share to configuration files for native-image creation, it would greatly help us, thank you."
Incubator Pagespeed Ngx,SATD Repayment,"[2014-08-14 11:34:50][Jeff Kaufman][commit][d00911b00f93f75ce1c67690e60b9e925be974a0]
Merge pull request #775 from pagespeed/jefftk-clearer-test-flake-error

testing: make it clearer why test flake in Issue #774 happens
","[2014-08-13 17:53:57][jeffkaufman][pull:summary][775]
testing: make it clearer why test flake in Issue #774 happens"
Beam,No Relation,"[2016-11-15 22:38:05][amitsela][pull:comment][1332:260793013]
This is bad.. Contributors won't run this (I don't want to 😨 ) and so they'll miss checkstyle errors.
","[2016-11-09 10:29:21][Amit Sela][issue:comment][BEAM-891:15650573]
Do we want to ""remove source"" only in case of context reuse ? if so, why not bound it to this condition ?"
Arrow,No Relation,"[2016-06-02 21:07:32][emkornfield][pull:comment][84:223422800]
In the short term yes.   Need to look into see if there are mirrors.   Hopefully people will run these locally, so the code base won't get too messy ...
","[2016-06-01 21:36:28][Wes McKinney][issue:summary][ARROW-209:12974940]
See also PARQUET-626. For now we'll likely have to remove usages of clang-tidy / clang-format from our CI process"
Tinkerpop,No Relation,"[2015-01-12 12:57:44][Marko A. Rodriguez][commit][5dc5ec2905e9413d43d494b2e96c8548e5a461d8]
added until(traversal) and emit(traversal) with the predicate being traversal.hasNext(). Updated the docs with examples and provided a new test case to RepeatTest (though more should be added). Fixed #471.
","[2016-10-21 17:00:49][Marko A. Rodriguez][issue:comment][TINKERPOP-1506:15595686]
So, we could make it so that {{next()}} returns the result from {{hasNext()}}. However, the way {{BranchStep}} is implemented (for which {{ChooseStep}} is a subclass (for which {{optional()}} is implemented with)), the selection traversal is not the same as the branch traversal. Where the former is a ""local child"" and the latter, a ""global child."" Thus, {{optional()}} uses {{clone()}} to get a selection and branch traversal. We could always write an {{OptionalStep}} which would do as you recommend and in fact, this might be the best way forward."
Hudi,SATD Duplication,"[2020-10-01 14:25:29][Mathieu][code-comment][1f7add92916c37b05be270d9c75a9042134ec506]
 TODO(vc): This needs to be revisited
","[2020-09-27 18:18:11][vinothchandar][pull:comment][1827:495599940]
this is a problem. it changes behavior and needs to be reworked."
Myfaces Tobago,SATD Repayment,"[2016-12-14 12:52:06][Udo Schnurpfeil][commit][a8ff2ce7917ab6f5c633c4dce204a8d37a9abe0c]
TOBAGO-1652 Improve code coverage of enums
* add test for TobagoClass - deprecated enums will be ignored
[developed by hnoeth]
","[2016-12-03 07:54:47][Udo Schnurpfeil][issue:summary][TOBAGO-1652:13025307]
Improve code coverage of enums"
Helix,SATD Duplication,"[2020-07-15 13:01:23][Neal Sun][code-comment][c7a97bdce66b21dab5522a4f100d08054ada99c2]
 TODO: We dont need this in the future when TF is not relying on IS/EV anymore.
","[2020-06-23 21:41:50][dasahcc][pull:comment][1076:444525028]
You can mark a TODO here. We dont need it in the future since TF is not relying on IS/EV anymore."
Beam,SATD Repayment,"[2019-11-19 09:39:42][Etienne Chauchot][code-comment][f9ecf1f1ad73f8bcadfb618a51d8931ec7935c83]
 applying a groupByKey avoids for some reason that the spark structured streaming fmwk
 casts data to Row which makes it impossible to deserialize without
 the coder shipped into the data. For performance reasons
 (avoid memory consumption and having to deserialize), we do not ship coder + data.
","[2019-11-19 09:39:42][Etienne Chauchot][commit][f9ecf1f1ad73f8bcadfb618a51d8931ec7935c83]
[BEAM-8470] Apply a groupByKey avoids for some reason that the spark structured streaming fmwk casts data to Row which makes it impossible to deserialize without the coder shipped into the data. For performance reasons (avoid memory consumption and having to deserialize), we do not ship coder + data. Also add a mapparitions before GBK to avoid shuffling"
Lucene Solr,No Relation,"[2011-07-06 21:16:33][Steven Rowe][code-comment][9abc6a2912f97fdd4b3f8150c28c44e24b54a766]
*  Basic tests for TaxonomyWriter. Basically, we test that
    IndexWriter.addCategory works, i.e. returns the expected ordinals
    (this is tested by calling the fillTaxonomy() method above).
    We do not test here that after writing the index can be read -
    this will be done in more tests below.
","[2011-07-08 14:55:21][Robert Muir][issue:comment][SOLR-2452:13061999]
playing around with the branch, the whole situation looks so much better to me.

in my opinion we can then go and make other little improvements, make things faster, add new targets, in separate issues... so I think you should just commit before the patch goes out of date.

maybe we even encounter some serious grief, but I think we should just work thru this in svn.

great work!"
Calcite,No Relation,"[2019-04-17 13:47:06][zabetak][pull:comment][1020:276249367]
Maybe rename readType/writeType to iterateType/forwardType to be slightly more general? The rest of the text should be adapted as needed.
","[2019-01-30 18:48:16][Julian Hyde][issue:comment][CALCITE-2812:16756408]
It's a good start on recursive union, which is by far the most common and useful case for recursive queries. I want to give some thought to the terms ""delta"" (already used in the context of streaming queries), ""table"" (it seems more like a relation than a table), and ""recursive"" (as [~wmoustafa] says, it's more like iterative). And let's figure out how we can make this amenable to extension for other kinds of iterative query (do we need an ""iteration count"" field?)."
Trafficcontrol,No Relation,"[2019-12-19 14:32:43][ocket8888][commit][052f5e9626eff43aaa8d4728fef3d4559252359f]
Rewrote /user/current to Go (#3996)

* Rewrote /user/current to Go

* Update CHANGELOG

* add client method for updating current user

* add client/TO integration testing

* updated documentation

* Added Python client support

* Reworked PUT /user/current to behave like a PATCH

* Added built TO binary to gitignore

* go fmt

* Use API functions to write responses

* Remove unnecessary 'else'

* Changed method name

* fix typo

* simplify return

* Simplified password update

* More verbose parameter name

* JOIN clause now more appropriate for the schema

* relaxed restriction on password confirmation to match Perl
","[2019-11-01 19:28:57][ChrisHines][pull:comment][3996:341720076]
Which ever way you think the code is simpler and most clear. I personally think removing the `else` reduces the cognitive load of reading the code."
Systemds,SATD Duplication,"[2018-07-12 23:48:38][EdgarLGB][code-comment][8def2040be8e9704c8ee8083e8b949ffc0d74927]
TODO Add an additional physical operator which broadcasts the labels directly (broadcast join with features) if certain memory budgets are satisfied
","[2018-07-07 22:44:30][mboehm7][pull:comment][793:200823935]
Add a ToDo for an additional physical operator that broadcasts the labels directly (broadcast join with features) if certain memory budgets are satisfied."
Hive,SATD Repayment,"[2017-03-21 13:55:27][Sergey Shelukhin][code-comment][9f5a3e3d89db7d6f4754eb345ad9abb6997857e1]
 5. Release the copies we made directly to the cleaner.
","[2017-03-21 01:52:55][Sergey Shelukhin][issue:comment][HIVE-16180:15933968]
Simplifying the release logic - we can just remember the buffers in the beginning. Could be simplified even more by removing all the early release."
Kafka,No Relation,"[2017-08-22 23:55:03][hachikuji][pull:comment][3703:134629119]
It would be more concise to just store the config into a `transactionalId` variable and do a null check here.
","[2017-08-19 18:41:55][Jason Gustafson][issue:summary][KAFKA-5755:13096240]
We added a {{LogContext}} object which automatically adds a log prefix to every message written by loggers constructed from it (much like the Logging mixin available in the server code). We use this in the consumer to ensure that messages always contain the consumer group and client ids, which is very helpful when multiple consumers are run on the same instance. We should do something similar for the producer. We should always include the client id, and if one is provided, the transactional id."
Kafka,SATD Repayment,"[2019-09-17 09:46:40][vinoth chandar][code-comment][4962c8193e2faa589914be52962c701aba0980d1]
 If this is a permanent error, then we could spam the log since this is in the run loop. But, other related
 messages show up anyway. So keeping in debug for sake of faster discoverability of problem
","[2019-09-17 09:46:40][vinoth chandar][commit][4962c8193e2faa589914be52962c701aba0980d1]
KAFKA-8839 : Improve streams debug logging (#7258)

* log lock acquistion failures on the state store
* Document required uniqueness of state.dir path
* Move bunch of log calls around task state changes to DEBUG
* More readable log messages during partition assignment

Reviewers: Matthias J. Sax <mjsax@apache.org>, A. Sophie Blee-Goldman <sophie@confluent.io>, Guozhang Wang <wangguoz@gmail.com>"
Camel,SATD Repayment,"[2015-01-20 09:53:59][Claus Ibsen][commit][f7cbecbb43738a94bf37f856868f3685ad65896f]
CAMEL-8195: Add javadoc to model classes so we have EIP documentation out of the box
","[2014-12-30 10:04:09][Claus Ibsen][issue:summary][CAMEL-8195:12764171]
Add javadoc to model classes so we have EIP documentation out of the box"
Carbondata,SATD Duplication,"[2017-04-05 13:45:30][manishgupta88][pull:summary][735]
[CARBONDATA-870] Folders and files not getting cleaned up created locally during data load operation
","[2017-04-05 13:44:54][Manish Gupta][issue:summary][CARBONDATA-870:13061745]
Folders and files which are created in local temp store location during data load and insert into operations are not getting cleaned up. After some time this will lead to filling up of local disk space and eventually will lead to data load failure if threshold limit is reached.
For this all the folders and files created locally need to be deleted once the operation is completed."
Ozone,SATD Duplication,"[2020-11-19 00:58:54][smengcl][pull:summary][1601]
HDDS-4404. Datanode can go OOM when a Recon or SCM Server is very slow in processing reports
","[2020-10-28 17:54:07][Aravindan Vijayan][issue:summary][HDDS-4404:13337718]
Datanode can go OOM when a Recon or SCM Server is very slow in processing reports."
Ozone,SATD Repayment,"[2019-11-19 16:02:16][Doroszlai, Attila][commit][e5a3b0cf0ba9f4ce1c214e4aa31f008f37d4e018]
HDDS-2509. Code cleanup in replication package (#185)
","[2019-11-15 15:30:04][Attila Doroszlai][issue:summary][HDDS-2509:13268599]
Code cleanup in replication package"
Parquet Mr,SATD Duplication,"[2019-01-02 06:50:24][liupc][pull:summary][581]
PARQUET-1485: Fix Snappy direct memory leak
","[2019-01-02 06:33:41][liupengcheng][issue:summary][PARQUET-1485:13207220]
Snappy Decompressor/Compressor may cause direct memory leak"
Lucene Solr,No Relation,"[2016-04-01 12:21:59][markrmiller][commit][ce172acb8fec6c3bbb18837a4d640da6c5aad649]
SOLR-4509: Move to non deprecated HttpClient impl classes to remove stale connection check on every request and move connection lifecycle management towards the client.
","[2016-03-18 15:49:44][Oleg Kalnichevski][issue:comment][SOLR-4509:15201673]
One can override SSL configuration on a per request basis by setting a custom connection socket registry in the HttpContext of the request. 

http://hc.apache.org/httpcomponents-client-4.5.x/httpclient/xref/org/apache/http/impl/conn/DefaultHttpClientConnectionOperator.html#66

This however can potentially lead to SSL connections being re-used by another thread with a different user identity / security context, that is why we do not really advertise this feature.

Oleg"
Cxf,SATD Repayment,"[2017-12-15 12:47:02][Daniel Kulp][commit][97cde56cd73cb03ffb259f01446080fa7748ab8b]
[CXF-7591] Allow getResponseContext().clear() to clear out everything to reduce memory usage
","[2017-12-15 11:21:07][Luca Boncompagni][issue:summary][CXF-7591:13125184]
memory leak in ClientImpl"
Zeppelin,No Relation,"[2019-03-13 21:12:33][felixcheung][pull:comment][3331:265333667]
we can't hardcode the mirror
","[2012-07-22 23:40:58][Hari Mankude][issue:comment][YARN-3:13420366]
Relevant information would be the performance impact of running maps and reduces in cgroups in terms of latency. 

Overall, this would be a very useful feature since it is possible to add fencing around cpu/io resources in addition to memory usage for MR tasks."
Incubator Mxnet,SATD Repayment,"[2018-08-07 05:18:48][Anirudh Subramanian][commit][9dd5edd8e6ec28a97c6ba9bda51b2b9c7a88971b]
Disable flaky cpp test (#12056)
","[2018-08-06 23:10:52][anirudh2290][pull:summary][12056]
## Description ##
Disabling flaky test. Tracking here: https://github.com/apache/incubator-mxnet/issues/11998

## Checklist ##
### Essentials ###
Please feel free to remove inapplicable items for your PR.

- [x] Changes are complete (i.e. I finished coding on this PR)
- [x] All changes have test coverage:
- Unit tests are added for small changes to verify correctness (e.g. adding a new operator)
- Nightly tests are added for complicated/long-running ones (e.g. changing distributed kvstore)
- Build tests will be added for build configuration changes (e.g. adding a new build option with NCCL)
- [x] To the my best knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change

### Changes ###
- [x] Disable test MKLDNNSum"
Arrow,SATD Repayment,"[2020-04-22 18:04:29][Wes McKinney][commit][7d8c2d32ce9fbc487778e491cb16c7f56dce3067]
ARROW-8512: [C++] Remove unused expression/operator prototype code

None of this code was ever used.

Closes #7013 from wesm/ARROW-8512

Authored-by: Wes McKinney <wesm+git@apache.org>
Signed-off-by: Antoine Pitrou <antoine@python.org>
","[2020-04-22 14:37:54][wesm][pull:summary][7013]
None of this code was ever used."
Samza,SATD Repayment,"[2018-06-15 16:27:45][Wei Song][code-comment][42b187a217d5caa882047ca836070f986753a141]
*
 * Utility class to generate metrics that helps to encapsulate required parameters,
 * maintains naming consistency and simplifies metrics creation API for tables.
","[2018-06-15 14:17:19][weisong44][pull:summary][555]
Refactored metrics for table API
 - Added TableMetricsUtil that encapsulates required parameters, maintains naming consistency and simplifies metrics creation API for tables.
 - Added metrics to local table
 - Maintained consistency between local, remote and caching table"
Jena,SATD Duplication,"[2017-02-02 14:20:38][afs][pull:summary][215]
A number of small improvement to the JSON handling code, motivated by working with it in another project.
","[2017-02-08 12:37:59][Andy Seaborne][issue:summary][JENA-1287:13041371]
A number of small improvement to the JSON handling code:

* Ensure multiline output/strings end in NL
* Add to pair(,) to JSONBuilder (c.f. JSWriter)
* Return 'this' for chaining style in JSONBuilder
* JSON.copy, JSON.buildObject

PR#215"
Lucene Solr,No Relation,"[2008-03-05 20:23:36][Grant Ingersoll][code-comment][51f13195005b4df161cc01d8b1de2a60af46d037]
/hmm, is this really the best way to get a newInstance?
","[2007-10-25 21:30:31][Yonik Seeley][issue:comment][SOLR-342:12537738]
> Default is the maxBufferedDocs way, but this could be changed to be the other way around (and probably should be)

+1
ramBufferSizeMB is now the default in Lucene AFAIK.
I think perhaps 32MB might be a good default.

{quote}luceneAutoCommit [...] Still need to develop recommendations for when to change this.{quote}
For Solr, you never would want to use it.  trying to catch a glimpse of new segments as they are flushed leads to an inconsistent view of the index since docs haven't been deleted yet.

We do need to document recommended solrconfig.xml changes in CHANGES.txt (at the top in the migration section we normally have) for people to get these performance gains with existing configs."
Spark,No Relation,"[2019-11-22 15:20:54][Norman Maurer][code-comment][f28eab2de72f7da883b970fc19edd4f569340bd7]
 We do the closing of the stream / channel in handlerRemoved(...) as
 this method will be called in all cases:

     - when the Channel becomes inactive
     - when the handler is removed from the ChannelPipeline
","[2019-11-22 19:03:19][srowen][pull:comment][26609:349747895]
Just checking this is no longer needed because of the new cleanup?"
Lucene Solr,SATD Repayment,"[2016-04-04 12:51:03][Robert Muir][commit][c1a3e1b8d04ffc94e502b086e0544c0e0494d5a8]
LUCENE-7159: Speed up LatLonPoint point-in-polygon performance
","[2016-04-01 02:56:38][Robert Muir][issue:summary][LUCENE-7159:12955174]
improve spatial point/rect vs. polygon performance"
Ignite,SATD Duplication,"[2019-04-16 09:54:58][tledkov-gridgain][pull:summary][6457]
IGNITE-11755 Memory leak H2 connections at the ConnectionManager#deta…
","[2019-04-16 09:09:43][Taras Ledkov][issue:summary][IGNITE-11755:13228295]
Memory leak H2 connections at the ConnectionManager#detachedConns"
Arrow,SATD Repayment,"[2018-10-02 13:55:35][Antoine Pitrou][code-comment][a9787863893a733a8134f61b9e1051c86ff5445c]
 In newlines are not accepted in CSV values, we can simply search for
 the last newline character.
 For common block sizes and CSV row sizes, this avoids reading
 most of the data block, making the chunker extremely fast compared
 to the rest of the CSV reading pipeline.
","[2018-10-02 13:55:35][Antoine Pitrou][commit][a9787863893a733a8134f61b9e1051c86ff5445c]
ARROW-3404: [C++] Make CSV chunker faster

This speeds up multi-threaded CSV reads by removing the serial bottleneck of detecting newlines when no newlines can be present in CSV values.

On this machine (8-core AMD processor), the speed of reading a CSV file of text column data goes from 600 MB/s (before this patch) to 1.2 GB/s.

Author: Antoine Pitrou <antoine@python.org>

Closes #2684 from pitrou/ARROW-3404-faster-csv-chunker and squashes the following commits:

549ef20c5 <Antoine Pitrou> ARROW-3404:  Make CSV chunker faster"
Beam,No Relation,"[2016-07-14 16:41:33][Ben Chambers][commit][2b47919c18d6485c3bb3df8452bd67c940f00d65]
[BEAM-37] DoFnReflector: Add invoker interface and generate code

The method to call for a DoFnWithContext requires reflection since the
shape of the parameters may change. Doing so in each processElement call
puts this refelection in the hot path.

This PR introduces a DoFnInvoker interface which is bound to a specific
DoFnWithContext and delegates the three important methods (startBundle,
processElement, finishBundle).

It uses byte-buddy to generate a simple trampoline implementation of
the DoFnInvoker class for each type of DoFnWithContext.

This leads to 2-3x better performance in micro-benchmarks of method
dispatching.
","[2016-07-15 17:29:50][Ben Chambers][issue:comment][BEAM-37:15379728]
Notes on remaining tasks to complete this:

1. Modify DoFnRunner to allow executing a DoFnWithContext
2. Modify any runner specific code to use DoFnRunner when a DoFnWithContext is received.
3. Remove wrapping of DoFnWithContexts from DataflowRunner (and others) to use the modified code above."
Beam,No Relation,"[2016-08-17 15:43:47][bchambers][code-comment][89367cfb19ae86d66441970277177512961d3b6a]
 Remember the field description of the instrumented type.
","[2016-08-16 03:52:04][bjchambers][pull:comment][812:239994578]
A bunch of nits. I scanned the tests and things seem in order. Are there any of the old tests that you know you removed (it didn't look like it).

Assuming not, once the nits are addressed this LGTM.

I'd like to see these moved into a package related to the reflection -- it would allow us to use package visibility to connect the pieces while using public to control what is visible to the runner/SDK. That can happen in this PR (which introduces the multiple reflection related classes) or a followup."
Lucene Solr,SATD Repayment,"[2016-02-20 01:05:45][Uwe Schindler][commit][0f29b3ec7fd638341915f83384656e72dff868ec]
LUCENE-6989: Make casting to Runnable interface in cleaner hack easier to understand
","[2016-02-19 23:56:05][Uwe Schindler][issue:comment][LUCENE-6989:15155170]
Here is a rewrite of the Java 8 / Lucene 6 code to make it easier to understand (the casting of the Runnable interface).

This helped me to debug the Java 9 b105 issue we have seen today."
Cloudstack,No Relation,"[2016-05-19 20:12:04][Sudhansu][code-comment][18a6aa89bead3c0b321b759570f3de804d6e8105]
 Clean up
","[2016-05-19 20:12:04][Sudhansu][commit][18a6aa89bead3c0b321b759570f3de804d6e8105]
CLOUDSTACK-9366: Capacity of one zone-wide primary storage ignored

introduced new capacityType parameter in updateCapacityState method and necessary changes to add capacity_type clause in sql
also fixed incorrect sql builder logic (unused code path for which it is never surfaced )
Added marvin test to  check host and storagepool capacity when host is disabled
Added conditions to ensure the capacity_type is added only when capacity_type length is greater than 0.
Added checks in marvin test to ensure the capacity exists for a host before disabling it.
Added  checks to avoid index out of range exception"
Tvm,SATD Repayment,"[2020-08-10 08:56:09][lhutton1][commit][fc7a705104fda70f178d5b1070275196abf582cf]
[BYOC][ACL] Improve installation tutorial (#6170)

* [BYOC][ACL] Improve installation tutorial

Improves installation script so that ACL can be built natively and improves tutorial to give clearer information on how ACL can be installed using two different methods.

Change-Id: I6cec98b4b0a7dc2b151b36583d3d28f2b85f8702

* Address comments

Change-Id: I88db6d9d539a8f06e2dfe1b9a0a3ac7a4b46cece
","[2020-07-29 14:39:19][lhutton1][pull:summary][6170]
Improves installation script so that Arm Compute Library (ACL) can be built natively and improves tutorial to give better information on how ACL can be installed using two different methods.

cc @u99127, @leandron, @comaniac"
Beam,No Relation,"[2018-07-13 08:52:39][Ahmet Altay][code-comment][c14c975224af417dcdc74fed8b0d893be742e9d7]
 Dill 0.28.0 renamed dill.dill to dill._dill:
 https://github.com/uqfoundation/dill/commit/f0972ecc7a41d0b8acada6042d557068cac69baa
 TODO: Remove this once Beam depends on dill >= 0.2.8
","[2018-07-10 18:38:16][Barry Hart][issue:comment][BEAM-4752:16539075]
I can work around the problem by doing the following before {{import apache_beam}}.

 
{code:java}
import dill
if not hasattr(dill, 'dill'):
    dill.dill = dill._dill{code}"
Kafka,No Relation,"[2017-01-08 16:15:05][Raghav Kumar Gautam][code-comment][fa80093c067e6684e005bfd548770541b5b2778b]
 hack to copy test dependencies
 this is required for running MiniKDC
","[2016-12-13 04:35:28][ewencp][pull:comment][2197:92096704]
I'd imagine its a bit of a pain to do from a bash script and I wouldn't make it a requirement for this patch, but a nice improvement for the future would be to make the JSON file auto-generated by this file (and in .gitignore) and make the # of nodes configurable. With a beefy docker host and the parallel test runner support, this could make local testing a lot faster."
Camel,SATD Repayment,"[2016-11-07 20:12:06][Tadayoshi Sato][commit][583bec8fb6d5595170d6ab36981d4acdcb9de4c2]
CAMEL-10446 - Need to consolidate header mapping logic between Camel and CXF messages
","[2016-11-05 12:33:49][Tadayoshi Sato][issue:summary][CAMEL-10446:13018595]
Need to consolidate header mapping logic between Camel and CXF messages"
Flink,SATD Repayment,"[2020-10-27 09:01:17][Yuan Mei][code-comment][28d2766766094245cda87c9f0cfb116229be4e77]
 CASE: partialRecordLength < max buffer size,
 partial record ends within the buffer, cleanup successful, skip the partial record
","[2020-10-09 03:22:41][Yuan Mei][issue:summary][FLINK-19547:13334544]
Partial records happen if a record can not fit into one buffer, then the remaining part of the same record is put into the next buffer. Hence partial records only exist at the beginning of a buffer. 

Partial record clean-up is needed in the mode of approximate local recovery. If a record is spanning over multiple buffers, and the first (several) buffers have got lost due to the failure of the receiver task, the remaining data belonging to the same record in transition should be cleaned up."
Samza,SATD Duplication,"[2017-03-31 13:48:35][Navina Ramesh][code-comment][944c70878797a316be0a5be4f4d3ad9238666f3c]
 TODO: Fix in SAMZA-1183
@Test
 TODO: Fix in SAMZA-1183
 @Test
","[2017-03-31 13:48:35][Navina Ramesh][commit][944c70878797a316be0a5be4f4d3ad9238666f3c]
SAMZA-1182 - Commenting out some of the flaky tests

Author: navina <navina@apache.org>

Reviewers: Prateek Maheshwari <pmaheshwari@linkedin.com>, Jagadish Venkataraman <vjagadish1989@gmail.com>

Closes #107 from navina/SAMZA-1182"
Drill,SATD Repayment,"[2018-06-06 09:06:22][Timothy Farkas][commit][e0c39e070bb696d2bc67f60f18559e5a547208ad]
DRILL-6389: Fixed building javadocs
 - Added documentation about how to build javadocs
 - Fixed some of the javadoc warnings

closes #1276
","[2018-05-07 22:49:53][Timothy Farkas][issue:summary][DRILL-6389:13157734]
Javadocs don't build when running

{code}
mvn javadoc:aggregate
{code}

Get the javadocs for all the classes to build. Fix some warnings."
Druid,No Relation,"[2016-10-21 14:57:07][Akash Dwivedi][code-comment][4b3bd8bd630130fb852dfa3054bd9a60d507fd2b]
*
   * Round out Interval such that it becomes granularity-aligned and nonempty.
","[2016-10-18 00:38:51][leventov][pull:comment][3585:254374651]
In IntelliJ, it's easy to fix many formatting errors at once by Ctrl/Cmd+Shift+A, ""run inspection by name"", then find a relevant inspection like ""unused import"" or ""if-else without braces"", run the inspection. It will give a list of inspection violations. Then click the ""resolve all"" button."
Beam,SATD Repayment,"[2017-10-16 17:13:54][Luke Cwik][commit][8ff9c003f407a8db7941a071280e16c603732f92]
[BEAM-3063] Improve VoidCoder structural value to use a single shared instance.

 This closes #4000
","[2017-10-16 21:56:35][lukecwik][pull:summary][4000]
[BEAM-3063] Improve VoidCoder structural value to use a single shared instance."
Hadoop,No Relation,"[2013-04-13 02:13:59][Aaron Myers][code-comment][801b484f9787b7c70e146aa82f9131a9ee473fed]
 There's only enough checksum buffer space available to checksum one
 entire slow read buffer. This saves keeping the number of checksum
 chunks around.
","[2009-10-07 23:26:10][Dhruba Borthakur][issue:comment][HDFS-347:12763300]
I like this approach, but there is one thign that is not very clear in my mind... where is the real bottleneck that we are trying to avoid via this proposed mechanism? It appears that we are trying to avoid copying lots of data via the network interface. Is there any alternate way to reduce this cost, maybe use UDP? change the ethernet MTU size?"
Kafka,No Relation,"[2017-04-25 18:10:49][Matthias J. Sax][commit][f7b7b4745541a576eb0219468263487b07bac959]
KAFKA-5111: Improve internal Task APIs of Streams

 Refactors Task with proper interface methods `init()`, `resume()`, `commit()`, `suspend()`, and `close()`. All other methods for task handling are internal now. This allows to simplify `StreamThread` code, avoid code duplication and allows for easier reasoning of control flow.

Author: Matthias J. Sax <matthias@confluent.io>

Reviewers: Ismael Juma, Damian Guy, Eno Thereska, Guozhang Wang

Closes #2895 from mjsax/kafka-5111-cleanup-task-code
","[2017-04-24 19:34:50][mjsax][pull:comment][2895:113036593]
Yes. Just moved some methods in the third commit to ""cluster"" them a little bit in the code -- right now it's all scattered around the whole file and I have always are hard time to keep an overview (maybe it's just me...)"
Systemds,No Relation,"[2020-06-18 14:16:37][Sebastian][code-comment][cfe52420d091d620ebd2823b5276871aba69734b]
 Events bubbling up the document may have been marked as prevented
 by a handler lower down the tree; reflect the correct value.
","[2020-06-18 14:16:37][Sebastian][commit][cfe52420d091d620ebd2823b5276871aba69734b]
[SYSTEMDS-501] Documentation webpage framework

This commit moves the documentation back to the master branch.
It also clean up the previous documentation (by deleting it).
Such that we have a clean start.

Furthermore this commit, merges back the documentation on master,
into the webpage documentation.

Related PRs: #949 #922

Discussion Mails:
https://tinyurl.com/yal7fd3r
https://preview.tinyurl.com/yal7fd3r"
Incubator Doris,SATD Repayment,"[2019-10-11 23:12:38][kangpinghuang][commit][4678ec8dd939aca10301ff4879edd5399cd11213]
Delete unused log (#1957)
","[2019-10-11 12:09:12][kangpinghuang][pull:summary][1957]
Delete unused log"
Accumulo,No Relation,"[2017-04-06 13:35:33][lstav][pull:comment][242:110162252]
@ctubbsii worked on this better than I can, but he made the change since we no longer have a BasicServlet class.
","[2014-01-11 17:41:11][Arshak Navruzyan][issue:summary][ACCUMULO-2181:12688401]
We can improve the look & feel of monitor by using Twitter's bootstrap (http://getbootstrap.com/2.3.2/getting-started.html#examples)

Adding bootstrap (and getting rid of the html code inside of the java classes) will make it easier to add future functionality like search, tabs, more complex screen layouts, etc."
Geode,No Relation,"[2019-04-03 05:52:39][Jacob Barrett][commit][50dfb33b49584182557bd8ff67132462d8dc8986]
GEODE-6588: Cleanup generics and other static analyzer issues. (#3391)
","[2019-06-04 15:00:46][Jacob Barrett][issue:comment][GEODE-6588:16855800]
[~jackw26] This needs to stay open. It is a long running catch all ticket for cleanups like this."
Drill,SATD Duplication,"[2018-06-18 23:01:52][sohami][pull:summary][1328]
DRILL-6503: Performance improvements in lateral
","[2018-06-15 22:36:12][Sorabh Hamirwasia][issue:summary][DRILL-6503:13166481]
Performance improvements in lateral"
Activemq,No Relation,"[2015-11-04 12:47:57][Timothy Bish][code-comment][82a5839fc733c24cef6e2178b52d8fb649b69879]
*
 * Used to make throwing IOException instances easier.
","[2015-11-04 12:47:57][Timothy Bish][commit][82a5839fc733c24cef6e2178b52d8fb649b69879]
NO-JIRA Update test client to have no real linkage to the activemq
internals to make it easier to share the tests with Artemis."
Lucene Solr,No Relation,"[2020-12-23 12:41:23][Dawid Weiss][code-comment][2d6ad2fee6dfd96388594f4de9b37c037efe8017]
 NOTE: in Java, if you cast a too-large double to long, as we are doing here, then it becomes
 Long.MAX_VALUE
","[2020-12-23 12:41:23][Dawid Weiss][commit][2d6ad2fee6dfd96388594f4de9b37c037efe8017]
LUCENE-9570: code reformatting [partial]."
Flink,SATD Repayment,"[2020-07-30 15:10:12][Jark Wu][commit][f86cb1a53ec524e6468712e793d67e784cb58af8]
[FLINK-18579][jdbc] Remove deprecated classes in flink-connector-jdbc
","[2020-07-13 07:12:38][Jark Wu][issue:summary][FLINK-18579:13316393]
Remove deprecated classes in flink-connector-jdbc"
Drill,No Relation,"[2016-07-18 17:01:24][Aman Sinha][code-comment][4f818d074373f3572cb3c2e99d1c9c43df2090aa]
 DRILL-3917, positive test case for DRILL-4530
","[2016-07-12 22:59:01][jinfengni][pull:comment][519:70537956]
I see the need to remove duplicates and the confusion comes from old code. Is it reasonable to change existing code, and only keep fileSet in all cases? Keep fileName and fileSet seems to be a bit confusing."
Myfaces Tobago,SATD Repayment,"[2016-12-14 12:52:06][Udo Schnurpfeil][commit][a8ff2ce7917ab6f5c633c4dce204a8d37a9abe0c]
TOBAGO-1652 Improve code coverage of enums
* add test for TobagoClass - deprecated enums will be ignored
[developed by hnoeth]
","[2016-12-03 07:54:47][Udo Schnurpfeil][issue:summary][TOBAGO-1652:13025307]
Improve code coverage of enums"
Hadoop,No Relation,"[2014-11-06 20:22:22][Steve Loughran][commit][1670578018b3210d518408530858a869e37b23cb]
YARN-2768 Improved Yarn Registry service record structure (stevel)
","[2015-05-08 21:28:50][Karthik Kambatla][issue:comment][YARN-2768:14535590]
Thanks for working on this, [~zhiguohong]. 

I would like to understand this better. Looking at your profiling output, I see that {{Resources.createResource}} under {{Resources.multiply}} takes about 61 seconds. However, the same call right *after* {{Resources.multiply}} takes 37 milliseconds. The earlier 61 seconds is likely the effect of waiting for GC. Can you repeat this profile a few times so we understand what exactly is going on? Also, it would be nice if we could get the GC stats around the same time."
Beam,SATD Duplication,"[2018-01-10 00:03:13][holdenk][pull:summary][4376]
[BEAM-3444] Fix python3 flake8 errors e999
","[2018-01-09 22:45:48][Holden Karau][issue:summary][BEAM-3444:13129692]
Fix flake8 detected errors E999 (AST compile error)"
Arrow,SATD Repayment,"[2020-04-14 15:13:44][Krisztián Szűcs][commit][b0902ab32f26681c9e99a0b61a5ab5d6d03a20df]
ARROW-8444: [Documentation] Fix spelling errors across the codebase

Quickly run `codespell` which found a couple of misspellings.

Closes #6931 from kszucs/spelling

Authored-by: Krisztián Szűcs <szucs.krisztian@gmail.com>
Signed-off-by: Benjamin Kietzman <bengilgit@gmail.com>
","[2020-04-14 12:35:36][Krisztian Szucs][issue:summary][ARROW-8444:13298261]
[Documentation] Fix spelling errors across the codebase"
Nifi,No Relation,"[2016-11-20 03:50:23][alopresto][pull:comment][1247:88792898]
I know this means ""a user who has access to restricted components"" but the name is slightly misleading.
","[2016-11-17 07:39:36][Pierre Villard][issue:comment][NIFI-3050:15673059]
+1 great discussion

It'll need to be well documented but will provide a better security management.

One question: how the backward compatibility will be ensured? Meaning: what will be the behavior when started NiFi with an existing workflow containing restricted processors? A message like ""insufficient permissions, please contact the administrator""?"
Hive,SATD Duplication,"[2016-11-18 08:17:39][Ferdinand Xu][code-comment][936df7a15a3ce323300cabe7b2ebb90e22f2069d]
TODO
","[2016-09-29 04:59:05][sunchao][pull:comment][104:81065106]
add a TODO?"
Lucene Solr,SATD Repayment,"[2016-04-04 12:51:03][Robert Muir][commit][c1a3e1b8d04ffc94e502b086e0544c0e0494d5a8]
LUCENE-7159: Speed up LatLonPoint point-in-polygon performance
","[2016-04-01 02:56:38][Robert Muir][issue:summary][LUCENE-7159:12955174]
improve spatial point/rect vs. polygon performance"
Tvm,SATD Duplication,"[2020-07-15 15:23:40][Zhao Wu][code-comment][ae4480a37907f6eda602c45bba9632221e4c5646]

 * When we are in the tuning of TVM, we will make TVM occupy
 * the cache fully and doesn't flush it during iteration.
 * This has problems then in e2e testing, since arrays that
 * we assume exist in cache (ie. weights) are evicted during e2e runs,
 * which leads to lower performance.
","[2020-06-24 11:45:20][FrozenGene][pull:summary][5914]
When we are in the tuning of TVM, we will make TVM occupy the cache fully and doesn't flush it during iteration. This has problems then in e2e testing, since arrays that we assume exist in cache (ie. weights) are evicted during e2e runs,
which leads to lower performance. This has been demonstrated in Ansor. 

@merrymercy @tqchen @jcf94 @minminsun"
Fineract,No Relation,"[2020-04-17 19:37:28][Michael Vorburger][commit][059d1bebe700b9f1006af2fdceebf1952c4cba00]
comment out flaky testSavingsAccount_DormancyTracking (FINERACT-852)
","[2020-04-13 18:43:54][Michael Vorburger][issue:comment][FINERACT-852:17082581]
[https://github.com/apache/fineract/pull/761] proposes to {{@Ignore}} the ClientSavingsIntegrationTest > testSavingsAccount_DormancyTracking ... but that PR itself failed, due to:
{code:java}
org.apache.fineract.integrationtests.SchedulerJobsTest > testSchedulerJobs FAILED    java.lang.ArrayIndexOutOfBoundsException at SchedulerJobsTest.java:116 {code}
and in that case, the {{ArrayIndexOutOfBoundsException}} makes a lot more sense now... I'm just very puzzled what could possibly mix up these two tests like that?

Let's first try to ignore this one, without ClientSavingsIntegrationTest, and see if that helps... so proposed in https://github.com/apache/fineract/pull/764."
Incubator Brooklyn,No Relation,"[2014-07-09 22:34:43][Alex Heneveld][code-comment][37d2004fae1ee22cf207f2ff97e1986c36f66d31]
 TODO this may be large when serialized as it includes the context search bundles
","[2014-07-09 22:34:43][Alex Heneveld][commit][37d2004fae1ee22cf207f2ff97e1986c36f66d31]
add BrooklynClassLoadingContext and pass it around when we are instantiating,
fixing BrooklynComponentTemplateResolver.loadEntitySpec to use new loaders from CatalogItem.

currently BCLC does not really pull his weight, as he is just used for instantiation and is never combined or kept;
but as we fix deeper bugs in trying to resolve classes from the purview of another,
i think it will become very useful.

(already it should be the case -- but needs testing -- that BCLC allows children to be resolved WRT
the parent's bundle if they are not declared as catalog items)"
Kafka,No Relation,"[2017-01-03 19:53:20][Ismael Juma][commit][6d6c77a7a9c102f7508e4bc48e0d6eba1fcbc9c6]
MINOR: Improvements to Record related classes (part 1)

Jason recently cleaned things up significantly by consolidating the Message/Record classes
into the common Java code in the clients module. While reviewing that, I noticed a few things
that could be improved a little more. To make reviewing easier, there will be multiple PRs.

Author: Ismael Juma <ismael@juma.me.uk>

Reviewers: Ewen Cheslack-Postava <me@ewencp.org>, Jason Gustafson <jason@confluent.io>

Closes #2271 from ijuma/records-minor-fixes
","[2016-12-31 11:43:00][ijuma][pull:comment][2271:94272499]
I did mention in the PR description that this is still work in progress. :) I've been making some notes while reviewing and included this one in a pushed commit by mistake. The code that was replaced by this one special-cased MagicValue_V0 and it was unclear why that was no longer needed. I'll have more coherent questions when I'm finished with this. :)"
Nifi,No Relation,"[2017-11-01 23:43:07][mattyb149][pull:comment][1662:148413690]
Checkstyle (via the -Pcontrib-check Maven profile) says this is unused, so it should be removed
","[2017-04-10 21:06:35][Dmitry Lukyanov][issue:summary][NIFI-3688:13063007]
The idea is to simplify groovy scripting.
Main targets:
- to be compatible with existing groovy scripting
- simplify read/write attributes
- simplify read/write content
- avoid closure casting to nifi types like `StreamCallback`
- simplify and provide visibility when accessing to controller services from script"
Incubator Pagespeed Ngx,SATD Repayment,"[2013-08-29 09:51:04][Jeff Kaufman][commit][ac7a6bce2cedbf81917ba4717414c94372d2265f]
Merge pull request #498 from pagespeed/jefftk-code-cleanup

code cleanup
","[2013-08-29 13:55:06][jeffkaufman][pull:summary][498]
code cleanup"
Lucene Solr,SATD Repayment,"[2016-04-04 12:51:03][Robert Muir][commit][c1a3e1b8d04ffc94e502b086e0544c0e0494d5a8]
LUCENE-7159: Speed up LatLonPoint point-in-polygon performance
","[2016-04-01 02:56:38][Robert Muir][issue:summary][LUCENE-7159:12955174]
improve spatial point/rect vs. polygon performance"
Samza,No Relation,"[2017-05-24 17:46:12][Navina Ramesh][code-comment(deleted)][7355a45035306443544cf44e557322d9dc5fc0be]
*
 * Interface for a barrier - to allow synchronization between different processors to switch to a newly published
 * JobModel.
","[2017-05-24 20:52:12][navina][pull:comment][195:118361664]
Ah.. This method can be called when the barrier throws any exception. For now, we are not actually handling the errors from the barrier. For example, if there is a duplicate processor, ""join"" will throw an error saying ZkNodeExists. We don't handle it now, but potentially we should be able to handle it later on and cleanly shutdown the processor or handle intelligently. For now, I didn't want to include error handling in ZkBarrier. At least not in the same PR."
Beam,SATD Repayment,"[2016-07-06 04:56:46][Lucas Amorim][code-comment(deleted)][88cc25d76dd769ff0f309010348b94b22f2ff16f]
Inefficient use of keySet iterator instead of entrySet iterator
","[2016-07-06 04:56:46][Lucas Amorim][commit][88cc25d76dd769ff0f309010348b94b22f2ff16f]
[BEAM-405] Fixes inefficient use of keySet iterator instead of entrySet iterator.

BiggQueryIO$StreamingWriteFn.finishBundle: Fixes inefficient use of keySet iterator instead of entrySet iterator."
Kafka,No Relation,"[2018-09-24 13:27:39][John Roesler][code-comment][057c5307e0f055b37794453d16f6f43b8c56528c]
*
     * Use this value to indicate that the test correctness does not depend on any particular number
","[2018-09-21 16:26:53][vvcephei][pull:comment][5567:423594358]
@guozhangwang Thanks for that catch. I failed to add the extra parameter to the javadoc for the second method. The semantics are basically the same. The first one defaults to an unbounded buffer.

In retrospect, this seems like an unnecessary shortcut. I think I'll just ditch the first method and document the buffer config on the second."
Geode,SATD Repayment,"[2017-06-09 10:08:19][Bruce Schuchardt][code-comment(deleted)][3f12fd460b1c34543d56ef4f6844f2b9f56918d5]
 Flaky: GEODE-2542
","[2017-06-09 10:08:19][Bruce Schuchardt][commit][3f12fd460b1c34543d56ef4f6844f2b9f56918d5]
GEODE-2542 LocatorDUnitTest and LocatorUDPSecurityDUnitTest flaky

Removed yet another Flaky annotation from this test class.  Flakiness
was fixed months ago but the Flaky annotations and categorization
weren't removed from the test."
Druid,No Relation,"[2018-11-09 10:55:17][Clint Wylie][commit][c2f020eacc318a0dc5501209922b5b93a17c91fa]
fix druid-bloom-filter thread-safety (#6584)

* use BloomFilter instead of BloomKFilter since the latters test method is not threadsafe

* fix formatting

* style and forbidden api

* remove redundant hive notice entry

* add todo with note to delete copied implementation and link to related hive jira

* better fix for masks than ThreadLocal
","[2018-11-10 00:57:29][Slim Bouguerra][issue:comment][HIVE-20893:16682121]
I did test this locally and added some tests for float case. [^HIVE-20893.patch]

Will run some Benchmark soon on our internal Cluster while tests will run on the patch."
Lucene Solr,No Relation,"[2015-05-22 18:58:29][Erick Erickson][code-comment][375899fdbd3512fc33c5c872c88c244cdf3f7541]
 If the parent reader was correctly fast forwarded, it should be on the third tlog, and the first two should
 have been removed.
","[2015-04-27 10:33:47][Renaud Delbru][issue:comment][SOLR-6273:14513880]
Here is a new patch with the following changes:

- Renamed 'slice' into 'shard'

- Removed an optimisation in the replication of tlog files which could lead to duplicate tlog entries on a slave node. We were trying to avoid transferring tlog files that were already present on the slave nodes in order to reduce network transfer. However, tlog files between the master and slave can differ, overlap, etc. making the comparison difficult to achieve. We removed this optimisation and now during a recovery the tlog replication will transfer all the tlog files from the master to the slave, and replace on the slave node all the existing tlog files."
Systemds,No Relation,"[2020-06-02 22:52:40][Sebastian][commit][02e5c6db0dd5d02416e45874253c59db04151605]
[SYSTEMDS-396] Distinct values count/estimation functions

New function for counting the number of distinct values in a
MatrixBlock. It is using the builtin AggregateInstructions to parse
through hop lop. It can be called to execute with different types of
estimators:

- count : The default implementation that counts by adding to an
hashmap.
  Not memory efficient, but returns exact counts.
- KMV : An estimation algorithm K Minimum Values
- HLL : An estimation algorithm Hyper Log Log (Not finished)

Closes #909.
","[2020-06-01 12:40:36][Baunsgaard][pull:comment][909:433210181]
I had to choose something, and here 64k double values in an Hash Map equates to ~512k memory, which i found fair, and the approximate functions need some bigger number of elements before they begin to really shine.
I have lowered it now to 1k. just like our block sizes, but the effects of this value has to be explored. (there probably is a good trade-off somewhere.)"
Tvm,No Relation,"[2021-01-12 17:34:24][masahi][commit][86479badd125125c9109595e9cb4fed3c099e061]
[Torch] Restore class-aware NMS for detection models by graph rewrite (#7154)

* add a pattern to rewrite nms to batched nms

* update object detection test to add rewrite

* updated tutorial

* add doc

* fixed coord_start

* test fixed by setting force_surpress=False

* revert tutorial change

* add some comment to explain the pattern

* update NMS pattern following frontend change
","[2020-12-23 19:52:10][masahi][pull:comment][7154:548183138]
Yes, the problem is that the model is huge so manually creating the reference is not possible. Programmatically creating a reference requires the same pattern match & rewrite I want to test :)

We have search-and-rewrite, but I think it would also be nice to have search-but-not-rewrite, for use case like this. Just like regex."
Tomee,SATD Repayment,"[2011-12-04 22:51:01][Romain Manni-Bucau][commit][4ab251e4001898c6efea4dccfc08c89d20cf5f00]
avoid to print an ugly exception which is not an error
TOMEE-107: Reduced logging of harmless ""Could not install our singleton service"" message

git-svn-id: https://svn.apache.org/repos/asf/openejb/trunk/openejb@1210266 13f79535-47bb-0310-9956-ffa450edef68
","[2012-01-23 03:17:06][David Blevins][issue:summary][TOMEE-107:12539404]
Reduced logging of harmless ""Could not install our singleton service"" message"
Flink,No Relation,"[2014-03-25 22:10:54][Jonathan][code-comment][cc8e16ebd53500c146dd9826436f983d3f243151]
 excanvas hack
","[2014-03-25 22:10:54][Jonathan][commit][cc8e16ebd53500c146dd9826436f983d3f243151]
Integrated Bootstrap in the User Interface and made some improvements and code clean ups."
Incubator Pinot,SATD Repayment,"[2019-07-29 20:25:30][Xiaotian (Jackie) Jiang][code-comment][c768df89ef52e80df1595a98721fdf364f37bfad]
 NOTE: preserve 10% buffer for cardinality to reduce the chance of re-sizing the dictionary
","[2019-06-25 03:24:29][Jackie-Jiang][pull:summary][4363]
The current off-heap mutable dictionary is designed to hold all values in a single buffer
If the buffer allocated is just enough for the cardinality estimation, there are quite high possibility that the dictionary needs to be expanded, which will impact performance
In order to reduce the chance of re-sizing the dictionary, preserve 10% buffer for cardinality"
Arrow,SATD Duplication,"[2020-05-28 17:14:45][lidavidm][pull:summary][7298]
ARROW-8975: [FlightRPC][C++] try to fix MacOS flaky tests
","[2020-05-28 13:31:43][David Li][issue:summary][ARROW-8975:13308043]
[FlightRPC][C++] Fix flaky MacOS tests"
Hbase,No Relation,"[2013-03-28 13:53:13][David S. Wang][code-comment][e645a6a6d87fdf4a0e118c48de28811c8518a7bd]
 add a named command to the table instance

 name - name of the command that should added to the table
    (eg. sending 'scan' here would allow you to do table.scan)
 shell_command - name of the command in the shell
 internal_method_name - name of the method in the shell command to forward the call
","[2012-03-21 17:54:58][Jesse Yates][issue:comment][HBASE-5548:13234594]
Waiting on your comments as to if you liked the design of the current patch, with the addition of the table methods via class-reopening and with the internal vs external method stuff, etc. If you are happy, then I'll do the rest of the table commands (put, get, etc.) in the same style and throw a patch up on RB tonight so everyone gets a chance to look."
Lucene Solr,No Relation,"[2020-03-02 22:31:45][dsmiley][pull:comment][1303:593657932]
Why a separate PR for my proposed test?

Your proposal is better than the status quo but I think is rather lacking if that's it.  If your proposal can also accommodate a query-time user supplied cost, especially by FunctionRangeQuery somehow, then I think we're then in good shape as it'll allow a user to set this on the fly.  (BTW ignore the identical named class in Solr, which I plan on removing).  Perhaps this cost could sneak in by putting the cost on the ""context"" Map supplied to ValueSource.getValues ?  Yeah; that'd be cool :-)
","[2020-02-28 20:23:06][David Smiley][issue:comment][LUCENE-9114:17047928]
If this is too time-consuming, we could reduce the scope to merely make the cost settable by a query parser (this issue not touching any query parser, however).  That's the minimum I need to unblock using the costs on the Solr side (it's QParsers), which I want to do after this."
Spark,SATD Repayment,"[2018-01-17 09:27:49][Sameer Agarwal][commit][c132538a164cd8b55dbd7e8ffdc0c0782a0b588c]
[SPARK-23020] Ignore Flaky Test: SparkLauncherSuite.testInProcessLauncher

## What changes were proposed in this pull request?

Temporarily ignoring flaky test `SparkLauncherSuite.testInProcessLauncher` to de-flake the builds. This should be re-enabled when SPARK-23020 is merged.

## How was this patch tested?

N/A (Test Only Change)

Author: Sameer Agarwal <sameerag@apache.org>

Closes #20291 from sameeragarwal/disable-test-2.
","[2018-01-17 08:19:16][sameeragarwal][pull:summary][20291]
## What changes were proposed in this pull request?

Temporarily ignoring flaky test `SparkLauncherSuite.testInProcessLauncher` to de-flake the builds. This should be re-enabled when SPARK-23020 is merged.

## How was this patch tested?

N/A (Test Only Change)"
Nifi Minifi Cpp,No Relation,"[2017-11-13 20:47:11][Marc Parisi][code-comment][c0a788b3539da254265f7a74b99289bdbc71af03]
 setting this m_TempHeaderExtension because adjustOptionsTrailer() may extend or shorten the layer and the extend or shorten methods need to know the accurate
 current size of the header. m_TempHeaderExtension will be added to the length extracted from getIPv4Header()->internetHeaderLength as the temp new size
","[2017-11-14 01:10:43][apiri][pull:comment][170:344112486]
@phrocker build and code looked good.  Was able to verify functionality in Linux and OS X.

I don't believe I saw any updates to the LICENSE to incorporate the library addition.  Could we also look to trim the extraneous files from the library that are going unused.

Otherwise, looks good to go."
Flink,SATD Repayment,"[2019-11-06 23:54:37][Hwanju Kim][commit][155885cc6d182bf0f6519a9992b21b957444b4fe]
[FLINK-14589] Redundant slot requests with the same AllocationID leads to inconsistent slot table

When a slot request is redundantly made with the same AllocationID to a
slot index other than the already allocated one, slot table becomes
inconsistent having two slot indices allocated but one AllocationID
assigned to only the latest slot index. This can lead to slot leakage.
This patch prevents such redundent slot request from rendering
inconsistent slot allocation state by rejecting the request.

This closes #10099.
","[2019-11-06 07:44:08][hwanju][pull:summary][10099]
[FLINK-14589] [Runtime/Coordination] Redundant slot requests with the same AllocationID lead…"
Ignite,No Relation,"[2018-06-11 10:53:22][Sunny Chan][code-comment][2021942c9972c8a4fb7118fd57f422f87c579ff3]
emulating additional page writes to be sure log message is generated
","[2017-08-07 14:06:40][Sergey Chugunov][issue:summary][IGNITE-5960:13092885]
Ignite Continuous Query (Queries 3): CacheContinuousQueryConcurrentPartitionUpdateTest::testConcurrentUpdatesAndQueryStartAtomic is flaky"
Hive,SATD Duplication,"[2015-11-03 11:24:58][Pengcheng Xiong][code-comment][7073ce3244f62ff8c41ae83dbafb4465ad0567e9]
 The following check is only a guard against failures.
 TODO: Knowing which expr is constant in GBY's aggregation function
 arguments could be better done using Metadata provider of Calcite.
","[2015-11-02 22:04:57][Ashutosh Chauhan][issue:comment][HIVE-12305:14986144]
Fix in this patch is a guard against failures, but knowing which expr is constant in GBY's aggregation function arguments could be better done using Metadata provider of Calcite. It will be good to add a #TODO in comment for this. 
+1 LGTM"
Nifi,No Relation,"[2015-01-30 22:41:52][joewitt][code-comment][8cd461e276872f56951b5f660732a8fe229ee5ad]
*
     * Initialize the details for the source funnel.
     * 
     * @argument {string} groupId               The id of the current group
     * @argument {string} groupName             The name of the current group
     * @argument {object} destination            The destination of the connection
","[2015-01-16 12:25:57][Benson Margulies][issue:summary][NIFI-270:12768002]
Get version numbers, pom config, whatever, ready for release of the maven plugin. Some cleanup for releasing the rest might also occur."
Kafka,No Relation,"[2017-08-25 10:23:11][Jason Gustafson][commit][c4d629a0b3cbd11c174cb8b09a50bc8de77825e9]
MINOR: Consolidate broker request/response handling

This patch contains a few small improvements to make request/response handling more consistent. Primarily it consolidates request/response serialization logic so that `SaslServerAuthenticator` and `KafkaApis` follow the same path. It also reduces the amount of custom logic needed to handle unsupported versions of the ApiVersions requests.

Author: Jason Gustafson <jason@confluent.io>

Reviewers: Ismael Juma <ismael@juma.me.uk>

Closes #3673 from hachikuji/consolidate-response-handling
","[2017-08-24 16:05:55][hachikuji][pull:comment][3673:135059206]
I used that name initially, but since it is invoked from `KafkaRequestHandler`, which is also responsible for receiving the shutdown request, it seemed clearer with this name."
Calcite,No Relation,"[2020-06-15 05:06:24][amaliujia][pull:comment][2025:643904684]
@bozzzzo I am using similar idea now in this PR (not hardcode UNNEST check anymore).
","[2020-05-30 19:52:39][Rui Wang][issue:summary][CALCITE-4033:13308523]
Unparser should not apply parentheses for UNNEST (as a built-in table operator)"
Cloudstack,SATD Repayment,"[2013-01-30 15:21:01][Kelven Yang][code-comment(deleted)][da2e6461a681f428a6db933eb3cc77df36a1ef39]
 Servlet injection does not always work for servlet container
 We use a hacking here to initialize static variables at Spring wiring time
","[2013-01-30 15:21:01][Kelven Yang][commit][da2e6461a681f428a6db933eb3cc77df36a1ef39]
Remove temporary hacking and use Official way to wire-up servlet with injection under Spring"
Hbase,SATD Repayment,"[2017-12-14 15:59:41][zhangduo][commit][7466e64abb2c68c8a0f40f6051e4b5bf550e69bd]
HBASE-19510 TestDistributedLogSplitting is flakey for AsyncFSWAL
","[2017-12-14 02:33:36][Duo Zhang][issue:summary][HBASE-19510:13124863]
TestDistributedLogSplitting is flakey for AsyncFSWAL"
Lucene Solr,SATD Duplication,"[2015-06-09 20:15:21][Michael McCandless][code-comment][1789048472520c0ae1d3380ba832bd4854488c0f]
 TODO: in the future (7.0?  sigh) we can use this to throw IndexFormatTooOldException ... or just rely on the
 minSegmentLuceneVersion check instead:
","[2015-06-04 14:32:43][Robert Muir][issue:comment][LUCENE-5954:14572876]
{code}
if (format >= VERSION_53) {
  // TODO: in the future (7.0?  sigh) we can use this to throw IndexFormatTooOldException ... or just rely on the
  // minSegmentLuceneVersion check instead:
  infos.luceneVersion = Version.fromBits(input.readVInt(), input.readVInt(), input.readVInt());
} else {
  // else leave null
}
{code}

I guess I was hoping we could take it further. We dont technically need to change file formats to implement this, it could be computed from the segments on read in the 4.0-5.2 case? Its just the min() that it finds there. Or does this become too hairy?"
Kafka,No Relation,"[2018-03-16 16:02:11][Matthias J. Sax][code-comment][394aa7426117d0d04666c1c2a63d5f98229b7894]
 TODO when we remove this method, we can also remove `ProcessorNode#children`
","[2018-03-11 19:36:59][guozhangwang][pull:comment][4519:173666579]
Do we still need `children` above, could we use `childByName.values` to replace it? Generally speaking having two structures that always need to be updated means unnecessary maintenance cost./"
Pulsar,SATD Duplication,"[2018-12-17 21:54:10][Boyang Jerry Peng][code-comment][1414edd322c364152e9d5c47a9dad8b469fe5977]
 Cannot use latest version of prometheus client because of thread leak
 prometheus_client.start_http_server(args.metrics_port)
 Use patched version of prometheus
 Contains fix from https://github.com/prometheus/client_python/pull/356
 This can be removed one the fix in is a official prometheus client release
","[2018-12-17 21:54:10][Boyang Jerry Peng][commit][1414edd322c364152e9d5c47a9dad8b469fe5977]
Path prometheus python client due to thread leak (#3206)"
Kafka,SATD Repayment,"[2019-08-11 11:44:30][Lucas Bradstreet][commit][35ed7b14cc8f943b4fbc9945a93eecbff7b72ab2]
MINOR: Eliminate unnecessary map operations in RecordAccumulator.isMuted (#7193)

Avoids calling both `containsKey` and `get` from isMuted, when only a single get is necessary.
Also avoid calling `remove` unless necessary. This could be a reduction of map operations
from 3 to 1. 

isMuted showed up as a hotspot in profiling when using the producer with high numbers of partitions.

Reviewers: Ismael Juma <ismael@juma.me.uk>
","[2019-08-11 05:37:15][lbradstreet][pull:summary][7193]
Avoids calling both `containsKey` and `get` from isMuted, when only a single get is necessary.
Also avoid calling `remove` unless necessary. This could be a reduction of map operations
from 3 to 1. 

isMuted showed up as a hotspot in profiling when using the producer with high numbers of partitions."
Camel,SATD Repayment,"[2015-05-13 15:06:51][Willem Jiang][code-comment][a86f22b6ba400946f120f0c7c977bc39fbfa9e66]
 NOTE: if we don't specify the MaxChannelMemorySize and MaxTotalMemorySize, the thread pool
 could eat up all the heap memory when the tasks are added very fast
","[2015-05-13 06:49:47][Willem Jiang][issue:summary][CAMEL-8771:12829470]
if we don't specify the MaxChannelMemorySize and MaxTotalMemorySize, the OrderedMemoryAwareThreadPoolExecutor could eat up all the heap memory when the tasks are added very fast"
Incubator Brooklyn,SATD Repayment,"[2013-01-28 17:27:45][Aled Sage][code-comment][03cc7b6dd7f656c23d0a64c3c2df563d83480200]
 In jenkins for things like testRepeatedResizeUpStabilizationDelayTakesMaxSustainedDesired, which runs
 a time-sensitive test 100 times, it fails periodically due to things taking too long. This is most
 likely caused by a full (slow) GC kicking in during the test.

 By GC'ing here, we attempt to avoid a GC in the middle of the time-sensitive test
","[2013-01-28 17:27:45][Aled Sage][commit][03cc7b6dd7f656c23d0a64c3c2df563d83480200]
AutoScalerPolicyTest repeated test: gc in setup

- Try to fix jenkins failure where the ""repeated"" test, which runs a
  time-sensitive test 100 consecutive times, fails occasionally due to
  scale out/back taking a couple of seconds longer than expected. I
  suspect it fails due to a slow GC in the middle of the test. 
  Therefore GC as part of setup for integration tests."
Arrow,SATD Duplication,"[2019-04-23 15:12:43][pitrou][pull:summary][4193]
Remove a spurious memset() call that would 0-initialize any additional data area.

Also tweak the overallocation strategy.

This makes PrimitiveBuilder 60+% faster here (4.5 -> 7.4 GB/s).
","[2019-04-23 15:05:44][Antoine Pitrou][issue:summary][ARROW-5204:13229640]
BufferBuilder makes a spurious memset() when extending the buffer size.

We could also tweak the overallocation strategy in Reserve()."
Lucene Solr,No Relation,"[2018-12-03 09:07:27][markrmiller][commit][1408f5255fbcde6e843845375349a694f783d247]
SOLR-12801: Disable TimeRoutedAliasUpdateProcessorTest because the feature leaks threads.
","[2018-09-24 16:03:23][Mark Miller][issue:summary][SOLR-12801:13187075]
Fix the tests, remove BadApples and AwaitsFix annotations, improve env for test development."
Lucene Solr,No Relation,"[2016-03-01 07:04:45][Robert Muir][commit][2264600ffe4649abb0edbe7a6882ffc82f6e918b]
LUCENE-7057: cleanup some sandiness around LatLonPoint
","[2016-03-01 05:37:01][Robert Muir][issue:summary][LUCENE-7057:12945730]
A few improvements to make this less sandy: geo stuff tends to get complicated so we can try to make the simple stuff right
* encode/decode tests became useless because all tested points were quantized
* explicitly test extreme values (field creation and quantization error)
* encoding could overflow integer for the maximum possible value
* turn encoder checks into real checks
* add assert on decode that decoded values are within bounds
* test various illegal parameters
* add setLocation(double, double) to change value for the field
* improve javadocs 
* fix toString bug in distance query
* make distance and polygon queries package private
* add missing numDims/bytesPerDim checks to distance and polygon query"
Qpid Dispatch,SATD Repayment,"[2019-03-11 16:04:41][Ted Ross][code-comment][e87577bb401490800716fd482d0b9eaf169d2fae]

 Schedule the cleanup of deliveries freed during this core-thread pass
","[2019-03-06 18:52:38][Ted Ross][issue:summary][DISPATCH-1281:13220007]
Profiling has identified a disproportionate amount of core-thread time being spent in qdr_delete_delivery_internal_CT.  This is due to the fact that every in-core delivery-free results in the posting of one unit of general work (work to be performed by an I/O thread without any association with a particular connection).

This improvement batches the freed messages to be handled at one time, with one unit of general work, at the end of the processing of each set of core-thread actions.

The result is a greater degree of batching of message-cleanups when the core thread is busier.  This will free up core-thread CPU capacity for when the router is the busiest."
Beam,SATD Duplication,"[2017-02-07 00:15:31][chamikaramj][pull:summary][1932]
[BEAM-1406] Removes deprecated fileio.TextFileSink
","[2017-02-06 21:27:34][Chamikara Madhusanka Jayalath][issue:summary][BEAM-1406:13040772]
Remove deprecated fileio.TextFileSink"
Lucene Solr,No Relation,"[2018-03-20 11:57:29][Adrien Grand][commit][710993435f365fce44a60b7c498ce6af8327f92c]
LUCENE-8197: Efficient integration of static scoring factors.
","[2018-03-09 00:18:00][Robert Muir][issue:comment][LUCENE-8197:16392154]
Also i'm not sure what the explanation currently looks like (looks like it will just return the total value without ""breaking it down""), but we may want to open a followup to improve that if its the case."
Spark,SATD Repayment,"[2018-01-17 09:27:49][Sameer Agarwal][commit][c132538a164cd8b55dbd7e8ffdc0c0782a0b588c]
[SPARK-23020] Ignore Flaky Test: SparkLauncherSuite.testInProcessLauncher

## What changes were proposed in this pull request?

Temporarily ignoring flaky test `SparkLauncherSuite.testInProcessLauncher` to de-flake the builds. This should be re-enabled when SPARK-23020 is merged.

## How was this patch tested?

N/A (Test Only Change)

Author: Sameer Agarwal <sameerag@apache.org>

Closes #20291 from sameeragarwal/disable-test-2.
","[2018-01-17 08:19:16][sameeragarwal][pull:summary][20291]
## What changes were proposed in this pull request?

Temporarily ignoring flaky test `SparkLauncherSuite.testInProcessLauncher` to de-flake the builds. This should be re-enabled when SPARK-23020 is merged.

## How was this patch tested?

N/A (Test Only Change)"
Geode,SATD Duplication,"[2017-04-20 19:19:16][davinash][pull:summary][470]
GEODE-267: Remove deprecated ThreadInterruptedException
","[2015-08-24 16:40:35][Darrel Schneider][issue:summary][GEODE-267:12858333]
Remove deprecated ThreadInterruptedException"
Arrow,SATD Duplication,"[2018-02-08 17:35:42][cpcloud][pull:summary][1578]
ARROW-1973: [Python] Memory leak when converting Arrow tables with array columns to Pandas dataframes.
","[2018-01-07 03:29:30][Alexey Strokach][issue:summary][ARROW-1973:13129051]
[Python] Memory leak when converting Arrow tables with array columns to Pandas dataframes."
Lucene Solr,No Relation,"[2012-08-25 10:06:07][Uwe Schindler][code-comment][2317133ca2c3c295bf5c27216bf1995fe2e48d32]
* Called when we are done adding docs to this term
","[2012-08-30 22:51:39][Uwe Schindler][issue:comment][LUCENE-3312:13445383]
I merged in the recent changes in trunk (rev. 1379200). Robert Muir added lots of JavaDocs to the document and index package, so we should check that everything is still correct. We should especially review sentences that contain hints to stored documents on IndexableDocument and vice versa."
Samza,SATD Repayment,"[2020-01-14 12:03:24][Ke Wu][commit][eaa0491d7527d9e8c6fbe3ed923cf2aa1034d21c]
Clean up unused org.apache.samza.autoscaling module (#1250)

Issues: samza-autoscaling module is not used.

Changes: remove the unused module.

API Changes:
None

Upgrade Instructions:
None

Usage Instructions:
None

Tests: build
","[2020-01-11 01:41:01][kw2542][pull:summary][1250]
Clean up unused org.apache.samza.autoscaling module"
Geode,SATD Repayment,"[2015-07-14 12:25:42][Dan Smith][commit][9fa9ced08f1851f97d2d2407f1519dcc3cac06e0]
GEODE-74: Making the satisfy redundancy phase of rebalance parallel

Tasks submitted to background threads to trigger redundancy
satisfaction. After the satisfy redundancy phase is done we wait for the
tasks to finish.

The number of buckets that can be recovering in parallel is controlled
by the system property gemfire.MAX_PARALLEL_BUCKET_RECOVERIES, currently
set to 8.

If a redundancy recovery/rebalance is restarted due to a membership
change, wait for any in progress operations to complete before fetching
new information from all of the members.
","[2015-07-01 18:54:35][Dan Smith][issue:summary][GEODE-74:12842076]
Recover redundancy in parallel"
Hadoop,No Relation,"[2016-03-18 11:18:48][Anu Engineer][code-comment][37e3a36a3f3ab217afc47f1120db6a4f03559efb]
 add to low redundancy queue if need to be
","[2017-11-12 15:50:21][Mukul Kumar Singh][issue:comment][HDFS-7240:16248902]
patch v6 is after fixing check style/findbugs/whitespace issues in the HDFS-7240 branch."
Drill,SATD Repayment,"[2017-04-07 15:24:51][Paul Rogers][commit][163a0c4e83d1500c27eb5d59d320f91e07961a0f]
DRILL-5355: Misc. code cleanup closes #784
","[2017-03-14 22:08:12][paul-rogers][pull:summary][784]
DRILL-5355: Misc. code cleanup"
Kafka,No Relation,"[2017-05-21 17:31:31][Jiangjie Qin][code-comment][7fad45557e4cb7b345f34cec32f910b437c59bc2]
 The minimum speed to decrease compression ratio when a batch compresses worse than expected.
","[2017-05-19 18:29:26][becketqin][pull:comment][2638:117546148]
I haven't done benchmark. Is the concern about the new synchronization? It is probably not a big issue given that there will only be one read and one write to this map per batch. A single producer benchmark is unlikely to give any insight in this case. We will need many producers to produce in the same JVM at the same time to make the synchronization take some effect if any. So personally I am not really concerned about this synchronization."
Ignite,SATD Duplication,"[2018-05-18 14:06:34][Mmuzaf][pull:summary][4027]
IGNITE-605: remove todo as no needs
","[2015-03-26 09:53:20][Artem Shutak][issue:summary][IGNITE-605:12785831]
[Test] TODO in GridAbstractTest w/ comment ""propose another way to avoid network overhead in tests"""
Hadoop,SATD Repayment,"[2015-02-20 19:47:28][Robert Kanter][commit][6f0133039a064ca82363ac6f29fb255506f31b8a]
HADOOP-11612. Workaround for Curator's ChildReaper requiring Guava 15+. (rkanter)
","[2015-02-19 00:34:49][Robert Kanter][issue:summary][HADOOP-11612:12776043]
Workaround for Curator's ChildReaper requiring Guava 15+"
Nifi,No Relation,"[2016-01-26 15:46:22][markap14][pull:comment][185:50852054]
Can we call this InvokeScript instead of InvokeScriptProcessor? We used to call all the Processors ...Processor but got away from it because using the <Verb><Noun> naming scheme made the flows much easier to understand
","[2014-12-31 21:23:41][A. Steven Anderson][issue:comment][NIFI-210:14262441]
Well, it's pretty much the same use case as the other languages that are supported; i.e. you have some simple processing you want to do but in Scala instead of the other languages. ;-)"
Groovy,SATD Repayment,"[2019-10-11 09:35:14][Daniel.Sun][commit][28ae0c4f0ac9764c08bce8064cfb1983723cde98]
GROOVY-9276: Improve the performance of parsing
","[2019-10-11 00:05:03][Daniel Sun][issue:summary][GROOVY-9276:13261667]
Improve the performance of parsing"
Fluo,SATD Repayment,"[2014-12-04 12:38:42][Mike Walch][commit][c9bb1761242e0788e5d1fd939d859c1d6793df65]
Merge pull request #358 from mikewalch/fluo-348

Closes #348 - Clean up ScannerConfiguration and create unit test
","[2014-12-02 13:14:14][mikewalch][pull:summary][358]
Closes #348 - Clean up ScannerConfiguration and create unit test"
Hudi,SATD Repayment,"[2017-03-21 17:36:46][prazanna][commit][f1b7afad2143cba6a87e03207e0e45c7cfc8ef10]
Add config for index parallelism and make clean public (#109)

* Add config for index parallelism and make clean public

* Review comments on clean api modification
","[2017-03-21 19:16:37][prazanna][pull:summary][109]
Add config for index parallelism and make clean public"
Brooklyn Server,SATD Repayment,"[2014-01-26 17:11:16][Alex Heneveld][code-comment][7abe6f5211639f94c76239af9cc7d2ca606bd89a]
 problem: but let's ensure that classpath is sane to give better errors in common IDE bogus case
","[2014-01-26 17:11:16][Alex Heneveld][commit][7abe6f5211639f94c76239af9cc7d2ca606bd89a]
some cleanups to ensure PortRange coercions are set, and give better error messages on errors i encountered"
Arrow,SATD Duplication,"[2020-08-19 18:50:17][lidavidm][pull:summary][8010]
ARROW-9587: [FlightRPC][Java] clean up FlightStream/DoPut
","[2020-07-28 17:48:48][David Li][issue:summary][ARROW-9587:13319814]
[FlightRPC][Java] Clean up DoPut/FlightStream memory handling"
Zookeeper,SATD Duplication,"[2019-06-23 18:56:36][xoiss][pull:summary][1000]
ZOOKEEPER-2894: Memory and completions leak on zookeeper_close
","[2017-09-08 11:26:29][Alexander A. Strelets][issue:summary][ZOOKEEPER-2894:13100765]
Memory and completions leak on zookeeper_close"
Flink,No Relation,"[2017-07-31 16:37:52][Dawid Wysakowicz][code-comment][0c9c9fb5cb7a8a27d444db5c725c8abd792ca761]
CHECKSTYLE.OFF: AvoidStarImport|ImportOrder
CHECKSTYLE.ON: AvoidStarImport|ImportOrder
","[2017-07-14 17:20:44][zentol][pull:comment][4340:127506011]
indentation seems off."
Carbondata,SATD Duplication,"[2017-04-05 13:45:30][manishgupta88][pull:summary][735]
[CARBONDATA-870] Folders and files not getting cleaned up created locally during data load operation
","[2017-04-05 13:44:54][Manish Gupta][issue:summary][CARBONDATA-870:13061745]
Folders and files not getting cleaned up created locally during data load operation"
Incubator Heron,SATD Repayment,"[2016-04-26 10:28:01][Bill Graham][code-comment][4899cbe68871241a60518f3e32cfc99b5bfc1364]
 allows us to use annotations to supress, like this: @SuppressWarnings(""checkstyle:methodlength"")
","[2016-04-25 17:46:42][billonahill][pull:summary][446]
Allows us to use annotations to suppress checkstyles like this:

`@SuppressWarnings(""checkstyle:methodlength"")`"
Tinkerpop,SATD Repayment,"[2014-07-18 14:40:43][Stephen Mallette][code-comment(deleted)][fddd2030c3c4a469463258797a599cd41053f063]
 todo: something still fishy with exception handling here
","[2014-07-18 14:40:43][Stephen Mallette][commit][fddd2030c3c4a469463258797a599cd41053f063]
drop some todo comments."
Hudi,SATD Duplication,"[2020-08-05 21:34:55][lw0090][code-comment][51ea27d665d8053895dd047ca85e3338b357a81d]
 Get the last time we successfully synced partitions
 TODO : once DLA supports alter table properties
","[2020-08-05 01:16:41][leesf][pull:comment][1810:465415868]
we would add a TODO here once DLA supports alter table properties."
Geode,SATD Repayment,"[2019-01-30 16:06:11][Bruce Schuchardt][commit][8e3c9d712183a684bde55c2611a5104926397e3e]
GEODE-6342 ThreadsMonitor prints many warnings in gateway sender logs

Modified the gateways to update the ThreadsMonitor before sleeping.
","[2019-01-30 21:33:31][Dan Smith][issue:summary][GEODE-6342:13212919]
ThreadsMonitor prints many warnings in gateway sender logs if receiver is not running"
Incubator Pinot,SATD Duplication,"[2019-10-25 17:50:02][Neha Pawar][code-comment][494ff8a38080190c07f62072058d5e1275bf98cd]
 FIXME: support BYTES in DataTable instead of converting to string
 ByteArray::toString
","[2019-10-24 22:52:08][Jackie-Jiang][pull:comment][4728:338825007]
Add a TODO to support BYTES in DataTable instead of converting to string"
Hadoop,No Relation,"[2011-08-17 22:08:08][Arun Murthy][code-comment][2da287b31209011f27555734c0378ec4cff0e9a3]
 Makes injection in subclasses optional.
 Time will tell if this buy us more than the NPEs :)
","[2011-03-21 15:49:07][Arun Murthy][issue:comment][MAPREDUCE-279:13009183]
bq. Looking through the code a bit more I came across Hamlet.

Luke can provide more details, but I believe he took this route due to the lack of a better 'embeddable' alternative.

Having said that, echo'ing eric14, please feel free to open a jira with an alternate proposal and we can consider moving over to something more standard that satisfies our constraints. Alternately, in the long run, we could move Hamlet out to a separate (incubator?) project to attempt build a community around."
Drill,No Relation,"[2017-07-03 11:41:20][Paul Rogers][commit][63e243378f3be125f1e8bfb52c74b8211c87bfc3]
DRILL-5518: Test framework enhancements

* Create a SubOperatorTest base class to do routine setup and shutdown.
* Additional methods to simplify creating complex schemas with field
widths.
* Define a test workspace with plugin-specific options (as for the CSV
storage plugin)
* When verifying row sets, add methods to verify and release just the
""actual"" batch in addition to the existing method for verify and free
both the actual and expected batches.
* Allow reading of row set values as object for generic comparisons.
* ""Column builder"" within schema builder to simplify building a single
MatrializedField for tests.
* Misc. code cleanup.

closes #851
","[2017-06-21 01:51:47][paul-rogers][pull:comment][851:123138037]
Checkstyle does not care. In fact, earlier headers used to use a line of stars across the top as well, but the first three characters, /**, caused the comment to look like Javadoc, so we've been deprecating that style. Still, fixed this one as well."
Phoenix,SATD Repayment,"[2019-05-28 23:28:14][Kadir][code-comment][dff179b6c184bfeb4d28c090241cf08577ec4d85]
 Run the orphan view tool to clean up orphan views
","[2018-11-16 01:03:03][Kadir OZDEMIR][issue:summary][PHOENIX-5025:13198797]
Tool to clean up orphan views"
Hbase,SATD Repayment,"[2014-12-03 13:13:12][Sean Busbey][commit][c5c395b68a1379e3cb85a01e90dcc94c13b1cc6c]
HBASE-12623 removes unused code to upgrade from pre-0.96 to 0.96.

Removes both insertion of namespaces and migration of zookeeper data to protobufs.
","[2014-12-03 15:03:01][Sean Busbey][issue:summary][HBASE-12623:12759192]
Since we require a cluster to be 1.0+ prior to upgrading to 2.0, we should remove code that is only used for handling upgrades prior to that version."
Pulsar,SATD Repayment,"[2021-01-07 09:44:48][Enrico Olivelli][code-comment][7313b3403867d5ca16ea68edeaedd42f8c389ad3]
 this makes the test easier and predictable
","[2020-12-29 17:12:46][sijie][pull:comment][9083:549782046]
How does this make the test easier and predictable?"
Ozone,SATD Repayment,"[2019-08-13 23:07:02][Anu Engineer][commit][eb1738d310feeb383d418026e80d59446bf46ac3]
HDDS-1947. fix naming issue for ScmBlockLocationTestingClient.
Contributed by star.
","[2019-05-14 08:22:52][star][issue:summary][HDDS-1947:13233164]
fix naming issue for ScmBlockLocationTestingClient"
Lucene Solr,SATD Repayment,"[2016-04-04 12:51:03][Robert Muir][commit][c1a3e1b8d04ffc94e502b086e0544c0e0494d5a8]
LUCENE-7159: Speed up LatLonPoint point-in-polygon performance
","[2016-04-01 02:56:38][Robert Muir][issue:summary][LUCENE-7159:12955174]
improve spatial point/rect vs. polygon performance"
Thrift,SATD Duplication,"[2015-09-22 02:09:51][nsuke][pull:summary][615]
THRIFT-3342 Improve ruby cross test client and server compatibility
","[2015-09-22 02:08:08][Nobuaki Sukegawa][issue:summary][THRIFT-3342:12895311]
Improve ruby cross test client and server compatibility"
Incubator Pinot,SATD Repayment,"[2020-08-05 21:23:37][Xiaotian (Jackie) Jiang][commit][ffa954194e61e330c625a795cae94c15a54a2694]
Pre-generate aggregation functions in QueryContext (#5805)

`AggregationFunction` itself is stateless, so we can share it among all the segments to prevent the overhead of creating it per segment. This can significantly improve the performance of high selectivity queries that hit lots of segments.

- Remove the `accept(visitor)` from the `AggregationFunction` interface which may make it stateful
- Make `DistinctCount` and `DistinctCountBitmap` stateless by caching the dictionary within the result holder
","[2020-08-04 19:59:16][Jackie-Jiang][pull:summary][5805]
## Description
`AggregationFunction` itself is stateless, so we can share it among all the segments to prevent the overhead of creating it per segment. This can significantly improve the performance of high selectivity queries that hit lots of segments.

- Remove the `accept(visitor)` from the `AggregationFunction` interface which may make it stateful
- Make `DistinctCount` and `DistinctCountBitmap` stateless by caching the dictionary within the result holder

## Release Notes
Interface change: `accept(visitor)` is removed from `AggregationFunction`
All the implementation of the `AggregationFunction` should be stateless so that it can be shared among all the segments."
Ignite,SATD Repayment,"[2019-03-27 17:32:23][tledkov][commit][4f5732b2fc7bf077ed5fd314031709edf4c1e1e9]
IGNITE-11524: JDBC Thin Driver: fixed statement leak in connections. This closes #6265.
","[2019-03-13 11:39:44][tledkov-gridgain][pull:summary][6265]
IGNITE-11524 Memory leak caused by executing a jdbc prepared statement"
Helix,SATD Repayment,"[2020-02-07 12:24:22][Jiajun Wang][commit][39f395937ef86a0cf60687e76dec40c0434a942b]
Refine the WAGED rebalancer to minimize the partial rebalance workload. (#639)

* Refine the WAGED rebalancer to minimize the partial rebalance workload.

Split the cluster module calculation method so that different rebalance logic can have different rebalance scope calculation logic.
Also, refine the WAGED rebalancer logic to reduce duplicate code.
","[2019-11-01 06:22:02][jiajunwang][issue:summary][563]
Improve the WAGED rebalancer calculating speed."
Trafodion,SATD Repayment,"[2017-10-02 00:13:35][Anoop Sharma][code-comment(deleted)][2eaef5d7a9b3beb1b4f45ab97899c2a4b6b7059e]
 warning elimination
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination 
 warning elimination
","[2017-10-02 00:13:35][Anoop Sharma][commit][2eaef5d7a9b3beb1b4f45ab97899c2a4b6b7059e]
PR-1251 [TRAFOFION-2731] CodeCleanup: Phase4: Removed lagacy/obsolete warning elimination pragmas"
Usergrid,No Relation,"[2015-03-04 13:34:11][Dave Johnson][code-comment][c0d50394e0e4f3b3669fcfd582b78ce49a86a542]
 emit internal hard-coded applications first (currently there is only one)
 this way consumers can perform whatever work they need to on the root system first
","[2015-03-04 13:34:11][Dave Johnson][commit][c0d50394e0e4f3b3669fcfd582b78ce49a86a542]
Changes to merge appinfo and application_info collections into one application_info collection. Also:
- Removed unnecessary system and default applications
- Now use seek rather than search to load application info entities
- Uncommented the parts of ApplicationDeleteTest that did not work before the appinfo fix
- Will migrate old appinfo collection to application_info on startup, but can be configured to skip that"
Lucene Solr,No Relation,"[2020-12-23 12:41:23][Dawid Weiss][code-comment][2d6ad2fee6dfd96388594f4de9b37c037efe8017]
*
   * true if the <code>len</code> chars of <code>text</code> starting at <code>off</code> are in the
   * set
","[2020-12-23 12:41:23][Dawid Weiss][commit][2d6ad2fee6dfd96388594f4de9b37c037efe8017]
LUCENE-9570: code reformatting [partial]."
Drill,SATD Repayment,"[2014-09-11 19:25:28][Aditya Kishore][commit][676f5df6b14b10ccc3603360e0efee9c745c5b97]
DRILL-1402: Add check-style rules for trailing space, TABs and blocks without braces
","[2014-09-11 02:50:03][Aditya Kishore][issue:summary][DRILL-1402:12740667]
Add check-style rules for trailing space, TABs and blocks without braces"
Incubator Brooklyn,SATD Repayment,"[2015-10-14 17:11:07][Svetoslav Neykov][code-comment(deleted)][883feaea73a5d1f528796908535fcb3c708f96e0]
 TODO Not CAMP specific, move to core, to be reused by other parsers
","[2015-10-14 17:11:07][Svetoslav Neykov][commit][883feaea73a5d1f528796908535fcb3c708f96e0]
Move ServiceSpecResolver and its implementations to core

To be reused by other plan parsers."
Airflow,SATD Repayment,"[2021-01-25 10:08:11][Jarek Potiuk][code-comment][31b956c6c22476d109c45c99d8a325c5c1e0fd45]
 Remove files from `docker-context-files` if the directory is not used
 This causes that Docker cache is consistent across different
 people who might have some files present in the docker-context files from previous builds
","[2021-01-25 10:08:11][Jarek Potiuk][commit][31b956c6c22476d109c45c99d8a325c5c1e0fd45]
Removes files from docker-context-files if not used (#13830)

In case docker-context files are not used during build, they
shoudl be cleaned just before the build to make sure that
docker context does not contain extra files here. Otherwise
files left from previous runs might be in the context and cause
cache invalidation if you are building the images locally."
Lucene Solr,SATD Repayment,"[2017-01-18 13:48:27][Adrien Grand][code-comment][3404677e57fcf7901813f7d7ccfc3e57db011993]
*
       * Create a visitor that clears documents that do NOT match the range.
","[2017-01-18 13:48:27][Adrien Grand][commit][3404677e57fcf7901813f7d7ccfc3e57db011993]
LUCENE-7641: Speed up range queries that match most documents."
Pulsar,SATD Duplication,"[2019-06-26 04:03:33][MarvinCai][pull:summary][4604]
fix #1267
Instead of sorting the consumers based on priority level and consumer name then pick a active consumer, which could cause subscription getting into a flaky state, where the ""active"" consumer joins and leaves, no consumer is actually elected as ""active"" and consuming the messages.

Fix logic to always pick the first consumer in the consumer list without sorting consumers. So consumers will be picked as acive consumer based on the order of their subscription.
","[2018-02-21 20:01:52][sijie][issue:summary][1267]
*Problem*

Currently failover subscription is sorting the consumers. so if a consumer who consumer name is always the first consumer after sorting and the consumer has flaky network where it joins and leaves, this would cause the whole subscription getting into a *flaky* state, where the ""active"" consumer joins and leaves, no consumer is actually elected as ""active"" and consuming the messages.

The sorting logic is useful for partitioned topics. However it is not necessarily required by non-partitioned topic. So we should change the logic to not sort the consumers and make the ""active"" consumer stabilize no matter how other consumers joining the subscription."
Ignite,No Relation,"[2020-12-03 10:34:58][ibessonov][code-comment][09d5c73c467acf13408d22ab4198bff6c2c7d229]
 A bit too general for now, but I like it more then saving only the last checkpoint future.
","[2020-11-16 14:44:25][agoncharuk][pull:comment][7984:524319380]
We have very verbose statistics for each partition printed out separately. Instead, I would have a separate aggregated statistics object that is periodically printed during defragmentation, and full stats printed out per cache/cache group completion (something like ""Defragmentation [cache='cacheA', processedSize=10Gb, defragmentedSize=2Gb, partitions=24(56), progress=39%]""). Detailed per-partition logging can be moved to the debug level."
Hadoop,No Relation,"[2015-09-24 10:30:04][Jian He][code-comment][d45880569064dae191ed286875903e1906e597bf]
 When the container expired, and it has a pending increased request, we
 will kill the container.
 TODO, we can do better for this: roll back container resource to the
 resource before increase, and notify scheduler about this decrease as
 well. Will do that in a separated JIRA.
","[2015-09-02 17:32:37][MENG DING][issue:comment][YARN-1651:14727683]
I think that should work. 
We probably need to make sure to properly log warning messages so that user will find out what is going on and why under these circumstances. I know that both of my examples are edge cases (mostly through incorrect logic in AM), but it could be frustrating to the user when they think their container has been granted certain resource in NM, only to find out at a later time that it is not."
Cloudstack,No Relation,"[2011-06-21 01:12:06][Alex Huang][code-comment][5771b35a7a77ea9f895b9e2379f2c90ddb349574]
*<em>*</em></em>
<a name=""99"" href=""#99"">99</a>  <em>     * Check that LevelRangeFilter.decide() returns Filter.NEUTRAL</em>
<a name=""100"" href=""#100"">100</a> <em>     *    when event level is above min level and accept on match is false.</em>
<a name=""101"" href=""#101"">101</a> <em>
","[2011-06-21 01:12:06][Alex Huang][commit][5771b35a7a77ea9f895b9e2379f2c90ddb349574]
new log4j jar files and now the ability to get rid of the stupid cglib stack traces in our logs"
Beam,SATD Duplication,"[2019-05-14 21:08:43][Maximilian Michels][code-comment][567499605dd11c5d22a6573fed5dd8bba2242a5c]
 todo: this is a hack!
","[2019-05-07 14:35:27][mxm][pull:comment][8410:281662121]
Why is this a hack?"
Lucene Solr,No Relation,"[2020-12-28 12:26:13][Dawid Weiss][code-comment][8ef6a0da56878177ff8d6880c92e8f7d0321d076]
 TODO: recognize ',' address delimiter. Also, see examples of ';' delimiter use at:
 http://www.mailto.co.uk/
","[2020-12-28 12:26:13][Dawid Weiss][commit][8ef6a0da56878177ff8d6880c92e8f7d0321d076]
LUCENE-9570: code reformatting [partial]."
Hadoop,No Relation,"[2016-01-06 13:50:35][Junping Du][code-comment][9da7b1fdd2b88399d2b2e11bc7dce7d80b41e297]
 Container c1 is killed which leads to cleanup
","[2015-09-13 18:10:53][Varun Saxena][issue:comment][YARN-2902:14742588]
Fixed one related test case, checkstyle and whitespace issues."
Trafficcontrol,No Relation,"[2020-02-17 10:09:41][mattjackson220][code-comment][18fe13ac638557b5532813bce8ab3ad2d964fe49]
 TODO(cbro): append to existing User-Agent header?
","[2019-10-16 20:42:25][mattjackson220][pull:comment][3534:335698703]
yes. ill update the docs for those too."
Kafka,No Relation,"[2017-06-30 00:13:52][junrao][pull:comment][2929:124940850]
There are a few places like LogManager.truncateTo() where we call LogManager.handleLogDirFailure() directly. It seems that they should all call ReplicaManager.handleLogDirFailure() instead since it does things like taking the partition off AllPartitions and removing the partition from replicaFetcherManager, which need to be done on an offline logDir.
","[2017-09-01 06:50:29][Dong Lin][issue:comment][KAFKA-4763:16150131]
[~uncleGen] The current design don't use remaining disk currently for simplicity."
Phoenix,SATD Repayment,"[2016-08-31 20:45:12][Josh Elser][code-comment][477b4fa788b84d9ceb97283a02ab5dd01648cc02]
 PHOENIX-3189 Because ConnectionInfo is immutable, we must make sure all parts of it are correct before
 construction; this also requires the Kerberos user credentials object (since they are compared by reference
 and not by value. If the user provided a principal and keytab via the JDBC url, we must make sure that the
 Kerberos login happens *before* we construct the ConnectionInfo object. Otherwise, the use of ConnectionInfo
 to determine when ConnectionQueryServices impl's should be reused will be broken.
","[2016-08-17 17:46:45][joshelser][pull:summary][191]
Now that ConnectionInfo has the current User/UGI stored inside, we must
make sure that any automatic Kerberos login occurs before the ConnectionInfo
object is constructed. Otherwise, we will have multiple instances of
ConnectionInfo that differ only by the User, which will leak HBase/ZK
connections in the connectionQueryServicesMap."
Airflow,SATD Repayment,"[2017-06-07 09:16:51][Bolke de Bruin][commit][4764646b18f56c34a35c19bd20a1931eb3a844fe]
[AIRFLOW-1166] Speed up _change_state_for_tis_without_dagrun

_change_state_for_tis_without_dagrun was locking a
significant
amount of tasks uncessarily. This could end up in
a deadlock
in the database due to the time the lock stood.

Closes #2267 from bolkedebruin/fix_deadlock
","[2017-05-02 20:26:20][bolkedebruin][pull:summary][2267]
[AIRFLOW-1166] Speed up _change_state_for_tis_without_dagrun"
Drill,SATD Duplication,"[2018-06-26 20:01:11][ppadma][pull:summary][1341]
DRILL-6512: Remove unnecessary processing overhead from RecordBatchSizer
","[2018-06-18 00:48:02][Padma Penumarthy][issue:summary][DRILL-6512:13166627]
Remove unnecessary processing overhead from RecordBatchSizer"
Camel,No Relation,"[2015-01-19 14:28:16][Claus Ibsen][code-comment][780c09640167e82babe8f6495b414297f986084e]
*
     * The description as human readable text
","[2015-01-19 14:28:16][Claus Ibsen][commit][780c09640167e82babe8f6495b414297f986084e]
CAMEL-8195: Add javadoc to model classes so we have EIP documentation out of the box"
